{
  
    
        "post0": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . Front Matter is a markdown cell at the beginning of your notebook that allows you to inject metadata into your notebook. For example: . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(movies).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(movies).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=alt.Y(&#39;IMDB_Rating:Q&#39;, axis=alt.Axis(minExtent=30)), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=600, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=700, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; df = pd.read_json(movies) # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks just like you can with markdown. . For example, here is a footnote 1. . . This is the footnote.&#8617; . |",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Start",
            "content": "Here for Google Summer of Code 2020? . User documentation and files . How to chat with the team (/ccextractor-wiki-test/2020/02/20/for support, to join us, for GSoC or GCI, or anything else) . What’s CCExtractor? (/ccextractor-wiki-test/2020/02/20/the software, not the organization) . About CCExtractor Development (/ccextractor-wiki-test/2020/02/20/the organization, not the software) . Downloads . Changelog . Using the command line tool . Using the Windows GUI . Real time demo - Currently down, our primary source of data is moving to a new office and their infrastructure is not yet available. . Extracting burned-in subtitles . Extracting CEA-708 subtitles . Translating subtitles in real time . Using the cross-platform GUI . Extracting closed captions from a DVD step by step tutorial . public:general:Working with HDHomeRun . public:general:Using SPUPNG . TV samples . Donate . Cool external projects that use subtitles . Technical documentation . Most of these pages are the result of Summer of Code work. . Getting started with our code . public:general:Rotating capture system with HDHomeRun . public:general:Subtitle standards around the world . Regression system . Online real time repository . Subtitle Downloader (/ccextractor-wiki-test/2020/02/20/user) . Subtitle Downloader (/ccextractor-wiki-test/2020/02/20/technical) . public:gsoc:DVD Subtitles Technical Documentation GSoC’16 . public:gsoc:Python Extension Module Technical Documentation GSoC’17 . public:gsoc:Python Extension Module Compilation Documentation GSoC’17 . Building CCExtractor inside a Vagrant box . Activity Extractor (/ccextractor-wiki-test/2020/02/20/user) . Activity Extractor (/ccextractor-wiki-test/2020/02/20/technical) . Google Code-in public pages . public:codein:Google Code-in 2016 task list . public:codein:Google Code-in 2017 code-in for designers . public:codein:google_code-in_2018 . Google Code-in 2019: Welcome and introduction (start here) . Google Code-in 2019: Rust . Google Code-in 2019: Flutter . Google Code-in 2019: FFmpeg . Google Code-in 2019: Mastermind . Summer of Code public pages . public:gsoc:Ideas page for Summer of Code 2020 . public:gsoc:Ideas page for Summer of Code 2019 . public:gsoc:Ideas page for Summer of Code 2018 . public:gsoc:Welcome to Summer of Code 2016 . public:gsoc:Welcome to Summer of Code 2015 . public:gsoc:ccextractor_Bug Hunt . public:gsoc:ccextractor Tasks . CCExtractor unassigned tasks (/ccextractor-wiki-test/2020/02/20/pick what you like) . Blog Posts from our Students . Season of docs public pages . Ideas page for Season of Docs 2019 . GSoC Students Project Report . 2019 . Amit - Poor Man’s Rekognition . Bowen - PiPot . Faiz - Poor Man’s Rekognition . Sarfaraz - Poor Man’s Rekognition . Shivam Kumar Jha - Sample Platform . 2018 . Archit - FabBits . Aaditya - Project Nephos . Shivam Kumar Jha - Project Nephos . Saurabh Shrivastava - CCExtractor Web - A web application for subtitle extraction through CCExtractor. . Satyam Mittal - The sample platform / Continuous integration . 2017 . Diptanshu - Python Extension Module (/ccextractor-wiki-test/2020/02/20/bindings) for CCExtractor . Saurabh - CCAligner - Word by Word Audio Subtitle Synchronisation . Satyam - Sample platform improvements (/ccextractor-wiki-test/2020/02/20/Windows testing) . 2016 . Willem - Sample platform iteration 2 . Abishek - Subtitle Extractor and CCExtractor improvements . Abhinav - Extract hard-coded subtitles from video streams . Shruti - News shot classification . Rishabh - DVD Subtitle Extraction . Ruslan - Real-time Repository and website . Vasanth - Commercial detection . 2015 . Willem - Sample submission platform / CCExtractor improvements . Nurendra - Sentiment Analysis / Realtime Translation with Google Translate/Apertium . Summer of Code private pages . private:gsoc:People . private:gsoc:technical_resources . private:gsoc:Planned absences . Contract work . How to hire CCExtractor developers . Miscellaneous resources about things that interest us . Rust . Flutter . Preparing for interviews (/ccextractor-wiki-test/2020/02/20/Silicon Valley style) . Useful linux tools . Articles about vim (/ccextractor-wiki-test/2020/02/20/the editor) .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/start.html",
            "relUrl": "/2020/02/20/start.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Public:gsoc:welcome_to_summer_of_code_2016",
            "content": "Please visit Welcome to Summer of Code 2015 :-) it’s still relevant. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-welcome_to_summer_of_code_2016.html",
            "relUrl": "/2020/02/20/public-gsoc-welcome_to_summer_of_code_2016.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Public:gsoc:welcome_to_summer_of_code_2015",
            "content": "Welcome . This is CCExtractor’s GSOC 2015 Wiki. . Red Hen has another document system (generic, not GSoC-specific), please ask Mark or Francis for access. It is fine to create Red Hen pages here (by anyone) if it’s found to be more convenient. . About this wiki: . Anyone with access can edit existing pages and create new ones. | It is expected to contain all relevant information. If it’s not here it doesn’t exist :-) | It will eventually contain sensitive information (such as passwords), therefore make sure your own access credentials to the wiki are not shared with 3rd parties. | We use dokuwiki. It’s quite easy to use, but you should check out its documentation before you start editing. | .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-welcome_to_summer_of_code_2015.html",
            "relUrl": "/2020/02/20/public-gsoc-welcome_to_summer_of_code_2015.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Vote counter and reporter",
            "content": "Introduction Yes, we’ve just seen it again in Iowa, but it’s not really a new thing or a new need: Use of electronic voting, counting and reporting is becoming the norm, and so are the problems and lack of trust in the process. . We need to do something. . Your job Your job is to design and implement an universal tool that can be trusted by everybody to help with voting, counting and reporting in any election. . Universal means that it be made to work (with configuration of course) for any kind of voting or election, be it for a party candidate for a major election to a simple class delegate at your university. . Trust will come from its open source nature which makes the code auditable. . Voting means that your system can be used by the voters to well, vote. This is probably the hardest part to get right as you need to somehow verify the voters identity. . Counting means that for those elections (which are probably all the political ones) in which the votes are counted after everybody has votes it must be possible for the people that are doing the counting to update their counts in real time and most importantly compare their counts in real time: The way it works, at least in some countries, is that after the electoral place closes, the ballot box is opened and the counting starts. That counting is done by several people (possibly selected randomly from the registered voters) but there are interested parties (such as party representatives) verifying that everything is done correctly. Those representatives of course are also keeping their own tallies, and at the end of the counting they must match the official count. . It goes in the interest of the process that everybody involved can see the official tally and everybody’s else. . Reporting means that after the counting is over the results can be reported to different places: Depending on who is doing the counting (meaning the user of you application) that reporting will go to their party, to the press, to an “upstream” counting place, or several or those at the same time. . Your system will have a mobile frontend that must be written in Flutter (which generates Android and iOS native aps). . It will also have a backend that can be written in anything, but it must be scalable. For example, a PHP backend is a non-starter. Think of using a massively scalable cloud service as the core of your backend. Remember that your application will have an extremely high usage during a short period of time and then it’s over. . Interesting read. . Finally, this system is not supposed to replace paper. We need the paper trail. It’s essential. . Qualification tasks Take a look at this page. . Your proposal should also include reports regarding scalability and fault tolerance of your chosen tech stack. A list of stacks and their performance comparison for the same application can be made from RealWorld.io .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-votecounter.html",
            "relUrl": "/2020/02/20/public-gsoc-votecounter.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Translating captions",
            "content": "You can use the cctranslate tool (implemented by Oleg) to translate extracted captions in realtime and in SubRip formatted files. We use the Google Translate API for translation, but the tool is built so developers can easily add other translation engines. . How realtime translation works? . ccextractor starts with sharing service on | ccextractor launches cctranslate process | launched instance of cctranslate subscribes to ccextractors’ messages | ccextractor publishes extracted subtitles to all subscribers | cctranslate requests translation from translation service and saves translated captions to an output file | Ok, and what is a “sharing service”? . Sharing service is a Publisher-Subscriber IPC Pattern publisher implementation. It uses nanomsg as a cross-platform socket library, that provides simple interface to implement pub-sub model and supports lots of transport mechanisms. To serialize messages protobuf-c implementation of Google Protocol Buffers is used. Both of used solutions are language-independent, so sharing service could be easily used by third-party developers to create new solutions based on ccextractor. . What about the cctranslate tool? . Cctranslate tool was designed to be cross-platform and is implemented in C language. It uses: . libcurl to perform http/https requests . | nanomsg as a socket library . | protobuf-c to parse serialized messages . | CJSON to parse responses from Google Translate API . | . Standalone SubRip-formatted files could also be translated using this tool along with realtime translation. . Sharing service messaging format . Coming soon in a separate document . How to use it? . First, you have to compile it. It uses cmake build automation system, so make sure you have it installed. For Linux/MacOSX/UNIX use: . $ mkdir build &amp;&amp; cd build $ cmake ../ $ make . Make sure nanomsg and libcurl dev packages are downloaded. If your distribution doesn’t have a package system or these packages are not supported by maintainer, you can download tarballs and compile it by yourself. . Then, create a Google Cloud Platform account (or use your existing) and generate an API key. . Using cctranslate as a standalone text file captions translator . Check what languages are available at the moment: . $./cctranslate --list-langs --key=YOUR_API_KEY . Pick up languages you want your subs be translated to, and run: . $./cctranslate --input=subs.srt --langs=fr,it,th --key=YOUR_API_KEY . Using cctranslate for realtime translation . Copy cctranslate tool to ccextractors’ binary directory. There are two ways to translate realtime: launch ccextractor with translating mode on and launch cctranslate tool to connect to already running instance of ccextractor. . To launch ccextractor with translating mode on, run: . $ ./ccextractor INPUT_OPTIONS -translate LANGUAGE_LIST -translate-auth YOUR_API_KEY . To connect cctranslate tool to already running instance of ccextractor: . $ ./cctranslate --source=extractor --key=YOUR_API_KEY . In the second case, ccextractor has to be started with sharing service on. To do that add -enable-sharing option to arguments. By default, it starts TCP sharing service on localhost:3269. You can set other nanomsg-supported transport type to share captions using -sharing-url arg in format transport:address. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-translating_captions.html",
            "relUrl": "/2020/02/20/public-gsoc-translating_captions.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Take-home qualification tasks",
            "content": "We know that working on existing codebases can be daunting, and you might end up working on a new project anyway, so this year we have some alternative qualification tasks (we’ll add more soon, so come back). . You can still opt for the standard ones (such as fixing issues on GitHub) — these are just alternatives that are available. . Interprocess communication (low-level) . Language: Modern C (not C++). Must work in: Linux . Create a program, in C, that utilizes queues and memory-based interprocess communication. . We’re writing a system that encodes video using hardware encoders, specifically nVidia GPUs. These consumer-grade GPUs are limited to two simultaneous encode sessions. However they can encode (really) fast, easily at 300 frames per seconds. . We want to overcome this limitation by distributing the load in software. Suppose you have 10 cameras each of them providing a never ending stream of video at 30 frames per second. The job is to come up with a good plan (and proof of concept) that maximizes GPU usage. . Here’s a few things that will help you: . You will need to have a queuing system that take the frames. Let’s assume on the assumption that there is one process that reads data from one specific camera, so if there’s 10 camera there are 10 such processes. They are the producers. Let’s call them CameraManagers. . | Because of the way video encoding works (in which one frame can be compressed a lot by using information from the previous one), you can ‘t just merge data from all the cameras and them send to the GPU as they arrive. Instead, you will need to batch them and send a number of frames from one specific camera (maybe 2 seconds, so 60 frames) at a time. We’ll call the program that manages the work queue and the GPU the GPU manager. . | Remember that while you do this the frames will continue to arrive. . | Frames are big, so you want to minimize copying data around. For this, you have shared memory between processes. . | A possibility here is to have one GPUManager, that will take the frames from the the CameraManagers. The GPUManager will need to keep one list of pending frames per camera and a queue of cameras. When a camera has sent 60 frames its list of pending frames is ready to be encoded. The GPUManager then encodes those frames (that causes a file to be generated with the output, but that’s not needed for this exercise) and clears the list. Remember that while encoding was in progress other frames may have arrived and you don’t want to lose them. . | As mentioned, there’s 2 encode sessions. The GPUManager needs to support that and simultaneously encode two frame-queues at a time. . | Cameras can be added, removed, and come down (for example, they can break, or their CameraMananger can crash). You system needs to be tolerant to this. . | You need to create the mockup CameraManager and the Mockup GPUManager. Since you don’t have cameras of course, for each frame read a block of 1280x800 bytes from /dev/urandom. . | Demostrate that it works will by validating the output, for example using a checksum of each input frame and writing it to the output which can be a sample text file that contains the “camera number”, “frame number”, and “checksum” for that frame, in order. . | . Meetup auto-RVSP . Language: Any Must work in: Linux . This task is relatively simple (in theory), but it will help us assess your code organization abilities. . Write a program for meetup.com that sends an auto-RVSP to specific groups. For example, suppose you are a member of 7 different Meetup groups, some of which have very popular events that fill up quickly. You want to sign up for them as fast as possible to ensure that you get a spot. . Your program needs take care of authentication, searching for events in configured groups (not all), and automatically signing up on the user’s behalf in a timely manner. Usage of existing Meetup client libraries is permitted. . It’s OK for your program to be a simple command-line tool that needs to be run from cron once an hour or something like that. . Plan for migrating our DokuWiki website to fastpages . Our website currently uses an easy-to-use wiki solution called DokuWiki, but the aesthetics could be better. . There’s a new platform that uses GitHub Pages for hosting and pull requests for content management. It seems to integrate well with things we care about, e.g. YouTube embeds. . Can you devise a good plan for migrating from DokuWiki to fastpages? . Export data from MyFitnessPal to Grafana . MyFitnessPal is a mobile app used to track food &amp; energy intake, exercise, and more. It supports CSV data export (e.g. through email) to facilitate archival, but this style is a bit antiquated for manual viewing. . A simple website that accepts CSV exports and renders nice visual representations using Grafana would be much better for users. This should be feasible to complete in a few days since all of the major components already exist. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-takehome.html",
            "relUrl": "/2020/02/20/public-gsoc-takehome.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "SwagLyrics-For-Spotify",
            "content": "You can find the project at GitHub. . You can find a list of important issues here. . Getting started / Requirements . The software is written in Python, so we expect good knowledge of Python. Basic HTML, Javascript &amp; CSS knowledge is also required. You should be able to demonstrate that you possess the skills to successfully implement your proposal. . We make use of quite some libraries to support all platforms, and we expect you to read up on the documentation of these platforms so you know how they work in general. . Qualification . If you are interested in taking up this project during GSoC, you will need to satisfy these requirements (in order of importance, not all are a necessity): . A well researched, well written project proposal. | Proof you’ve set up SwagLyrics locally and can set up an instance of the issue-maker for development. | Fixed a bug, improved existing features, solved issues, … (contributed something to the project). | Have chatted with the mentor(s) at least once. | . Mentor(s) . Aadi Bajpai (@aadibajpai on Slack) is a former GCI winner (2017) and mentor (2018, 2019). He wrote the software and is the official (and currently sole) maintainer. | .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-swaglyrics.html",
            "relUrl": "/2020/02/20/public-gsoc-swaglyrics.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Subtitle Downloader Technical Documentation",
            "content": "This page contains how the service modules were coded and also how to add support for a new service. . Main Module . This module is responsible for detecting the type of service module to be used and calls the appropriate service module. A simple string search for the service name is done on the input URL to find the type of service. Errors are handled accordingly. . Hulu . We first require the page source of the video. The function createSoupObject() is responsible for this. For this purpose we use the requests module. We parse the HTML with the help of BeautifulSoup library. The getTitle function returns the title of the video. This is also used for naming the file. The title is present in the Soup Object. Example - &lt;meta name=&quot;twitter:title&quot; value=&quot;Interstellar&quot;/&gt; We then require the contentID of the video. This is also available in the HTML Source. This is one of the methodologies to get the content ID. If this fails the alternative method will be called. In the Beautiful soup text it can be found that every video has this parameter. &quot;content_id&quot;: &quot;60535322&quot; So we first use ‘”‘(quotes) as the delimiter and split the text. Then access the content ID from the returned list. The function getSmiSubtitlesLink returns the SMI subtitle link based on the contentID. The XML Link for any subtitle video is : http://www.hulu.com/captions.xml?content_id=CONTENTID If multiple languages are present we give the user an option to enter their choice. We then convert the SMI URL to a VTT URL as follows - http://assets.huluim.com/captions/380/60601380_US_en_en.smi —&gt; http://assets.huluim.com/captions_webvtt/380/60601380_US_en_en.vtt Then the subtitles are converted from VTT to SRT format in the standard way. . YouTube . We first require the page source of the video. The function createSoupObject() is responsible for this. For this purpose we use the requests module. We parse the HTML with the help of BeautifulSoup library. The getTitle function returns the title of the video. This is also used for naming the file. &lt;title&gt;VIDEO NAME - YouTube&lt;/title&gt; The function getRawSubtitleLink returns the Raw Link which is in encoded format. This is still an incomplete URL. The variable UglyString contains the complete URL. The link is present in the BeautifulSoup. We now prompt the user to choose the desired language from the available choices. The available subtitle language choices are extracted from the UglyString. Based on the chosen language, the corresponding language code is indexed from the language dictionary. This language code is appended to the decoded Link. This final URL contains the subtitles as an XML file. Now, the XML file is converted to .srt file using BeautifulSoup function calls. . Amazon . The subtitle URL for Amazon is present in this URL - . “PreURL”:”https://atv-ps.amazon.com/cdp/catalog/GetPlaybackResources?”, “asin” : “” , “consumptionType” : “Streaming” , “desiredResources” : “SubtitleUrls” , “deviceID” : “b63345bc3fccf7275dcad0cf7f683a8f” , “deviceTypeID” : “AOAGZA014O5RE” , “firmware” : “1” , “marketplaceID” : “ATVPDKIKX0DER” , “resourceUsage” : “ImmediateConsumption” , “videoMaterialType” : “Feature” , “operatingSystemName” : “Linux” , “customerID” : “” , “token” : “” , “deviceDrmOverride” : “CENC” , “deviceStreamingTechnologyOverride” : “DASH” , “deviceProtocolOverride” : “Https” , “deviceBitrateAdaptationsOverride” : “CVBR,CBR” , “titleDecorationScheme” : “primary-content” The primary parameters we need to get are ASIN ID, customerID and TOKEN. These are obtained from the config file. The config file is generated from the setup.py file. The setup.py file takes the users login and password and generates the config file. The ASINID is taken from the URL directly. https://www.amazon.com/dp/B019DSWVYC/?autoplay=1 . Now, add the parameters to the dictionary and generate the final URL. The final URL will look something like this - https://atv-ps.amazon.com/cdp/catalog/GetPlaybackResources?&amp;consumptionType=Streaming&amp;titleDecorationScheme=primary-content&amp;firmware=1&amp;marketplaceID=ATVPDKIKX0DER&amp;resourceUsage=ImmediateConsumption&amp;deviceTypeID=AOAGZA014O5RE&amp;videoMaterialType=Feature&amp;token=6463643hhhdfhdhf7374747&amp;deviceBitrateAdaptationsOverride=CVBR,CBR&amp;operatingSystemName=Linux&amp;deviceProtocolOverride=Https&amp;deviceID=b63345bc3fccf7275dcad0cf7f683a8f&amp;deviceStreamingTechnologyOverride=DASH&amp;asin=B0141BACGU&amp;desiredResources=SubtitleUrls&amp;customerID=A1234GH2343&amp;deviceDrmOverride=CENC . This is where the Subtitle URL is present. We get a JSON response from this URL and it contains a subtitle URL with .dfxp format. We request that subtitle URL and download the subtitles. With BeautifulSoup and Python regex we convert this dfxp to .srt format. (File - Amazon_XmlToSrt.py) . BBC . We first need to extract the episode ID from the URL. Sample URL - http://www.bbc.co.uk/iplayer/episode/p03rkqcv/shakespeare-lives-the-works . The episode ID is p03rkqcv. The episode PID and episode Title(for naming the file) are present in the URL - http://www.bbc.co.uk/programmes/&lt;episode_id&gt;.xml The subtitle URL is present in the following link - http://open.live.bbc.co.uk/mediaselector/5/select/version/2.0/mediaset/pc/vpid/&lt;pid&gt; The PID is nothing but the episode PID obtained above. There are multiple PID’s present. So, we try all the URL’s until the page request is successful. If the request is successful we get the subtitle link by parsing the XML page using Beautiful Soup. The subtitles obtained are in XML format. They are converted to .srt by using BeautifulSoup function calls and regex. The conversion takes place in the file Bbc_XmlToSrt.py . CrunchyRoll . This is one of the methodologies to get the subtitles ID. In the Beautiful soup text it can be found that every video has this parameter. . `&lt;div&gt;`Subtitles: &lt;span class=&quot;showmedia-subtitle-text&quot;&gt; &lt;img src=&quot;http://static.ak.crunchyroll.com/i/country_flags/us.gif&quot;/&gt; &lt;a href=&quot;/naruto-shippuden/episode-464-ninshu-the-ninja-creed-696237?ssid=206027&quot; title=&quot;English (US)&quot;&gt;English (US)&lt;/a&gt;, &lt;img src=&quot;http://static.ak.crunchyroll.com/i/country_flags/sa.gif&quot;/&gt; &lt;a href=&quot;/naruto-shippuden/episode-464-ninshu-the-ninja-creed-696237?ssid=206015&quot; title=&quot;العربية&quot;&gt;العربية&lt;/a&gt;, &lt;img src=&quot;http://static.ak.crunchyroll.com/i/country_flags/it.gif&quot;/&gt; &lt;a href=&quot;/naruto-shippuden/episode-464-ninshu-the-ninja-creed-696237?ssid=206733&quot; title=&quot;Italiano&quot;&gt;Italiano&lt;/a&gt;, &lt;img src=&quot;http://static.ak.crunchyroll.com/i/country_flags/de.gif&quot;/&gt; &lt;a href=&quot;/naruto-shippuden/episode-464-ninshu-the-ninja-creed-696237?ssid=206033&quot; title=&quot;Deutsch&quot;&gt;Deutsch&lt;/a&gt; &lt;/span&gt; &lt;/div&gt; . We need to obtain all the SSID’s. We return all the id’s as a list along with the respective Language title attached. For the above HTML we should have this - &lt;nowiki&gt; [‘206027’, ‘English (US)’], [‘206015’, ‘العربية’], [‘206733’, ‘Italiano’], ‘206033’, ‘Deutsch’ &lt;/nowiki&gt; We prompt the user to choose the language and based on the choice, we append the ID from the list obtained above. A sample subtitle URL, where a script_id(206027) has been appended to the base URL : http://www.crunchyroll.com/xml/?req=RpcApiSubtitle_GetXml&amp;subtitle_script_id=206027 . The encrypted subtitles are extracted from the above URL. The decryption of these subtitles has been taken from another Open Source software : youtube-dl. . Netflix . The user needs to input his username and password of Netflix in the userconfig.ini file. Netflix requires login to download the subtitles. . We use python-selenium browser to automate the process. The first step is to login to Netflix with the config file information. Chrome WebDriver is used as the driver for selenium. After a successful login from selenium browser, we request for the video URL. The chrome Network tab gives a list of resources fetched from the server. We use the command : return window.performance.getEntries(); This command returns all the fetched URL’s. It was observed that all the Netflix videos had this sub-string in common and it was unique. /?o So we query for /?o and let the browser fetch the resources until we find such a URL. If we do not find the URL before the time out, we exit the application. If such a URL is found we save the URL and follow the standard procedure. We request the URL using requests module and save the file. The module Netflix_XmlToSrt.py is used to convert XML to .srt format. . FOX . We first require the page source of the video. The function createSoupObject() is responsible for this. For this purpose we use the requests module. We parse the HTML with the help of BeautifulSoup library. . The video URL follows a specific standard throughout. ` http://www.fox.com/watch/684171331973/7684520448 ` We need to split and return “684171331973”. This is the required contentID. . This is the alternative method to obtain the contentID. In the soup text there is a meta tag which also contains the video URL. This is helpful in case the user inputs a shortened URL. . As stated above we split the URL and return the require contentID, 684171331973 The other parameters required for obtaining the subtitle URL are also present in the HTML page source. . The required script content looks like this- . jQuery.extend(Drupal.settings, {&quot;&quot;:...............}); . We add everything to a new string after encountering the first “{“. . | Remove the last parentheses and the semi-colon to create a valid JSON. —- ‘);’ The JSON has the standard format and the required parameters follow this naming. The json content : . {“foxProfileContinueWatching”:{“showid”:”empire”,”showname”:”Empire”},………….. “foxAdobePassProvider”: {……,”videoGUID”:”2AYB18”}} . | . We use the json module to parse the json and extract the parameters namely showid , showname , videoGUID . Sample Subtitle Links - http://static-media.fox.com/cc/sleepy-hollow/SleepyHollow_3AWL18_660599363942.srt http://static-media.fox.com/cc/sleepy-hollow/SleepyHollow_3AWL18_660599363942.dfxp . The standard followed is - http://static-media.fox.com/cc/[showid]/showname_videoGUID_contentID.srt http://static-media.fox.com/cc/[showid]/showname_videoGUID_contentID.dfxp . Some Subtitle URL’s follow this standard - http://static-media.fox.com/cc/[showid]/showname_videoGUID.dfxp http://static-media.fox.com/cc/[showid]/showname_videoGUID.srt . So we store both URL’s and check for both the varieties. We request both the varieties of URL and save the subtitles file when a successful request is returned. . General rules . Each service has a unique way of fetching the subtitles from the server. We can get to know the methodology by following some steps - . The easiest way is to first open the Developer tools in Chrome/Firefox and check for XHR requests. Generally we find the subtitle URL’s here. . | The next step is to find out a general pattern in the subtitle URL’s of that particular service. . | If a pattern is found, it is most likely that we can request the subtitle page by forming the URL’s from the required parameters. . | Generally, the parameters can be found in the HTML page source. We need to search for them and query the URL. . | Sometimes the required parameters for the URL are found in some other links in JSON format. A quick check of the fetched JSON resources will reveal the availability of them. . | For services such as Netflix, the parameters have some kind of hashing in them which is difficult to decrypt. In such cases we can use selenium browser and search for keywords like .srt, .dfxp, cc, sub . | By checking for multiple videos we can find out common sub-strings in the subtitle URLs. These common sub-strings(have to be unique) can be used for querying the resources from selenium browser. . | In most cases, the subtitle URL is fetched only if the user is logged in. So we first need to setup login and then go to the video URL in the WebDriver. . | The subtitles can then be downloaded from the URLs. . | . If you are a developer and want to add support for new services or fix bugs please feel free to send a pull request or contact me for further assistance. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-subtitle_extractor_technical_docs.html",
            "relUrl": "/2020/02/20/public-gsoc-subtitle_extractor_technical_docs.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Public:gsoc:sampleplatform",
            "content": "~~META: title = Google Summer of Code 2020 - The sample platform / Continuous integration revisited ~~ . The sample platform / Continuous integration . The sample platform was developed during GSoC ‘15 and overhauled during GSoC ‘16. In GSoC ‘17 another student added support for the Windows part, as well as some bugfixes. The student continued his work during GSoC ‘18, and will mentor this year. Last year a new student did some improvements and bugfixes. . This GCi edition we came to the conclusion that for new contributors, there are a bunch of drawbacks in the current system that make it no longer viable to continue to run the platform in it’s current form. . The two main issues are: . Long runtime if a lot of commits/PR’s are opened. This is because there is only one instance per OS available. | Unclear what the tests were being compared against. We should be able to have multiple approved versions and tell the user if the result deviates from those known ones. | . With a lot of different cloud offerings available and the launch of GitHub actions we want to iterate on the design of the Sample Platform, moving the infrastructure from a single dedicated server to a scalable service that can cope with the variations in load. . This will need an upfront survey of the existing functionality, followed by discussions with the mentor on how to implement this. . Features that will need to be implemented for certain are: . A coordinating platform that receives the call for actions, triggers the machines, displays results, … | Scalable Linux/Mac/Windows machines that can execute the regression tests (currently 180GB of samples!) | Deep integration with the GitHub Actions that should be run first (creating Linux, Windows, Mac builds), so that no time is wasted if there are compiler errors or no code changes. | Watch this video. Disregard that it’s about the Rust community - it’s the CD/CI part on it that is important to us. That’s what we want. | . Getting started / Requirements . The Sample Platform is written in Python, so we expect good knowledge of Python. The new project is not necessarily python-based, but the choice should be made based on maintainability (unit testing) and availability of third-party API’s and libraries. . Qualification . If you are interested in taking up this project during GSoC, you will need to satisfy these requirements (in order of importance, not all are a necessity): . A well researched, well written project proposal. This should include a monthly cost prediction based on expected runtime’s, disk storage used, … A comparison between multiple providers (e.g. Azure, GCP, AWS, Packet) must be included. | Have chatted with the mentor(s) at least once. | Fixed a bug, improved installation documentation, … (contributed something to the project). There are some issues in the tracker labeled issues labeled GSoC-proposal-task for this purpose. | Proof you’ve set up the Sample Platform locally. | . Additional information not necessarily well organized :-) . For each sample we currently have one “good” output. That’s not really correct. Changes in code might produce minor changes in the output (in the order of a few milliseconds). For each sample we’ll need to have a set of correct outputs (possibly with a “correctness score”). | When a pull-request is checked, our system now reports the number of “broken” samples, meaning how many samples are producing an incorrect output according to our “good output” list. This however does not help much determining how the output changes for this specific PR. Instead, the system needs to report the difference between the code before and after the changes in the PR, which is much more useful. | We’ll also need a way for final users to send test their own files against the current version so they don’t need us to release a new CCExtractor version that could fix something that is broken for them. | It should be possible for users to get a binary compiled by the new system, particularly for Windows (in linux we don’t have this problem since the typical way to install CCExtractor is just to build from source). Note that this build is already happening, so don’t worry much if you have zero interest on Windows :-) You can use what we already have in order to build. | We currently run all the tests for each PR. This is overkill. Instead, we should have different sets of tests, for example “only MP4 files”, or only “teletext”, and so on, and the developer should be able to decide which tests he needs to run his PR on (or maybe none, for example if he just edited the help screen). | One of the reasons we’re “going cloud” (as opposed to continue to run in one server) is the ability to scale and parallelize. It must be possible to check several PRs at the same time, different platforms, and so on. | We need to add a “regression finder” feature that works (and possibly uses) like git bisect: Give a specific sample find which specific commit changed the output. | . Mentor(s) . Willem Van Iseghem (@canihavesomecoffee on Slack) is a former GSoC student (2014, 2015, 2016) and mentor (2017, 2018, 2019). He started the project and is the official maintainer. | .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-sampleplatform.html",
            "relUrl": "/2020/02/20/public-gsoc-sampleplatform.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "Roku reference channel",
            "content": "Roku is currently the most common media streamer. It’s cheap and neutral (it’s not in any “fight”). Unfortunately, there aren’t any good open source channels, so if you want to start your own you have to start from scratch. We want to fix that by creating the “reference” source code for a generic channel. We will send a free Roku to our student for development. . What makes a good Roku channel? . For the playback itself Roku provides a basic system in which you have the usual things such as play/store, fast-forward and so on. But there’s no default context menu, the progress bar is horrible and looks really bad… . Organization must be flexible and complete. Don’t assume that things belong in just one place. For example you may want to have a section of Python tutorials, one of AI videos, one of videos in Spanish and so on. Of course there’s videos that belong in all three places. . The home page must be well designed and pleasant to the eye. It must be easy to navigate. . Recommendations, last played, search, settings, etc, must be easy to find and by themselves need to be good. Note that the recommendation themselves belong in a backend and you don’t need to implement the actual backend: You need to implement the connection to such backend though. . You also need to support “activation”, which is the process in which the user links his Roku to an account existing in the system, for example to get access (case of a non-free channel) or custom recomendations. . Your job is the Roku channel itself, but you must provide a backend skeleton at the very least to support all the channel features. . Qualification tasks Take a look at this page. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-rokuchannel.html",
            "relUrl": "/2020/02/20/public-gsoc-rokuchannel.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "Public:gsoc:realtimesubtitles",
            "content": "~~META: title = Google Summer of Code 2018 - Real time subtitles system ~~ This is our proof of concept demo for real time subtitles. . It’s fed in real time by a number of HDHomeRun tuners that are connected to CCExtractor, which in turn decodes the subtitles and uploads them to this system, which uses NodeJS among other things. . Right now, only monitoring web page is implemented (the one you see in demo), which is not intended to be used by end-users. During this summer you’ll have to design and implement a complete system, which should include: . Web pages, for displaying channels and real-time captions. UI sketches in the repository will give you ideas of which features are required. Additional features, listed below are also desired: | * Multilanguage support (for example, if the program comes with both English and Spanish subtitles we should allow to display both) * Sharing URL * Support for all display sizes and devices (&quot;responsiveness&quot;) 2. Administrator dashboard which allows to mange channels, captions, monitor the states of infrastructure components. The page you see in the demo should be a part of administrator dashboard. 3. Create a subsystem for analyzing a stream of cations in real-time and presenting its current topic and/or keywords. (Check https://github.com/rkuchumov/ccr/issues/13 for more details) . What should I do? . Check repository issues page. Submitting pull requests will definitely make you stand above other students. Note that for “enhancement” tasks you can submit PR, event if there’re already PRs by other students. . | Highlight all aforementioned tasks as well as tasks from GitHub in your proposal with as much details as possible. Do not forget that we select students with the best understanding and a vision of a project. . | Discuss the project with mentor and suggest new ideas. . | Don’t ask questions regarding installation and usage (it works fine). It only shows that you are incapable of reading the code and solving problems, we don’t need such developers. If you think there’s a bug in deployment stage, fix it and submit a pull request. . | . **Mentor** Ruslan Kuchumov (@kuchumovri on slack) is a former GSoC student (2014, 2015, 2016) and mentor (2017). He has done all the work so far so he’s the best possible mentor. . Repository Link : https://github.com/rkuchumov/ccr .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-realtimesubtitles.html",
            "relUrl": "/2020/02/20/public-gsoc-realtimesubtitles.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post12": {
            "title": "Extend rclone’s webui",
            "content": "rclone webui currently supports basic plugins like a video player and a music player. This functionality could be extended to incorporate new plugins which could be added by a user on the go, and developers could develop these plugins for rclone. . The functionality will be something similar to Google Drive. Ex. If you want to edit a doc file, rclone webui will have a plugin for it, once you enable the plugin, you would be able to edit documents using rclone. . Deliverables: . A plugin dashboard, where you can install, remove and update plugins. | A plugins repository from where the plugins could be fetched into the local rclone instance. | The plugins should work in an isolated environment so that they cannot interfere with the system data. | Develop at least 3 demo plugins for demonstration. This could be a word processor, a photo editor, etc. | We could allow the developer to communicate with their own server and fetch data from there. | Current Stack: rclone backend: GoLang rclone webui: Reactjs . URLs: rclone GitHub: https://github.com/rclone/rclone react frontend: https://github.com/rclone/rclone-webui-react rclone forum: https://forum.rclone.org/ webui discussion thread: https://forum.rclone.org/t/beta-testing-webgui-for-rclone/11156 . Qualification tasks Take a look at this page. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-rcloneweb2.html",
            "relUrl": "/2020/02/20/public-gsoc-rcloneweb2.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post13": {
            "title": "Public:gsoc:rcloneweb",
            "content": "Web interface for rclone . rclone is a fantastic cloud sync tool. As good as it is though it lacks a web interface. This is of course not a problem for geeks as rclone’s popularity proves. However, it is a problem for everyone else. . Your job is to create, possibly from scratch (feel free to look for previous efforts), the ultimate rclone web interface that makes it possible to do from it everything that should be doable of nothing that shouldn’t be doable. . What does that mean? It means that it should be possible to give access to your web interface to a good faith operator (for example, your mom) and not be possible for her to break anything unintentionally. This implies that roles will be necessary, so it’s possible to disable certain operations to users even if we trust the users (“as good people”). . Of course, it also means that a bad actor shouldn’t be able to use your system as a way to break anything other than rclone’s config, but nothing else in the host system (for example, no exec, etc). So yes, common sense :-) . GSoC is 3 months. This is quite a bit for time for a web interface to an existing product with a healthy community, but we are quite ambitious with the scope. It’s not a “basic” web interface what we want to contribute, but a complete one that becomes the reference one. Anything and everything that rclone supports your web interface must support. . It must also work behind a reverse proxy, by accepting the standard –baseurl parameter. For example, suppose you use Flask or any stand alone web framework that comes with its own web server and that your interface is available at . http://localhost:5000 . It must be possible to use a reverse proxy in a way that . https://example.com/rclone . can be mapped to http://localhost:5000/rclone and it works. . If you have experience with frameworks then you have probably seen it. If not, do a bit of research. It’s easy to implement, but you have to implement it. This is an essential requirement - users often want to use a separate web server to handle security, certificates and so on, and they don’t want to open a different port of each web interface. . Notes from Nick Craig-Wood . I have quite a few ideas on rclone web GUIs. I’ve been gradually fleshing out the API https://rclone.org/rc/ so that it can control rclone completely. . Rclone can also just run the remote control, serve files and open your browser with . rclone rcd --rc-serve --rc-noauth --rc-files /path/to/files . So that should be enough to build a remote control interface entirely with web technologies. The --rc-server means rclone can serve the remote files too. . I made a very proof of concept react app (to show that the rc API was usable by react), but that is as far as I got! . I stuck it on github here: https://github.com/ncw/rcloneguiexperiment . That is how I imagine development might go, but I could also imagine bundling a version of rclone with the web GUI packaged in, so you could just run rclone gui (or maybe even just double click) and get the web interface. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-rcloneweb.html",
            "relUrl": "/2020/02/20/public-gsoc-rcloneweb.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post14": {
            "title": "Program Flow Visualizer",
            "content": "Introduction . Read this and then come back here :-) . The Task . We want to build a complete profiler tool. During Google Code-in we created several proofs of concept, so we know it’s possible, and we also know that it’s a really good idea that got popular really fast. For reference, as you can see in the article linked above, five high school students created each their own implementation (by themselves) in around one month with really impressive results. . You can take their existing work (it’s open-source after all) and build upon it, or you can do your own thing. But of course, your product must demonstrate GSoC quality - you’ll be working full-time for 3 months :-) . Ideas . Explore use-cases other than algorithms (comment on Hacker News) . | Decorators to inform the debugger about the properties of user-defined data structures and classes . | Visualizations for more data structures: trees, linked lists, etc. . | Support for pausing, delays, and interactive messages, described via comments in the code . | Interactive web version (or just an output format) . | Flow control visualization, less of a focus on variables specifically (comment on Hacker News) . | Support for large target programs (multi-file projects) . | Integration with gdb and in general, support for other languages [if possible] . | Manual control keys (Play, pause, speed) . | Control flow chart (as an overview) . | Support for all types of objects in saved sessions, even those that cannot be serialized directly . | . This is another potential source of inspiration: https://github.com/hediet/vscode-debug-visualizer/tree/master/extension . Qualification tasks . In order to qualify for our projects, you must complete a qualification task or accrue sufficient qualification points from GitHub issues. . Take a look at this page for tasks oriented for people who are working on new projects like this one. Alternatively, you can go the traditional route of fixing GitHub issues on the main CCExtractor project, which is written in C. You can find more information about this here. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-pythonprofiler.html",
            "relUrl": "/2020/02/20/public-gsoc-pythonprofiler.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post15": {
            "title": "Public:gsoc:pythonbindings",
            "content": "~~META: title = Google Summer of Code 2018 - Write Python bindings for CCExtractor ~~ . Write Python bindings for CCExtractor . Extend Python to use CCExtractor’s library to access subtitles. You should export as much of CCExtractor as possible. At a minimum, it should be able to . Open and close input video streams. | For an open stream, get the list of programs. | For a selected program, get the subtitles in various easy to use structures. You need to provide access to the original representation (for example, if it’s US TV subtitles then a grid for CEA-608, if it’s European DVB subtitles then a bitmap) as well as the conversion to usual formats such as .srt. | . While CCExtractor itself uses its own library (lib_ccx), we are not aware of any other program using the library directly (as opposed to running CCExtractor and getting the generated file). This means - it’s likely you will also need to modify the library itself to make it “sane enough” for this project. . We will also be prefer to have Cython code written instead of simple Python wrappers during the program as they offer better speed and compatibility with our existing codebase. . **Related GitHub Issues** Make the Python Scripts to run Python3 Python Bindings don’t compile with build_library . **Related Github Commits** Make Python3 Compatible Code . Qualification tasks Take a look at this page. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-pythonbindings.html",
            "relUrl": "/2020/02/20/public-gsoc-pythonbindings.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post16": {
            "title": "Python extension module for CCExtractor",
            "content": "This is the main documentation of Python extension module for CCExtractor: . CCExtractor Library . Refactoring the codebase into a library . Earlier version of CCExtractor was compiled as a binary and could not be used as a library. The entire codebase was executed via a single main function defined in ccextractor.c and this architecture was not suitable for extending ccextractor source code to a library. Hence, many modifications were made to ccextractor.c so that conversion to a library could be done. Major modifications were: . Segmenting the larger functions into smaller functions so that they could be called from one main function. Earlier the entire processing was carried out from one main function itself. This was not a good idea considering the possibility for library. This would allow the user to set the parameters to be passed to CCExtractor from Python with one parameter at a time and not the entire list of all parameters together. | The refactoring of the code base and architectural judgements as to how the code should be segmented so that the entire working remains the same and also the library structure could be established. Apart from these changes, the header file ccextractor.h was also included into the codebase to define many global variables as well as the function declarations of definitions made in ccextractor.c. The major changes could be seen at this PR (merged). However, following the next stages of development after the changes made in the above mentioned PR, the final structure could be found at ccextractor.c and ccextractor.h. | Definitions made in ccextractor.h . In ccextractor.h, the major changes included declaring global variables which would be accessible throughout the codebase for calling the respective callbacks (discussed later in the documentation) from C to Python for processing the caption frames in Python as they are extracted in CCExtractor. The global variable was also used to keep a track of the start time and end time of caption frames so that the CE-608 grids belonging to the same frame could be clubbed together. The global variable array has been defined and the respective structure definition has also been done in ccextractor.h. . | The global variable array is an instance of this structure. The elements of the structure are PyObject* reporter, int sub_count and struct python_subs_modified* subs. The subs has been defined with start_time and end_time as its elements. More detailed description about why start_time and end_time have been used is given in the section describing about extractors. The main motivation for defining a global variable to catch hold of start time and end time of the caption frames as they are processed in CCExtractor is to identify the text, font and color grids (for CE-608 captions) that belong to the same caption frame. . | The major point to note is that the compilation of Python extension module includes setting a macro PYTHONAPI which acts as an indication that the compilation is made for Python extension module and this helps in declaring as well as defining the functions which are only needed for Python extension module. As defined here, the PYTHONAPI macro is used to define the functions/variables which are needed only by the extension module. . | Another major advantage of defining the macro PYTHONAPI is that the definitions made for Python extension module only need python-dev package as a prerequisite for compilation. However, if the user wants to compile only CCExtractor and not the Python extension module, then the code should not have python-dev package as a dependency. This has been attained by using macro PYTHONAPI and C pre-processors. . | . CCExtractor Python Extension Module . Extension module dependencies . 1. SWIG . For generation of the wrappers of the C code base, which would then be used to compile the extension module, I have used SWIG (swig-3.0.12). The entire compilation has been included in a build script (discussed later) and the user need not have prior knowledge of SWIG to get started. . | For compiling the Python extension module, the second dependency in addition to the dependencies of CCExtractor is SWIG. The user can follow these installation steps for getting SWIG installed. . | For generating the wrappers of the C/C++ code in a user required language, the user needs to have a basic understanding of the interface file which is used by SWIG. However, in case of generating the extension module for CCExtractor, the interface file has been written and is available here. SWIG uses this interface file to generate the wrappers for CCExtractor which are then compiled to form the extension module. . | . 2. Python-dev package . Overall architecture . The entire Python Extension module related work is done in the api/ directory with modifications to the CCExtractor codebase to integrate the divergent path, CCExtractor would take if the processing is done via Python module. | . Generating the Python extension module . For this project, I have mainly used two build scripts, viz., build_api and build_library which are both present in the api/ directory. For generating the Python bindings, user need to just run the build_library script as ./build_library. This would internally generate the SWIG wrappers from the SWIG interface file (ccextractor.i) present in the same directory. The user should note that if the user has not installed SWIG, the the compilation would stop at this step itself. Once the wrappers are generated, then the build_library script would execute the build_api script which would compile the entire code base of CCExtractor along with the wrappers generated by SWIG. In addition to this, build_api would also compile the extractors and wrappers defined in the extractors/ and wrappers/ directories respectively. Once the compilation is successful, then build_library would generate a shared library called _ccextractor.so from the entire code which would be shared object for the module. . | In addition to generating the wrapper codes generated by SWIG, it also outputs the ccextractor.py which would be later used as Python extension module for accessing CCExtractor functionality via Python. . | As mentioned in earlier section, the build_api compiles the entire code base with an option -DPYTHONAPI which is used by GCC to define a macro PYTHONAPI. This macro then acts as a signal telling that the extension module is being generated and the bindings dependency need a check as well as the bindings dependent functions need to be defined. . | . Workflow of Python extension module . The following section encompasses on the detailed description of the entire workflow of Python extension modules and the importance of each function in the codeflow. An example usage has been done in api_testing.py. . api_init_options . Function declaration- struct ccx_s_options api_init_options()* . This function returns an initialized instance of struct ccx_s_options which is modified in CCExtractor according to the values of the parameters provided by the user while executing CCExtractor. check_configuration_file . | . Function declaration- void check_configuration_file(struct ccx_s_options api_options) This function is used to check the configuration file and it takes the struct ccx_s_options instance as returned by api_init_options(). . api_add_param . Function declaration- void api_add_param(struct ccx_s_options api_options,char* arg)* . The api_add_param function is used to add user passed parameters to the struct ccx_s_options instance which would be used to compile the parameters and make the necessary modifications in the working of CCExtractor. . | This function takes the instance of struct ccx_s_options passed to check_configuration_file function and also, the string denoting the parameter passed by the user. . | The parameters are added to the python_params element of struct ccx_s_options and the count of the parameters is kept in python_param_count. . my_pythonapi . | . Function declaration- (depends on whether the compilation is done as CCExtractor binary or as extension modules) . The my_pythonapi is defined on the basis of how the compilation has been done by the user. If the user wants to use CCExtractor binary rather than the Python extension module, then this function is defined as #define my_pythonapi(args, func) set_pythonapi(args) with the set_pythonapi being defined in wrapper.c. . | However, if the user wants to build the extension module, then the definition of my_pythonapi is done as #define my_pythonapi(args, func) set_pythonapi_via_python(args, func) with the set_pythonapi_via_python function being defined in wrapper.c. . | Thus, it can been observed that my_pythonapi takes two arguments when the compilation is done as extension module. In both the case, the first argument is struct ccx_s_options instance as used by api_add_param. But in case of compiling the extension module, the my_pythonapi function takes a second parameter which is the python callback function that CCExtractor would call when passing values from C to Python (a detailed discussion about this has been done later). . | This function is not a mandatory function to call when using the CCExtractor binary. . compile_params . | . Function declaration- int compile_params(struct ccx_s_options *api_options,int argc) . The compile_params function mainly compiles all the parameters supplied by the user and modifies the elements of the api_options on the basis of the parameters supplied by the user. . | In this function, we add a dummy parameter ./ccextractor so that the parse_params function which is called from compile_params function properly compiles all the parameter except the first parameter as done in here. . | This function then returns the return value as obtained by the parse_params function. . call_from_python_api . | . Function declaration- void call_from_python_api(struct ccx_s_options *api_options) . The call_from_python_api function checks if the parameter -pythonapi was provided by the user. If the parameter was passed by the user then the global varable signal_python_api is set to 1 showing that the execution is done via Python modules; otherwise the value of signal_python_api is 0. . | In case of clarifications, the user does not explicitly need to pass the parameter -pythonapi. It is passed by the my_pythonapi function and thus used by call_from_python_api to set the signal_python_api to 1. . api_start . | . Function declaration- int api_start(struct ccx_s_options api_options) . This is the most important function of entire processing done by CCExtractor. After the entire compiling of parameters have been completed, then comes the stage when the actual processing is done. . | The api_start is the function which is majorly responsible for extracting the caption frames and passing them back to Python for processing. . | . The user should note that the codeflow discussed above till this point is generic to both CCExtractor binary as well as CCExtractor’s Python extension module. From this point onwards, the codeflow that has been described is mainly how the Python extension module accepts the caption frames via callback function and then processings done on the caption frames to generate the output subtitle file (.srt) via Python. . The api_start function in case of CE-608 captions calls a function general_loop for processing of the sample(video) that needs to be processed which in turn makes a call to encode_sub which encodes the subtitle buffer obtained from the sample. . | In encode_sub function, the sub_type is checked to be CE-608. If the sub_type is 608, then another check is made to check the value of signal_python_api. If the signal_python_api is set to 1, then a call to pass_cc_buffer_to_python is made. Otherwise, the processing continues as if the call for processing was made from CCExtractor binary. . | . From the pass_cc_buffer_to_python function, the call is made to the extractor function, then the extractor function in turns calls the callback function provided earlier via my_pythonapi function. The arguments given to the callback function are the ones corresponding to the information content of the caption frame which has been processed by CCExtractor. This information is accessed via the Python SRT generator scripts which would process the caption frames and write the processed information in the output subtitle files. The following sections would be sequential in-detail descriptions about how each process functions: . Python Encoder for CCExtractor . Following the architecture of CCExtractor’s codebase, a new file named ccx_encoders_python.c was added. The main reason of adding this file was to define the functions which would be called when the extraction process or CCExtractor extraction functionality is being performed via Python extension module. At this moment, since the extension module extends support only for CE-608 samples, only pass_cc_buffer_to_python function has been defined. Later on, when the binding’s support is extended to support other formats then in that case other functions like pass_cc_bitmap_to_python and others would be included in this file following the architecture of other encoders. | . pass_cc_buffer_to_python . Function declaration- int pass_cc_buffer_to_python(struct eia608_screen *data, struct encoder_ctx *context) . This is the function where the actual work of passing the extracted caption buffer to Python extension modules for processing the caption frames is done. . | The pass_cc_buffer_to_python function is called when the sample from which the caption frames are to be extracted is a CE-608 sample and the call for extraction is made from Python extension module. . | In this function, whenever a caption frame element is extracted, be it the srt_counter, caption timing information or any information related to the text, font or color grid of the CE-608 captions, then that information is passed to extractor function defined in extractors/ directory. A detailed description about how exactly the extractors function would be included in the next section. . | . Extractors for bindings . As documented in the previous section, when the extraction of CE-608 caption frames in done via Python, then the call is made to pass_cc_buffer_to_python function defined in ccx_encoders_python.c. In this function, after extracting lines in a caption frame (lines may belong to any of the text, font or color grid for CE-608), those lines are passed to python_extract_g608_grid function defined in extractors.c. | . python_extract_g608_grid . Function declaration- void python_extract_g608_grid(unsigned h1, unsigned m1, unsigned s1, unsigned ms1, unsigned h2, unsigned m2, unsigned s2, unsigned ms2, char buffer, int identifier, int srt_counter, int encoding)* . The main aim of using python_extract_g608_grid function is to able to identify the lines belonging to a particular frame and then passing these lines to the Python callback function with added identifiers for identification as to which CE-608 grid those lines belong to in a particular caption frame. More documentation about the identifiers and the nomenclature used for the bindings has been documented in the ‘Support for only CE-608 captions’ section and the user is advised to read that section to get a better understanding of the nomenclature. . | The arguments passed to python_extract_g608_grid include encoding which is the encoding that CCExtractor would have used to write the output subtitle file. Thus, the encoding is passed from CCExtractor to Python via the callback function so that the output subtitle file generated by Python would have the same encoding as the output generated by CCExtractor would have had. . | Out of all the arguments that are passed to the python_extract_g608_grid function, the one interesting argument is the identifier argument which has different values depending on the type of caption frame line it is called with. For example, if the line passed to python_extract_g608_grid function is a line belonging to its color grid, then the value of the identifier would be 2. Similarly, we have: identifier = 0 -&gt; adding start and end time | identifier = 1 -&gt; subtitle | identifier = 2 -&gt; color | identifier = 3 -&gt; font | . | This is how the python_extract_g608_grid function is able to generate the entire caption frame for a CE-608 sample along with timings. | . Callback Function architecture . When using the extension module, when a particular C function is called from Python, the control is transferred to C and returned to Python only after the execution of the function. However, according to the adopted architecture, a single function would process the entire sample and extract all the caption frames until the control is passed back to Python for processing the captions in Python. Thereupon, for further processing in Python the user would have had to wait until the end of the extraction of all the caption frames from the sample. This would violate the basic ideology that the module should be able to process the caption frames in Python as they are extracted in CCExtractor rather than waiting till the end of extraction from the entire sample. . | As a result of this, the callback function architecture was adopted. The main advantage of this architecture is that the moment a line from the caption frame is extracted the line is passed via a callback function to Python and the processing of the extracted line could be done in Python. . | In the present architecture, the user has a flexibility to tell CCExtractor which Python function would act as a callback function and a mechanism has been designed to convey this function to CCExtractor. This has been done with the use of my_pythonapi function as discussed in the previous sections. . | NOTE: In the api_testing.py, I have defined the callback function to be named callback. However, the user has complete freedom to define any name for the callback function. The user needs to note that the callback function would be getting nothing but a line from the caption frame that is extracted by CCExtractor. Further processing of the extracted line is the responsibility of the user. . | After defining the callback function, the user needs to make sure that this function is passed via Python to CCExtractor so that it can be used for callback. For doing so, the user needs to set the second argument of the function my_pythonapi as the callback function. This has been done in the api_testing.py script and the user can refer to it for example. . | A detailed description about why a single line of the caption frame is passed via the callback function and not the entire frame is described in detail in later sections. . | Also, when the user passes the callback function via Python to CCExtractor so the my_pythonapi function saves a pointer to this function as an element to a global structure, array, defined and declared in ccextractor.h. The element reporter holds the callback function passed by user via Python. . | Whenever the user wants to pass a line to the callback function then the user needs to call the function run which has been defined in ccextractor.c. . | . run . Function declaration- void run(PyObject * reporter, char * line, int encoding) . The run function takes two arguments and their description is as follows: The first argument is the callback function which the user passes via Python. According to present architecture, this callback function is contained by the element reporter contained in the global structure named array. So the first argument is array.reporter. | The second argument to the run function is the line which needs to be passed to Python. This is how the callback mechanism works for passing the lines from C to Python in real time. | . | . Processing output in Python . As described in the previous sections, the extension modules just return a single line from the caption frames. The processing of the caption frames to generate the output subtitle file is done in Python. . | A script to generate an output subtitle file from the extracted captions frames in Python has been written. The api_testing.py has a function named callback which acts as a callback function returning the extracted caption lines in Python. These lines then are passed to generated_output_srt in api_support.py described in the api/ directory. Thereupon, the function searches if the line has specific identifier which are used to decide how the output would be generated. A detailed section has been included in this documentation regarding the nomenclature used for processing different lines in CE-608 format caption fields (Support for only CE-608 captions section). The main reason for doing so is to avoid any buffering in C to hold the caption lines until the entire caption frames are extracted. This facilitates real time processing of the extracted caption frames. . | For getting the output filename from CCExtractor which would then be used to write the output srt file from Python, whenever the code is run from the extension module the first line that is passed via the callback function is the output filename generated by CCExtractor. This is incorporated by calling the callback function from init_write function defined in the src/lib_ccx/output.c file. The line passed to the callback function is of the format filename-&lt;name of the output file to be generated&gt; and this is then used to generate the output file. This line is then captured in the generate_output_srt function defined in the api_support.py. . | However, if the user wants the flexibility of defining the filename in a different manner, then for such outputs, the user must make changes in the generate_output_srt function to set the filename and ignoring the first line that appears in Python via the callback function. . | . Support for only CE-608 captions . //For understanding the CE-608 caption format, the user is advised to refer to this documentation on CE-608.// . The Python extension module is so far able to extract the captions frames from CE-608 samples. In samples with CE-608, the caption frames that are extracted by CCExtractor are in the form a 15x32 grid which depicts the screen. Thus, the information regarding the font of the captions, the colour they would be having on the screen as well as their alignment on the screen is captured in font,color and text grids respectively. . | Using Python modules each of such grids can be accessed in Python. However, as described in the previous section the callback function gets a single line and not the entire grid from CCExtractor, some processing needs to be done in Python for getting the user required grids per caption frames. . | The functions which would be acting as the processing and buffering functions for grid generations are present in the ccx_to_python_g608.py. The two major functions are return_g608_grid and g608_grid_former. The g608_grid_former is mainly used to form the grid from lines obtained at the callback function. . | The main advantage of the return_g608_grid function is that the user can generate whatever pattern the user desires to process in Python. For accessing various different combinations of the font, color and text grids in CE-608, a help_string has been defined in the return_g608_grid function in the ccx_to_python_g608.py file which describes on the value of mode to be passed to this function to get proper combination of the grids. . | In the earlier sections it has been stated that the callback function in Python is not passed with the entire caption frame but just one single line from the frame, a particular nomenclature has been devised to make sure that the lines belonging to the same caption frames are identified in the Python interface. The nomenclature is as follows: For every frame, the first line that is passed to the callback function is the srt_counter which indicates the identifier value of the caption frame that would be extracted next. | Following the srt_counter, the next line would contain a conjunction of the start time and end time of the caption frame with respect to the timings when the captions would be visible on the screen. The start_time and end_time would be conjuncted as start_time-&lt;start time&gt; t end_time-&lt;end time&gt; n and the user needs to process this line to get the timings. This processing in case of getting a srt file as an output has been done in the generate_output_srt function. | After the timings have been sent via the callback function, until the next srt_counter is extracted, the lines containing information about the color, font or text grids of CE-608 samples are passed via the callback function to Python. | For processing the grids separately, the color grid could be identified by identifying the presence of color[&lt;srt_counter value&gt;]:&lt;color grid line&gt; in the line obtained from the callback function. Similarly, for the font and text grids, the nomenclatures are font[&lt;srt_counter value&gt;]:&lt;font grid line&gt; and text[&lt;srt_counter value&gt;]:&lt;text grid line&gt; respectively. Processing a grid on the basis of such a nomenclature has been done in the g608_grid_former in the ccx_to_python_g608.py file. | After the entire caption frame has been sent via the callback function to Python for further processing, when the extraction of present caption frames finishes and CCExtractor shifts to a new frame, then a line containing END OF FRAME is passed via the callback function from C to Python. The user needs to catch this line in order to get the signal that from the next line onwards a new caption frame would begin. Similar approach has been implemented in the function generate_output_srt in the api_support.py file. This is how the entire CE-608 is transmitted to Python and the user needs to follow the nomenclature in order to get the caption frames in Python. | . | However, if the user thinks to modify the nomenclature in accordance with some other nomenclature that suits their use case, then the user can do so by editing the python_extract_g608_grid function in the extractor.c file. In this file, the user needs to find the lines where the function run is called with its first parameter being the callback function that is passed from Python and the second parameter being the line which is to be passed to Python. | . Wrappers for the extension module . In case of using an API, it is highly desired to set the parameters desired by the user not via command line but as call to built-in functions. This gave rise to the necessity of wrapper functions which can be called to set certain parameters for directing the functioning of the bindings. . | The wrappers have been defined in the wrapper.c file in api/wrappers/ directory. The user can use just call the wrappers to set some parameters. More wrappers can be defined according to the architecture followed in wrapper.c. . | The user needs to note that the wrappers can be called anytime in between adding parameters to CCExtractor instance (as done in api_testing.py) and before calling the compile_params function from the CCExtractor module. . | Another thing to note about the wrapper is that, the my_pythonapi wrapper function is a very important wrapper function. It tells CCExtractor that the call has been made using the Python module and thus the functioning of CCExtractor is altered. Hence, if the user intends to use the Python module the user is always advised to call this wrapper function with its first argument to be the object returned by api_init function from CCExtractor module and second argument being the callback function which would be called by the CCExtractor to pass the extracted caption lines back to Python. . | . Test Script . Once the Python module are generated then the user can use them by importing ccextractor module in Python. . | For testing the output of the bindings a test script, api_testing.py. But to mention, the module at this stage only supports generating a subtitle file from the CE-608 standard samples only. . | Another testing feature, that has been added is that the user can use recursive_tester.py to generate the subtitle files for all the samples from a directory. The only parameter needed to run this script is the location of all the samples. . | . Silent API . The Python bindings have been designed in such a way that the API is silent in itself as well as in the form of output generation. Silent in itself means that the API doesn’t write out any output to the STDOUT and the entire output of CCExtractor is silenced when the module is used for extraction of caption frames. This feature has been made possible by passing a parameter -pythonapi internally in api_testing.py using the function my_pythonapi() from the ccextractor module. The -pythonapi internally makes CCExtractor to silence all the outputs that could have been generated otherwise. . | If the user wants to add some print functionality from the CCExtractor, then may be defining the prints using printf C function could be an option. Note that the user cannot use the mprint function to get prints from the extension module from inside the CCExtractor C code part as used in CCExtractor to get the desired STDOUT prints as these are silenced via -pythonapi. . | . Work status . The proposal made by me for this project had a major component of multi-threading to let CCExtractor’s Python bindings run the CCExtractor’s extraction process in multi-threads. . | However, the end goal was modified while the GSOC 2017 coding period and after Second Phase Evaluation, the main aim was to create a Python extension module for CCExtractor which could process CE-608 video samples, extract the caption information present in them and pass this information to Python for further processing. The module was expected to be silent and the output generation from the caption information present in the video sample has to be done via Python. . | The present status of the extension module is that the module can extract caption information from CE-608 standard video samples and pass the caption information to Python. Further work has also been done to process this caption information to generate an output subtitle(srt) file (the user is advised to check completion of comparing_text_font_grids function sub-section under the future work section). . | . Future Work . Identifying the input format and raising errors if unsupported . CCExtractor does not process any non-video files. Similarly, the processing of non-video files is not supported by extension module. However, since the API has been designed to be silent, the module doesn’t output any error log stating that the input file is a non-video file and it cannot be processed. . | This is a much desired feature and the present version of CCExtractor extension module lacks this feature. I would be working on this feature post GSOC 2017 but if any user finds that this feature has not been added until they start contribution to CCExtractor’s extension module, then their work on this feature would be highly appreciated. . | For adding this feature to extension module, the extension module must be extended to process the return value from CCExtractor as done in the api_start function. When the sample (non-video) is processed via CCExtractor’s binary, then the processing is stopped by raising an ‘Invalid option to CCExtractor Library’ error. However, since the extension module has been designed to be silent, this error message is suppressed. Hence, the user should extend the test scripts to process the return value of api_start function in python extension module according to the constants defined in ccx_common_common.h. . | . Callback class mechanism . The present architecture uses a callback mechanism to pass the extracted caption lines from the caption frames of CE-608 captions to Python for further processing. In the callback mechanism, a callback function is supplied to CCExtractor in C via the my_pythonapi function which stores the callback function as a PyObject* in the global variable array. However, according to Python documentation on C-API, everything in Python is a PyObject; be it a function, a tuple or a class. . | So, the ideology is to replace the present callback function by a class which can have many methods that the user can use for different use cases. . | An example of such an implementation has been done here. The user needs to note that for accessing the Python class in C, some modifications need to be done to the run function defined in ccextractor.c and a sample example for calling a class method named ‘callback’ could be found here. . | Also, an important point to be noted in this case is that the user needs to pass the callback function’s name to run function in C so that the corresponding callback method of the class passed via my_pythonapi could be called via C. As an example, the callback method’s name has been provided here. . | For understanding the exact implementation of this approach, I would recommend the user to understand C-API for Python as the documentation is quite extensive to every use case. . | . Completion of comparing_text_font_grids function . The Python extension module for CCExtractor is able to pass lines of the caption frames for different grids of CE-608 captions. However, for generating the subtitle file from the caption grids, the text grid needs to be modified according to the color grid as well as font grid. In CCExtractor, this job is done at the function, get_decoder_line_encoded. . | For generation of subtitle files (.srt files) from Python, an equivalent version of get_decoder_line_encoded has been implemented in Python and has been defined as comparing_text_font_grids in python_srt_generator.py . | However, as the user can note that this function is not a complete implementation of get_decoder_line_encoded function, completion of this function’s definition is a matter of future work. . | . Adding more wrapper functions . As described in the ‘Wrappers for the extension module’ section, more wrapper functions are needed to be declared in the wrapper.c file. For example, few wrappers have been defined. More wrapper functions can be defined in a similar manner. | . Extending the module to support other caption formats . In this version, CCExtractor’s extension module supports processing of video samples having CE-608 standard captions in them and writing these captions to output subtitle (.srt) files. . | However, CCExtractor in itself has support for other caption standards like DVB, 708 etc. So, extension of module to extract of caption information from samples containing the caption information in these formats is a future task. . | The user should note that the information passed from CE-608 to Python is in raw form as lines which are then used to form the 608 grids. Similarly, the extension to other formats must consider passing the raw information of caption in respective format and then processing the information extracted by CCExtractor in Python. . | While extending, the architecture to be followed for ccx_encoders_python should be consistent to other encoders in the codebase to maintain uniformity. Thus for DVB samples, a function name pass_cc_bitmap_to_python and for 708 samples pass_cc_subtitle_to_python need to be declared in ccx_encoders_python.c. . | .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-python_extension_module_technical_documentation_gsoc_17.html",
            "relUrl": "/2020/02/20/public-gsoc-python_extension_module_technical_documentation_gsoc_17.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post17": {
            "title": "Compiling the Python Extension module for CCExtractor",
            "content": "Dependencies . The Python extension module for Python module has additional dependencies in comparison to the dependencies of CCExtractor. The documentation about the dependencies of CCExtractor can be accessed here. . | However, for compiling of the Python extension module for CCExtractor, the user needs to compile the following two dependencies: . | . SWIG . SWIG is used for generating the wrappers for C code in CCExtractor as well as for generating the module. The user needs to install SWIG or else the compilation of Python extension module will fail. For, compiling the source, the user can find useful resources here. . | For standard installation, for Ubuntu, the user can do sudo apt-get install swig (This has been tested on ubuntu-16.04 (xenial)). . | . Python-dev package . The Python-dev package is used by Python Extension module for accessing the functions and definitions made in C-API for accessing Python functions and other functionality. . | The user needs to install this package in addition to SWIG. The installation procedure is highly OS dependent and hence left at the user-end for exploration. . | . Installing the extension module . (This section is for contributors who want to compile the extension module without installing) . After the user has successfully installed the dependencies as stated in the above section, then the user can proceed to install the extension module via PyPI with the command: sudo pip install ccextractor or pip install ccextractor --user . | For installation in virtual environment however, the user may use pip install ccextractor . | . Compiling the extension module . (This section is for contributors who want to compile the extension module without installing) . For compiling the Python extension module, the user is needed to get a clone of the main repository for CCExtractor. . | The following are the exact steps to be followed after the clone of the main repository has been obtained by the user. * cd api (changing the current working directory to api directory) * ./build_library (running the build_library script) The entire compilation procedure is taken care of by the build_library script. . | After the compilation is successful, then the user would have ccextractor.py module along with _ccextractor.so in the api directory. Then the user can import this module. . | However, the point to be noted here is that the extension module has not been installed on the user system. It has just been compiled. So the user needs to import this module only from the api directory. . | . PyPI module . (This section is for contributors who want to upload the package to PyPI) . The PyPI module that has been uploaded has many things added to the CCExtractor code tree and all of this can be found here (branch - manifest_file). . | The contributor is advised to use the documentation at //‘An Introduction to Distutils’// and its subsequent parts to understand this section. . | The overall strategy or steps that have been followed to generate the distribution for being uploaded to PyPI is as follows: . | . Adding files to distribution and generating the distribution . All the files that are needed to be included in the package distribution are to be added the MANIFEST file as done here. For understanding the syntax used in MANIFEST file the user can check this documentation. . | After the MANIFEST file has been written properly, the user can generate the distribution package by the command python setup.py sdist . | This command would generate the distribution on the basis of MANIFEST file and place in the dist/ directory as a .tar.gz file until specified otherwise by the user. . | One thing to mention about the MANIFEST file is that it can only include files/folders from the folder it is defined within. It cannot include directories/files from parent directory or any other child directory. However, in the MANIFEST file I used, I have added the symlink to src main src directory so that the source code can be added to the package distribution via the MANIFEST file. . | . An analysis of the setup.py file used . The setup.py has been used to install the Python module on the user system. To understand what all the parameters mean in setup the user must refer to this documentation. . | The cmdclass defined at line is a very important part of the script as it internally makes call to the scripts included in package_build_scripts. A point to note is that this directory is used to include the scripts into the package distribution via the MANIFEST file. . | The scripts in package_build_scripts are the scripts which do the actual compilation of the source code to required python module and shared object. The user is advised to refer to build_library_package and build_api_package to understand how to compilation process takes place. The user may also refer to this documentation for understanding how the build scripts work. . | For any modifications made to the build scripts, viz, build_library and build_api corresponding modifications are to be made to the scripts included in package_build_scripts so that the compilation does not fail while installing the Python extension module. . | The ccextractor.i used in the package_build_scripts is an interface file used by SWIG to generate the wrapper codes. This is an essential part and should always be present with the distribution. . | . Uploading to PyPI . For uploading the extension module to Python, I have followed the exact steps mentioned at here. . | The GitHub repository which I used to host the tar as mentioned in the above link could be found here. . | However, there is no mandatory rule to continue hosting the source distribution from the same repository. If a user feels that a newer version for CCExtractor’s extension module is ready to be shipped, then he can follow the same steps from the link mentioned in first point of this section. In those steps, he can create a self-owned public repository and upload the module to PyPI. . | .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-python_extension_module_compilation_documentation_gsoc_17.html",
            "relUrl": "/2020/02/20/public-gsoc-python_extension_module_compilation_documentation_gsoc_17.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post18": {
            "title": "Public:gsoc:projectnephos",
            "content": "~~META: title = Google Summer of Code 2018 - Project Nephos: Cloud based storage for a massive collection of TV recordings ~~ . Project Nephos: Cloud based storage for a massive collection of TV recordings . There’s a lot of documentation on our close friend organization Red Hen (just Google them, or check out their ideas page), but for our purposes these are the basic ideas: . Red Hen is an informal (as in they’re tied by collaboration, not contracts) group of entities, most of them large universities, from many places around the world that share resources. These resources are hardware, software, media, knowledge, source code, people, and access to people. | Everything is open, there’s no NDAs in place, or proprietary software or anything like that. The one thing is that limited (to researchers and other people that can benefit from it) is access to the media repository due to concerns on copyright. | One of the things some universities do (and most want to do) is record as many local (to them) TV channels as they can and archive them. They are used for a long list of research and analysis topics, from language trends to body language analysis, to catch politics on lies and almost anything you can think of. | They use CCExtractor to generate transcripts of the media files. This is the original link between Red Hen and us, but since we met we have been collaborating on other overlapping interests. | . As mentioned, some universities record a large number of TV channels available locally to them, so UCLA records what they can get in Los Angeles, UNav what they can get in Navarra, Spain, and so on. Currently storage is either handled in-house, or it is uploaded to UCLA, where it is stored. As pointed out, this is all done on good will, not contract, but this is a bit besides the point. . We’ve reached a point in which storing these files locally is making less and less sense. Google offers unlimited storage for organizations that use Google Apps (their professional cloud suite, with GMail, Drive, and so on) which some universities such as UNav have. . The project during this summer is migrate to cloud storage, which will require creating a number of tools, modifying others, figuring out the best way to handle access permissions to the files in the cloud, general organization and so on. . Some of the must-have features are easy, for example when a recording is complete (and exists as a local file) it needs to be moved to Cloud. . Other things will need more work. Specifically: . Indexing. This is not a “index by date” or other trivial thing, we index by content. | Sharing, which needs to be as flexible as possible. In general everything needs to be automatic. For example config such as “share all Spanish TV content with these American universities”, etc. | Duplication, which means that content shared with us from another instance of Nephos can be copied to our own instance of Cloud storage. | Pre and post processes, for example to convert the original format to smaller versions, or to extract subtitles. | . Current source code. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-projectnephos.html",
            "relUrl": "/2020/02/20/public-gsoc-projectnephos.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post19": {
            "title": "Poor Man’s Textract",
            "content": "Introduction Amazon Textract a (paid) service that “automatically extracts text and data from scanned documents. Amazon Textract goes beyond simple optical character recognition (OCR) to also identify the contents of fields in forms and information stored in tables.”. We want to build a free alternative that provides an output of similar quality. . Your job First, you’ll need to find lots of documents to process around the internet. We will provide you some, but you need to build your own corpus. A few ideas: . Tax documents. | Multiple-choice exams. | Immigration forms. | Resumes. | Contracts. | Blueprints. | Order forms. | Invoices. | . … and many more. . Then create a system that is able to identify the parts of all those models, write some output (for example, a JSON file) that contains the coordinates of each of the parts, writes each part to a separate file, and OCRs whatever information can be OCR’ed and writes it to a database (which can be as simple as document storage or a full-fledged SQL instance of your preferred flavor). . We strongly recommend you play a bit with Amazon’s Textract (for online tests it’s free) to get an idea of what to expect. . To get you started a bit you may take a look at what the GCI students did during last Christmas break (which only works for one specific use case, but it’s a reasonable proof of concept): . Musab Kılıç’s exam analyzer RobOHt’s exam analyzer knightron0’s exam analyzer . Qualification tasks Take a look at this page. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-poormantextract.html",
            "relUrl": "/2020/02/20/public-gsoc-poormantextract.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post20": {
            "title": "Poor Man’s Rekognition (II)",
            "content": "Amazon Rekognition is a (paid) service that is able to identify objects, people, text, scenes, and activities in a picture. We want to produce a free alternative. . Last year we had a number of students working on this in parallel, which in itself was an experiment - we wanted to see if having several students in parallel try to do their own implementation would be better than just choosing the one we thought would best. . This year we are only going to select one. The first task is to get the best from last year (so you have to do some analysis of the existing implementations) and come up with ways to merge (or rewrite) and improve. Therefore the chosen student must do some homework in order to come up with a good proposal. Also check the current status of Rekognition. What new features would be great to have? Which features is Rekognition actually missing and we could add ourselves to make something better than Rekognition? . This is the description to last year’s project. . And here’s the links to all the projects (yes we know one of them is offline at this time): . https://medium.com/@amkr/final-work-submission-gsoc19-ccextractor-development-40a2b6c6a946 https://github.com/pymit/Rekognition . https://gitlab.com/drcpmkeyi/poor-man-rekognition . https://medium.com/@sziraqui/not-the-normal-gsoc-journey-d51a6167a3a6 . http://fedoskin.org/2019/08/24/gsoc-2019-poor-mans-rekognition/ . https://medium.com/@amkr/final-work-submission-gsoc19-ccextractor-development-40a2b6c6a946 . Qualification tasks . An important aspect of your proposal should be the report on which of the last year’s project is best or what part of each of them are best and should be reused in your projects. | Take a look at this page for more tasks. | .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-poormanrekognition2.html",
            "relUrl": "/2020/02/20/public-gsoc-poormanrekognition2.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post21": {
            "title": "Poor’s man Rekognition",
            "content": "Amazon Rekognition is a (paid) service that is able to identify objects, people, text, scenes, and activities in a picture. We want to produce a free alternative. . While being able to do everything Rekognition does over the course of a summer is unrealistic, we think we should be able to kickstart the effort and get to a point where the project will be usable and attract more developers to the effort. . Let’s start with faces, and this is the actual goal: Given a set of properly tagged people (suppose for example, a number of celebrities), create an API that can be used to identify such people in other images. . At a minimum . Your code must be able to run either locally or in a cloud service | The API needs to be callable from any language (so REST, or something similar) | You need to provide a native binding to a language of your choice | You will need to provide the sample images yourself (can be taken from the internet) | For any picture, it will identify the faces there, and for each face give a list of the most likely people from the known set in order of likeness | Must be able to learn from user feedback | . Video processing Building on the previous work, figure out a way to analyze a video and determine who is in each scene. For example if you detect a known actor in let’s say, 3:05, and the scene runs until 3:17, then that actor is there from 3:05 to 3:17. Generate a text file (any format) that lists who is in each scene. If possible, don’t brute force. . Notes . You can use any open source library to help with the project as long as it doesn’t prevent from meeting the full scope | . How to get started Since this is a new project we don’t have issues open on it. A good way to start, and what other students are doing, is to write a working proof of concept that shows you are capable to doing the full thing. And then come up with ideas and a plan to implement them during the summer. . Mentor Johannes Von Lochter &lt;johannes.lochter at facens d-o-t br&gt; (look him up) .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-poormanrekognition.html",
            "relUrl": "/2020/02/20/public-gsoc-poormanrekognition.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post22": {
            "title": "Public:gsoc:pipot",
            "content": "~~META: title = Google Summer of Code 2019 - PiPot (A micro honeypot for RPi) ~~ . PiPot (A micro honeypot for RPi) . PiPot was developed as part of a master thesis of one of the main contributors of CCExtractor. Due to time constraints it didn’t see a lot of love the last few years, and that’s where you could come in! . There is a “small” list of improvements that could be made to the platform, and which we’d love to see implemented, so that the platform is more usable in general. . The full list is available on the issues page of the main repository, but is not exhaustive. We’d also love to see some integrations with other existing honeypots. . Getting started / Requirements . The honeypot software is written in Python, so we expect good knowledge of Python. Basic HTML, Javascript &amp; CSS knowledge is also required. Bash scripting knowledge will also be required for the tasks. . We make use of quite some libraries, and we expect you to read up on the documentation of these platforms so you know how they work in general. . Qualification . If you are interested in taking up this project during GSoC, you will need to satisfy these requirements (in order of importance, not all are a necessity): . A well researched, well written project proposal. | Proof you’ve set up PiPot locally on a Raspberry Pi (preferred), or on your local PC. | Fixed a bug, improved installation documentation, … (contributed something to the project). | Have chatted with the mentor(s) at least once. | . Mentor(s) . Willem Van Iseghem (@canihavesomecoffee on Slack) is a former GSoC student (2014, 2015, 2016) and mentor (2017, 2018). He wrote the software for his Master thesis and is the official (and currently sole) maintainer. | .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-pipot.html",
            "relUrl": "/2020/02/20/public-gsoc-pipot.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post23": {
            "title": "Cross-platform Qt GUI",
            "content": "CCExtractor Cross-platform Qt GUI lets users not familiar with CLI to extract subtitles. Oleg implemented the application using [[https://www.qt.io/| Qt framework]], what makes possible to run it on Linux/Unix/MacOSX/Windows desktop platforms. Design of the application is based on previous windows-only version, but it was a bit redesigned to follow “Extracting subtitles has never been so easy” concept and be as user-friendly as possible. Some options were also added according to latest ccextractors’ features. . How to build and run . Qt version &gt;= 5.0 is required to build the application. There are two ways to build it: Using Qt Creator IDE and qmake automation build system. Download and install Qt Creator IDE for your platform. Open the project file and click “run”. This will build and run application. If you want to build it from console, run: . qmake make . After the application build process finishes, move the ccextractor binary file (named “ccextractor” on Unix/Linux/Mac, “ccextractor.exe” on Windows) into the directory that contains the GUI’s binary. . How to use GUI . Main window has 5 areas: . Main menu. Exit an application or check the about box. | Source selection area. Pick up input files or set stream url using one of tabs: Files (add/remove files to/from a list), Filesystem (browse filesystem and select one or more files) and Network (set url and port for UDP streams). | Summary area. Nothing could be edited by user in this area. Just a brief summary of options selected. It is impossible to show all options selected, so the most critical could be seen here. | Quick options area. If ccextractor supports any options, that GUI doesn’t support, you can type these options in Additional options field and they will be passed to ccextractor. | Execution area. Click Extract button to launch extraction process, Options button to edit options in Options window. After extraction process is finished, Log button becames enabled, so you can view the log in a default text file viewer. |",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-olegkisselef_qt_gui.html",
            "relUrl": "/2020/02/20/public-gsoc-olegkisselef_qt_gui.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post24": {
            "title": "CEA-708",
            "content": "CEA-708 is the latest standart for ATSC DTV closed captioning. DTVCC (DTV Closed Captions) decoding and output was improved by Oleg during this summer. Along with major refactoring, more control commands support was added. Now ccextractor can handle 16 bit encoded captions in DTVCC streams, so lots of non-latin languages symbols could be extracted. Output to popular subtitles formats such as SAMI, Transcript and Timed transcript was added. Colored and styled captions will be extracted with information about it (where applies). Rolling up DTVCC support was also implemented. . Technical Details . Work done is based on CEA-708-D specification. . Re-encoding characters is done using iconv. To make it work on Windows, win-iconv implementation is used. . To check what encodings/charsets are supported by iconv, visit libiconv website . How to use . There is a -svc (or –service) argument, that enables processing of DTVCC. Arguments’ value is a comma delimited numbers of streams, e.g. “1,3,62”. If it is known that one of the services contains 16-bit characters, then you can pass charset or encoding right after service number, e.g. “1[EUC-KR],3[EUC-CN],62”. . If you don’t know what services source video file contains, or you would like to extract all existing, you can pass “all” as an arguments’ value. To specify charset or encoding pass “all[CHARSET]”. . So, for example, to extract DTVCC from Korean sample, run: . $ ./ccextractor mbc.ts -svc 1[EUC-KR] . How to evaluate . Try to extract captions from files located in Korean708D, Cristiano708 and Cristiano708_2 directories on ccextractors’ ftp server. Korean samples store captions in EUC-KR encoding, so specify charset in services argument: -svc 1[EUC-KR]. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-olegkisselef_cea_708.html",
            "relUrl": "/2020/02/20/public-gsoc-olegkisselef_cea_708.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post25": {
            "title": "Public:gsoc:ocr",
            "content": "~~META: title = Google Summer of Code 2018 - Complete our OCR subsystem ~~ . Complete our OCR subsystem . Useful skills/interests: Image processing, Text Localization and Binarization, Tesseract API . Subtitles come in all shapes and colors. Some are text based (such as American closed-captions, as specified in CEA-608 and CEA-708, or the old European teletext). Others are bitmap based such as the European DVB. When subtitles use bitmaps they are a lot more flexible, but also a lot harder to transcribe. . For the Latin languages in DVB what we have works quite well. Note that while DVB is bitmap based, as least those bitmaps are separate from the main image, so you only need to OCR the bitmap to get the text. . However, there’s variants and cases that make things a lot more harder (and interesting): . Burned-in subtitles, in which they overlay the actual TV image. | Non-latin languages, such as Chinese. | Moving subtitles, such as the usual tickers on the screen that move from to side. | Subtitles with different colors, for example to distinguish between different speakers. | . Believe it or not some of these cases are also supported already in CCExtractor, at least for some “good” conditions. But the really hard ones, are still a job in progress. . The heavy lifting (the OCR itself) is done by tesseract. But selecting the area to process, prefilter it so tesseract gets an input it likes and so on, it’s done by our own code. . We need someone that likes challenges to make the whole thing work. . We will provide all the samples and access to a high speed server that has them so the student can work on it (optional) if a fast internet connection is not available to them. . **Related GitHub Issues** Extract cyrillic tickertape text in Russian from NTV Extract subtitles in a Chinese newscast GUI, Burned-in Subtitle Extraction not working jumps based on uninitialised values Process closed captions and burned-in subtitles in one pass DVB subtitles from China Corrupt or empty subtitles Terrible OCR results with Channel 5 (UK) . **Mentor** Abhinav Shukla (@abhinav95 on slack), which is the former Summer of Code student that worked on it last year and made an incredible job. . Qualification tasks Terrible OCR results with Channel 5 (UK) This task is ideal to get started, because you only need to deal with one function in one file: quantize_map() in src/lib_ccx/ocr.c . In addition to the samples that we already have, we would also like the creation of a dataset of a few hardsubbed (videos with burned-in subtitles) videos with the accurate timed transcripts so that we can evaluate the performance of our code on a wide variety of these real world samples. For the qualification task, this does not have to be huge. A good representative set will do fine. . Take a look at this page for more issues. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-ocr.html",
            "relUrl": "/2020/02/20/public-gsoc-ocr.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post26": {
            "title": "Mouseless for Linux",
            "content": "Introduction Mouseless is a nice tool to practice keyboard shortcuts for a few popular apps. Unfortunately it’s only available for Mac. We’d like to create an open-source Linux version that can be easily extended. . Your job We don’t want to clone Mouseless (we don’t have any relationship with their authors, and we don’t want to copy any of their work) - but the idea is good, and we think we can do a good job doing a tool that does a similar job of training users to use the mouse less and the keyboard more, but for the usual Linux tools. . We don’t know what’s the best technology is to build this, so we’re open to ideas. Just come up with a good plan, and a proof of concept for any Linux tool you like. . Qualification tasks Take a look at this page. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-mouseless.html",
            "relUrl": "/2020/02/20/public-gsoc-mouseless.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post27": {
            "title": "Public:gsoc:livetvooverinternet",
            "content": "~~META: title = Google Summer of Code 2018 - Add support for Live TV over the internet (such as YouTube TV) ~~ . Add support for Live TV over the internet (such as YouTube TV) . A number of platforms are appearing these days to distribute local TV content over the internet. For example, YouTube now has a live TV. Hulu does, too. . It’s still early days for these platforms - they’re trying to grab the business from the cable-cutters, while (possibly, for now) providing the same functionality, which is a live TV with DVR. It’s possible of course that they will offer lots of new features and they manage to replace over the air broadcasts, cable… . Anyway, we don’t know how they are implementing subtitles, and the task this summer is to . a) Do the research b) Write code that is able to create transcripts in the usual formats such as .srt . This code might be integrated with the current CCExtractor core or it could be a new tool. What’s best depends mostly on how the subtitles are distributed. If they are embedded in transport streams then integrating with CCExtractor would be the natural option. It’s part of the job to figure this out. . We’re going to target the two major platforms that have a live TV over the internet: YouTube and Hulu. . We will pay for the subscriptions for both services during the coding period, and if you are currently outside the geographical areas in which these services are available, we’ll provide a VPN as well. . Features that we expect: . The system must be completely scriptable. For example, a solution that requires human intervention to start a capture session, or a browser open on a desktop is not going to work. Suppose we want the system running 24x7 on a Linux server, which might not even have a monitor. | Youtube TV supports a maximum of 6 simultaneous streams per subscription. We don’t know about Hulu, but the point is that your solution must be able to maximize what we get from the subscription - if the service allows 6 streams, your solution must too. | Allow several subscriptions to be used as well, for example, if we want 12 streams, then 6x2 should work. | It goes without saying, login information should be configurable and you must be careful not to push any real information to GitHub. | Documentation must be good - we want other projects to build on this one instead of having to figure out everything from scratch. | . Qualification tasks Take a look at this page. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-livetvooverinternet.html",
            "relUrl": "/2020/02/20/public-gsoc-livetvooverinternet.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post28": {
            "title": "Public:gsoc:linuxtuning",
            "content": "Introduction The linux kernel has hundreds of tunable settings. Some can be modified on the fly with sysctl; others require reboots, loading modules and so on. . Your job Your job is to come up with a self-tuning system that does all the analysis it needs and finds the optimum settings to maximize throughput and/or latency for well defined workloads. One of the must be BitTorrent, since that one uses a lot of traffic and it can just be tested with real data instead of synthetic tests. . Qualification tasks Take a look at this page. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-linuxtuning.html",
            "relUrl": "/2020/02/20/public-gsoc-linuxtuning.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post29": {
            "title": "Public:gsoc:jokertv",
            "content": "~~META: title = Google Summer of Code 2018 - JokerTV integration ~~ . JokerTV integration . As you may know, our reference TV tuner has been for a long time the amazing HDHomeRun from Silicon Dust. They (all models) are rock-solid and they are really easy to integrate with. However, they don’t support DTMB (the Chinese standard). . This small thing is JokerTV (stand-alone version). . You can see in the tech specs that everything we care about is supported, and that the list of chipsets is published, and that source code for everything, including firmware, is available. . We are quite excited about the openness and potential of JokerTV and want to be the first to integrate with it. What should be the result of this integration? . CCExtractor would be able to communicate directly with JokerTV - getting the streams directly from it, as we do with the HDHomeRun. | You don’t need to decode DTMB (that’s a different GSoC project, possibly a summer worth of work) but your integration needs to be as region agnostic as possible. If JokerTV works everywhere, then so must JokerTV+CCExtractor. | It’s likely that JokerTV included support tools are not up to par with HDHomeRun’s yet. If this is the case (your proposal should show that you’ve done your homework and can tell us) reserve some time to work on this. | Another two major programs that could use JokerTV integration are FFmpeg and Kodi (for their live TV and DVR functionality). We love cross project ideas, including of course sending patches to their maintainers. If you think you would have time for this, give it some consideration. | . About getting a JokerTV - we will buy one for the student that takes on this task. We will also have a few more distributed in different regions around the world so remote testing is possible. . **Related GitHub Issues** Extract subtitles in a Chinese newscast . **Mentor** Abylay Ospan, the genius behind JokerTV himself. . Qualification tasks Take a look at this page. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-jokertv.html",
            "relUrl": "/2020/02/20/public-gsoc-jokertv.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post30": {
            "title": "Add Japanese support",
            "content": "Watch this video. . And then come with a plan :-) . Qualification tasks Take a look at this page. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-japanese.html",
            "relUrl": "/2020/02/20/public-gsoc-japanese.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post31": {
            "title": "Public:gsoc:interestingbits",
            "content": "~~META: title = Google Summer of Code 2018 - Detect Automatically the most interesting bits of sample videos ~~ . Detect Automatically the most interesting bits of sample videos . Write software that is able to detect, for some kind of videos, the most interesting bits (highlights). You can use: . Audio (for example, ) | Video (for example, detect high speed scenes or score changes) | Subtitles | . At a minimum, the following must be detected: . Goals in soccer (previous work exists; you can build on it or reimplement) | Three pointers in basketball | Jokes in sitcoms Plus any other 5 use cases you want to work on. | . Useful documents: [[http://www.lrec-conf.org/proceedings/lrec2016/pdf/927_Paper.pdf||Deep Learning of Audio and Language Features for Humor Prediction ]] .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-interestingbits.html",
            "relUrl": "/2020/02/20/public-gsoc-interestingbits.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post32": {
            "title": "Public:gsoc:ideas_page_for_summer_of_code_2020",
            "content": "~~META: title = Google Summer of Code (GSoC) 2020 ideas page ~~ . Google Summer of Code 2020 . Welcome to our ideas page. It’s great you want to start early. Please join us in our slack channel! (we’ll leave as an exercise to you to find it — it’s on our website). . This is going to be an amazing year — lots of new things to work on, including JokerTV, a totally open TV receiver, plus several experimental/for fun projects. Projects in C, Node.js, Python, Rust and more, you name it, we have it. Plus resources for students — we’ll give access to a high-speed server, all our samples (we’ll even ship a portable drive with them anywhere in the world, so don’t worry about slow connections) and various other perks. . You are welcome to check out the page (actual ideas at the bottom of the page, with each project having it’s own separate page as well) and start early in the community bonding process as well as learning a bit about our code ethics and practices. And of course, we’d love you to stay around even if we are not invited to GSoC or if we cannot invite you as a student. . The ideas we currently have . Important: If you have something else in mind that relates to subtitles and accessibility please get in touch. We prefer that you do something that you are passionate about even if it’s something we hadn’t considered. . After you check out our ideas please continue reading to the bottom of the page to get information about who we are, how we collaborate, what resources we will provide to you, etc. . Some tasks descriptions are still vague. We know that. Feel free to get in touch for questions, or just check their page from time to time. We will update the descriptions often. . Core subtitle tool (CCExtractor itself) | Name | Description | Tech you need to know | Tech you will learn | Difficulty | | —- | ———– | ——————— | ——————- | ———- | | Complete 708 support | This is one of the big ones. Why? Because it’s been on our wish list for some time and until now no one has decided to really go for it; after the initial work it’s always been incremental improvements, but no one has raised their hand and said “I’m going to complete this”. It’s possible the code base is not really friendly. Who knows. If this is the case we’re OK with a total rewrite if that’s what it takes to get this done. The details page has some more information if this picked your interest. This project is guaranteed to be selected if the proposal is good. | C | Video standards Subtitle standards CCExtractor internals Internationalization | Hard | | Add support for streaming Live TV | A number of streaming platforms now offer support for internet based live TV, which is great: It lets you watch TV on the go, it lets you get rid of cable, satellite and areal antennas… unfortunately, this live TV is not standardized at all. Your job is to do the work to add suport for Hulu and Youtube. We will pay for the subscription costs as well as any required infrastructure. | Any | Video standards Subtitle standards Live streaming platforms | Unknown | | Work on JokerTV integration | JokerTV is an excellent open hardware and software platform (/ccextractor-wiki-test/2020/02/20/think Arduino, but for TV). It’s still early days, and we really want to be among the first supporting this amazing new platform. JokerTV can receive signals from all TV standards around the world (/ccextractor-wiki-test/2020/02/20/finally!, no more European or American models, etc). We will buy one device for the student (/ccextractor-wiki-test/2020/02/20/or students, if their ideas are different) that works on this. Abylay Ospan, the genius behind JokerTV has agreed to mentor. | C | Hardware Video standards Joker (/ccextractor-wiki-test/2020/02/20/the platform) | Unknown | | Write Python bindings for CCExtractor | This was partially done during GSoC 2017, but the approach was totally wrong — a wrapper, instead of Cython. Let’s cut our losses and start over. | C Python | Obscure C+Python topics CCExtractor internals | Medium | | Add support for DTMB countries | DTMB is the standard for Chinese TV, also implemented by countries such as Cuba. What kind of student is ideal for this task? One with lots of analytic skills and patience. If you are one of those, don’t disregard this task just because you don’t speak (/ccextractor-wiki-test/2020/02/20/or maybe, even care) about Chinese. The experience on dealing with this will be extremely valuable in the future. We will use part of the organization funds to buy standard documents you might need, a capture device, and in general, anything required to make your life easier. | C | DTMB Video standards Hardware Research | Unknown | | Improve our OCR subsystem | We use tesseract to OCR bitmap based subtitles. In theory this is straight forward, but when you take into consideration all variants (/ccextractor-wiki-test/2020/02/20/color, languages, subtitles burned-in image, even moving text such as tickers) the complexity grows fast. Still, the work done by PhD students in the past is great, and we’re confident this year we can complete the work on this area if someone of the same caliber decides to join the effort. | C | Tesseract Imaging OCR | Suspected hard | | Add Japanese support | Captions are used by people all over the world on a regular basis. Most of us are familiar with regular horizontal captions at the bottom of the screen, but did you know that in Japan a common position for captions is vertically on the right or left side of the screen? Come learn more about what Japanese audiences need out of captions as well as how captioning standard likes IMSC and WebVTT support these features. | Japanese (/ccextractor-wiki-test/2020/02/20/or be good with foreign languages) | Depends | Suspected hard | . ** Artificial Intelligence and clever algorithms ** | Name | Description | Tech you need to know | Tech you will learn | Difficulty | | —- | ———– | ——————— | ——————- | ———- | | Poor man’s Rekognition (/ccextractor-wiki-test/2020/02/20/II) | Amazon Rekognition is a (/ccextractor-wiki-test/2020/02/20/paid) service that is able to identify celebrity faces in a picture. Last year we did some work towards creating a free alternative. This year we want to improve on the past work. | Your choice | AI Computer vision | Unknown | | Poor man’s Textract | Amazon Textract a (/ccextractor-wiki-test/2020/02/20/paid) service that “automatically extracts text and data from scanned documents. Amazon Textract goes beyond simple optical character recognition (/ccextractor-wiki-test/2020/02/20/OCR) to also identify the contents of fields in forms and information stored in tables.”. We want to build a free alternative that provides an output of similar quality. | Your choice | AI Computer vision /ccextractor-wiki-test/2020/02/20/OCR | Unknown | . ** Support tools we and other orgs use as part of their development process** | Name | Description | Tech you need to know | Tech you will learn | Difficulty | | —- | ———– | ——————— | ——————- | ———- | | The sample platform (/ccextractor-wiki-test/2020/02/20/- continuous integration) project | The sample platform is a good way to help new contributors to check if their code doesn’t introduce any regressions. It’s pretty stable, but is often hard to interpret for new contributors, and still pretty slow if the queue builds up. We want to take the concepts of this existing platform and re-write it from scratch making use of the horizontally scalable cloud options that are nowadays available. This project is guaranteed to be selected if the proposal is good. | Git Python | Cloud services API’s GitHub Actions GitHub API’s Continuous Integration (/ccextractor-wiki-test/2020/02/20/CI) Automated deployments GitHub integration | Medium/Hard | . ** New things we’re currently interested on ** | Name | Description | Tech you need to know | Tech you will learn | Difficulty | | —- | ———– | ——————— | ——————- | ———- | | A reference channel for Roku | Roku is currently the most common media streamer. It’s cheap and neutral (/ccextractor-wiki-test/2020/02/20/it’s not in any “fight”). Unfortunately, there aren’t any good open source channels, so if you want to start your own you have to start from scratch. We want to fix that by creating the “reference” source code for a generic channel. We will send a free Roku to our student for development. | None | Brightscript Roku Video Streaming | Medium | | An “algorithm video creator” in Python | During Google Code-in we got some proof of concepts that are actually quite cool. We want to build a complete tool that helps study and understand algorithms | Python | Python internals Algorithms | Medium | | FFmpeg + Rust | This project is two fold: One, is create proper Rust bindings into FFmpeg’s libraries. The 2nd, and harder, is create a “graph to code” generator | C or C++ | FFmpeg’s internals Rust | Possibly hard | | Extend rclone’s web UI (/ccextractor-wiki-test/2020/02/20/mentored by Nick Craig-Wood, rclone’s developer) | rclone is a fantastic tool to synchronize cloud storage. It’s rsync for the cloud. Last year we started a web UI, and it was a successful GSoC project. We want to continue working on it. | Cloud (/ccextractor-wiki-test/2020/02/20/lots) Web (/ccextractor-wiki-test/2020/02/20/different tech) | — | Medium | | SwagLyrics | Last Summer of Code, we came up with a platform to align lyrics to their temporal location in the audio (https://github.com/SwagLyrics/autosynch). This year, we want to improve it, and integrate it to SwagLyrics proper. | Python (/ccextractor-wiki-test/2020/02/20/mainly) | Depends on your idea | Medium to Unknown | | Vote counter and reporter | More and more countries depend on electronic vote counting and/or reporting in their elections, and apparently no one can get this right. Either no one knows how to do it or they know exactly what they are doing. Both things are worrying, to say the least. We want to spend this summer working on an open-source solution everybody and use and audit, in any country. | Systems design | Flutter (/ccextractor-wiki-test/2020/02/20/frontend), your choice (/ccextractor-wiki-test/2020/02/20/backend) | Hard | | Mouseless for Linux | Mouseless is a nice tool to practice keyboard shortcuts for a few popular apps. Unfortunately it’s only available for Mac. We’d like to create an open-source Linux version that can be easily extended. | Your choice | ?? | Unknown | | rutorrent mobile interface | rutorrent is the most popular web interface for rtorrent, which is possibly the most used BitTorrent client in linux. The job is to write a Flutter based web interface that uses rutorrent’s backend service to provide a native interface. | Flutter | BitTorrent | Medium | | The next peer-to-peer protocol | BitTorrent is of course the world’s most used peer to peer protocol. It’s great, but it was designed before the cloud was ubiquitous and it doesn’t make use of the places where you have the most storage or the most bandwidth. Can we design something for the next decade? | Depends | Peer-to-peer, cloud | Medium | | Linux tuning for network throughput | Come up with a system that tunes the linux kernel to maximize network throughput for a number of workloads, such as web server or BitTorrent | Linux | Kernel internals, Networking | Hard | . About us . We are a small org, which means that your contribution will have a large impact. It’s not going to mean a 0.5% improvement on a big project — it’s going to be more than 10% on a medium size one. If you like challenges and want a chance to shine this is your place. . We have -we think- statistically amazing continuity in the team: Most GSoC students from all the past years are still involved, even if they are no longer eligible as students. They still contribute code, and they mentor both in GSoC and the sister program GCI. As mentors, they also come to the Summer of Code summit which traditionally takes place in October. . We have mentors all over the world (/ccextractor-wiki-test/2020/02/20/North America, Europe, Asia and Australia), so time zones are never a problem. Our main channel of communication is a Slack channel to which everyone is welcome. We expect all accepted students to be available on Slack very often, even if you don’t need to talk to your mentor. This will help you ask questions when necessary, and you might be able to help others out as well while working on your project. . Exception: If your country (such as Russia) has banned Slack please get in touch in we’ll work out a solution with you. We absolutely want you to participate. . A mailing list is also available for those that prefer email over slack. It’s a new mailing list (the old one hasn’t been used in a long time) but it’s read by everyone involved in GSoC. . All our top committers will be mentoring. Many of them are former GSoC students or winners of GCI. . Perks . All accepted students get a programming book immediately after being accepted, with the hope that they read them before the coding starts. We want to see if this increases the quality of the work. So far we have selected these three books (pick one), but we’re open to suggestions: Clean Code, Elements of Programming Interviews in Python, Cracking the code interview. . We will also provide to all accepted students: . 6 months of access (from the acceptance date) to all courses in educative.io | 12 months of access (from the acceptance date) to backtobackswe, which is a fantastic resource to learn algorithms, prepare for coding interviews, and in general learn fundamentals. | . The student working on CEA-708 will also receive a copy of the latest CEA-708 specification document. . About what we use . This is what we use today. It doesn’t mean this is what we want to continue using. Probably not — we’re really open to change. We’re just describing the status quo so you know what you are getting into :-) . The core tool that names the organization (CCExtractor) is a command-line program written in C (not C++). . The current Windows GUI is written in C#, and we have another GUI for Linux that’s written with Qt, and a small GUI that’s integrated into the main program (C). In we’re being honest, nothing is great. Good news for you is that you can start over if you want. . The testing tool we use to run regression tests is mainly written in Python, but it also used Javascript, CSS and some shell scripting. The Test suite is written in C#. One of the projects this year is about replacing it. . The prototype real time subtitle website is written in NodeJS. . We also have a number of support tools that do a number of different things, from downloading subtitles from streaming services to translating them with Google Translate or DeepL. Most of them are written in Python, but since they are small tools that do their job you don’t need to worry much about them. . For totally new things you can use whatever tool you feel is best for the job. . About sample media and other resources . We work with huge files. Not all of them are huge, but many are. We know that many students don’t have access to high speed internet. To those students we will ship (as soon as they are selected) a portable hard drive with all our samples. So if your internet connection is not good, don’t worry — as long as you can plug a USB drive to your development computer you can participate with us. . We also have a shared Linux development server with lots of storage and a Gigabit uplink. Students get an account on it and they are welcome to use it. There’s nothing there except our own work, so it’s a trusted environment (for a server that is connected to internet of course). . The sample platform also hosts a bunch of samples, both which are small or decently sized. . Some projects have specific requirements: For example to add support for JokerTV you will need a physical JokerTV device. We will send one to the student that takes this project well before GSoC starts. The LiveTV project requires a subscription to YouTube with LiveTV (whatever it’s called this week) and Hulu. We will pay for those. If your project requires some cloud resources (Google Compute Engine, for example), we will pay for that, too. . In general, you are not expected to pay for anything (other than your own development computer and internet, of course) related to any project. . If you need anything not mentioned (such as a book) let us know. Within reason, we’ll help you. . About the projects and getting accepted . Qualification: Our selection system is based on several factors. Of course no student ranks in all criteria, so don’t worry when you read the list below. . Work on our core tool: Even if you are going to be working on something totally different. This might seen counter intuitive, but the thing is if you prove you can dig into our (messy) code base, find yourself your way around it, and fix a few bugs, you are just the kind of person we can trust to “figure things out”. GSoC is among other things, a learning experience. No matter what project you decide to work on, there’s going to be roadblocks, things you don’t know how to do, etc. So we really like it when students embrace those situations. . Qualification tasks specific to the project: The detail page for some projects contains specific qualification tasks that apply to them. . Contributions to existing open source projects: This can be anything. From a good GitHub profile to pull-requests sent to any other existing project, participation in hackathons, Google Code-In, past GSoCs and so on. . A good proposal: This is the one criteria that is non-negotiable. Your proposal has to be good, period. . Project popularity: Some ideas just have more competition, so if participating in GSoC is a top priority for you (over working on a specific project), consider applying to one of the “niche” ideas. After all, that’s a great way to get your foot in the door :-) . Best core tool tasks . We’re added a difficulty level to all our open issues on GitHub. Best thing you can do is head there and see if you are able to fix some of the easy ones and work your way up. We don’t expect you to be able to do the hard ones but we’d be impressed if you did :-) . For some of the easy ones you don’t even need to know C. Just being able to compile CCExtractor and dig around a bit will be enough. . The sample platform’s issues are tagged with “gsoc-proposal-task”, so you can easily see what you can work on. . Take home qualification tasks . If instead of working on existing code you’d prefer to show us your skills working on something new, you can pick one of these projects. . Community etiquette . It goes without saying that everyone in the community has to be polite and respectful, and consider everyone else a member of a team and not a competitor. . All developers are part of the team, by the way. Our Slack channel has mentors, code-in participants, other students, or developers and users that are none of the above but they all play some kind of role in CCExtractor’s community. . Part of being respectful is giving consideration to everyone else’s time. Most of us have day jobs, and as such are limited in the time we can use to guide you. We’d like to spend it on quality discussions, and not on things that are for example written on this website, things that you can easily retrieve by reading documentation on used libraries or on the software’s help screen. Asking this kind of questions in the Slack channel shows little respect for our time. This doesn’t mean you can’t ask questions, but remember that being a clueless user and a lazy developer are two very different things. If you ask those questions you will probably get an answer as if you were a clueless user (polite no matter what), but if you apply to GSoC you will be considered a lazy developer. Google is your friend ;) . Tell things as you see them. Politely -you’re not Linus-, but don’t sugar-coat it. We know some parts of our code is poorly written, poorly documented, etc. It stands out, so you will know when you dig in. No one is going to be offended by having that code rewritten or refactored. Peer review applies to everybody’s work and is done by everybody. . Cross project proposals . Because we use a number of libraries and in fact “are a library” ourselves (meaning other programs can link CCExtractor as a library, or invoke the binary) we interact with other communities and their software. From time to time there’s a chance to do something interesting that affects CCExtractor and something else (FFmpeg comes to mind, but also Kodi, VLC, libGPAC, Red Hen, to mention just a few of our friends that typically participate in Summer of Code). So how does this work? As long as the work benefits CCExtractor and it’s part of your summer project, we’re OK with you spending some time on the other project. For example if you are improving our MP4 support, for which we use libGPAC, and need to fix or improve something on libGPAC you are welcome to do so. If you do, make sure you submit your changes to their maintainers and follow through with their merge process. . Your proposal . You can propose to do any of the following ideas, or you can bring your own. In any case, make sure you run them by us before you actually submit your proposal. . At the very least your proposal needs to . Explain what you do want to do, why it is important to you (don’t make up a story here — the reason can be that you need it, that you just think it’s cool, that you have an itch to work on it, etc), and why it could be important or useful to us. | Explain how you intend to accomplish the goal, in enough detail that makes it clear that you have done your homework. For example, “I will modify the CCExtractor binary so that it’s able to convert audio to text with perfect accuracy” is the same thing as sending your proposal to the trash. You need to have a plan. | Detail the timeline explaining what the expected progress is for each week or every two weeks (pay special attention to the milestones within the GSoC timeline itself, of course) and how we should validate the results. | Detail what kind of support you will need from us. For example, if you are going to need test streams, hardware, access to a server, etc, let us know, so we can prepare everything for you as soon as possible. | Detail your expected working hours in UTC. We’re used to weird working schedules, so don’t worry about working in the middle of the night, or weekends instead of other days, etc. Knowing your hours may help us to match you better with a mentor. | Mention your planned absences. We don’t need you to detail what you will be doing when you are not working of course, but if you are going away for any reason we need to know so we don’t think you’ve abandoned. | Link to your GitHub (or any other repository) profile, if you have one, so we can take a look at your previous work. | GSoC is a coding program: This means that ideas that are about testing (unless it involves coding something to test our programs ;) ), website design, etc, are out. | However, we want to have good documentation: Make sure you have time to write a good technical article explaining your work. | Be realistic and honest with the timeline. Consider each week you should work around 30 hours. If your timeline reserves a lot of time for minor things we’ll think that you are not going to be working full-time in GSoC. On the other hand if you promise to do things in a lot less than that it seems realistic to us it will seem that you don’t really know how much work things take. | If you are going to be using 3rd party libraries (that’s OK), make sure to validate that their license is compatible with GPLv2 (which is ours). List the libraries in your proposal. Check that they are cross-platform. If you will need to extend those libraries in any way please explain. In this case, your proposal should include time to get that extension submitted to the maintainers (we love to contribute to other projects). | . Something else: Mentors often have their fingers in several pies. If you send the same proposal to several orgs everyone will know. So do yourself a favor and don’t do that. You can apply to several organizations and that’s totally fine, but each organization will want to see that you have put the time to write a great proposal that is focused on them. . Useful resources . A great resource for GSoC. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-ideas_page_for_summer_of_code_2020.html",
            "relUrl": "/2020/02/20/public-gsoc-ideas_page_for_summer_of_code_2020.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post33": {
            "title": "Public:gsoc:ideas_page_for_summer_of_code_2019",
            "content": "~~META: title = Google Summer of Code (GSoC) 2019 ideas page ~~ . Google Summer of Code 2019 . Welcome to our ideas page. This is going to be an amazing year - lots of new things to work on, including JokerTV, a totally open TV receiver, plus several experimental/for fun projects. Projects in C, Node, Python… you name it, we have it. Plus resources for students - we’ll give access to a high speed server, all our samples (we’ll even ship a portable drive with them anywhere in the world, so don’t worry about slow connections). . You are welcome to check out our ideas page (this is it - actual ideas at the bottom of the page) and start early in the community bonding process as well as learning a bit about our code. And of course, we’d love you to stay around even if we are not invited to GSoC or if we cannot invite you as a student. . ** About us ** . We are a small org, which means that your contribution will have a large impact. It’s not going to mean a 0.5% improvement on a big project - it’s going to be more than 10% on a medium size one. If you like challenges and want a chance to shine this is your place. . We have -we think- statistically amazing continuity in the team: Most GSoC students from all the past years are still involved, even if they are no longer eligible as students. They still contribute code, and they mentor both in GSoC and the sister program GCI. As mentors, they also come to the Summer of Code summit which traditionally takes place in October. . We have mentors all over the world (/ccextractor-wiki-test/2020/02/20/North America, Europe, Asia and Australia), so time zones are never a problem. Our main channel of communication is a Slack channel to which everyone is welcome. We expect all accepted students to be available on Slack very often, even if you don’t need to talk to your mentor. This will help you ask questions when necessary, and you might be able to help others out as well while working on your project. . Exception: If your country (such as Russia) has banned Slack please get in touch in we’ll work out a solution with you. We absolutely want you to participate. . A mailing list is also available for those that prefer email over slack. It’s a new mailing list (the old one hasn’t been used in a long time) but it’s read by everyone involved in GSoC. . All our top committers will be mentoring. Many of them are former GSoC students or winners of GCI. . ** Books / other references** . This year we’re going to try something new. All accepted students will get a programming book immediately after being accepted, with the hope that they read them before the coding starts. We want to see if this increases the quality of the work. So far we have selected these three books (pick one), but we’re open to suggestions: Clean Code, Elements of Programming Interviews in Python, Cracking the code interview. . The student working on CEA-708 will also receive a copy of the latest CEA-708 specification document. . ** About what we use ** . The core tool that names the organization (CCExtractor) is a command-line program written in C (not C++). The current Windows GUI is written in C#, and we have another GUI for Linux that’s written with Qt, and a small GUI that’s integrated into the main program (C). The testing tool we use to run regression tests is mainly written in Python, but it also used Javascript, CSS and some shell scripting. The Test suite is written in C#. The prototype real time subtitle website is written in NodeJS. We also have a number of support tools that do a number of different things, from downloading subtitles from streaming services to translating them with Google Translate or DeepL. Most of them are written in Python, but since they are small tools that do their job you don’t need to worry much about them. For totally new things you can use whatever tool you feel is best for the job. . ** Support tool** . If for any reason you want to show us your desktop or we want you to take a look at one of the mentors we’ll use getsee (no account needed and free). Feel free to take a look at it in advance. . ** About sample media and other resources ** . We work with huge files. Not all of them are huge, but many are. We know that many students don’t have access to high speed internet. To those students we will ship (as soon as they are selected) a portable hard drive with all our samples. So if your internet connection is not good, don’t worry - as long as you can plug a USB drive to your development computer you can participate with us. . We also have a shared Linux development server with lots of storage and a Gigabit uplink. Students get an account on it and they are welcome to use it. There’s nothing there except our own work, so it’s a trusted environment (for a server that is connected to internet of course). . The sample platform also hosts a bunch of samples, both which are small or decently sized. . Some projects have specific requirements: For example to add support for JokerTV you will need a physical JokerTV device. We will send one to the student that takes this project well before GSoC starts. The LiveTV project requires a subscription to YouTube with LiveTV (whatever it’s called this week) and Hulu. We will pay for those. If your project requires some cloud resources (Google Compute Engine, for example), we will pay for that, too. . In general, you are not expected to pay for anything (other than your own development computer and internet, of course) related to any project. . If you need anything not mentioned (such as a book) let us know. Within reason, we’ll help you. . ** About the projects and getting accepted ** . Qualification: On top of -of course- the quality of the proposal, we will be ranking students with a points system (we introduced this two years ago, and it worked pretty well). . We don’t have a minimum number of required points, but you definitely will need some (with equally good proposals we will rank based on acquired points). This means, the more points you get the more likely you are to be invited to join us during the summer, assuming that your proposal is good. . You can get points by doing one (or more) of the next options: . 1) By solving issues in our GitHub issue tracker (CCExtractor), Sample platform issues (default 1 points per issue unless specified somewhere in the issue page). Most issues have an explicit number of points that you can find in a comment. 2) By joining the community in Slack. You can invite yourself here. (/ccextractor-wiki-test/2020/02/20/1 point) 3) If you are a former Code-in finalist you start with 1 point. If you were a winner, you start with 2 points. Note that there are just a few developers that meet this, so don’t be discouraged if you aren’t one of them. Almost no one is, but we’d love to hear from those that are. 4) By sending us a TV sample that has something we don’t support. It doesn’t have to be from your own country (since hopefully, we already support it), but if it is, so much the better. This is probably hard to get, since we already got all the low hanging fruit. But if your local TV has subtitles you can turn on and off, we’d love a recording. . ** Best qualification tasks ** . If you don’t don’t know which issues in GitHub to do, here’s a list of the ones that are approachable (you don’t need to dig too deep or learn many parts of the code) and useful: . Terrible OCR results with Channel 5 (UK) CCExtractor won’t extract subtitles from TS with no PAT/PMT Automatically switch to correct encoding for 708 subtitles based on PMT data Request: Allow to extract several teletext pages in one pass ‘live’ raw data problem Extract telemetry data (which is stored in a subtitle track) from a Drone recording Extract EIA-608 subtitles from Matroska (.mkv) . The sample platform’s issues are tagged with “gsoc-proposal-task”, so you can easily see what you can work on. . ** Community etiquette ** . It goes without saying that everyone in the community has to be polite and respectful, and consider everyone else a member of a team and not a competitor. . All developers are part of the team, by the way. Our Slack channel has mentors, code-in participants, other students, or developers and users that are none of the above but they all play some kind of role in CCExtractor’s community. . Part of being respectful is giving consideration to everyone else’s time. Most of us have day jobs, and as such are limited in the time we can use to guide you. We’d like to spend it on quality discussions, and not on things that are for example written on this website, things that you can easily retrieve by reading documentation on used libraries or on the software’s help screen. Asking this kind of questions in the Slack channel shows little respect for our time. This doesn’t mean you can’t ask questions, but remember that being a clueless user and a lazy developer are two very different things. If you ask those questions you will probably get an answer as if you were a clueless user (polite no matter what), but if you apply to GSoC you will be considered a lazy developer. Google is your friend ;) . Tell things as you see them. Politely -you’re not Linus-, but don’t sugar-coat it. We know some parts of our code is poorly written, poorly documented, etc. It stands out, so you will know when you dig in. No one is going to be offended by having that code rewritten or refactored. Peer review applies to everybody’s work and is done by everybody. . ** Cross project proposals ** . Because we use a number of libraries and in fact “are a library” ourselves (meaning other programs can link CCExtractor as a library, or invoke the binary) we interact with other communities and their software. From time to time there’s a chance to do something interesting that affects CCExtractor and something else (FFmpeg comes to mind, but also Kodi, VLC, libGPAC, Red Hen, to mention just a few of our friends that typically participate in Summer of Code). So how does this work? As long as the work benefits CCExtractor and it’s part of your summer project, we’re OK with you spending some time on the other project. For example if you are improving our MP4 support, for which we use libGPAC, and need to fix or improve something on libGPAC you are welcome to do so. If you do, make sure you submit your changes to their maintainers and follow through with their merge process. . ** Your proposal ** . You can propose to do any of the following ideas, or you can bring your own. In any case, make sure you run them by us before you actually submit your proposal. . At the very least your proposal needs to . Explain what you do want to do, why it is important to you (don’t make up a story here - the reason can be that you need it, that you just think it’s cool, that you have an itch to work on it, etc), and why it could be important or useful to us. | Explain how you intend to accomplish the goal, in enough detail that makes it clear that you have done your homework. For example, “I will modify the CCExtractor binary so that it’s able to convert audio to text with perfect accuracy” is the same thing as sending your proposal to the trash. You need to have a plan. | Detail the timeline explaining what the expected progress is for each week or every two weeks (pay special attention to the milestones within the GSoC timeline itself, of course) and how we should validate the results. | Detail what kind of support you will need from us. For example, if you are going to need test streams, hardware, access to a server, etc, let us know, so we can prepare everything for you as soon as possible. | Detail your expected working hours in UTC. We’re used to weird working schedules, so don’t worry about working in the middle of the night, or weekends instead of other days, etc. Knowing your hours may help us to match you better with a mentor. | Mention your planned absences. We don’t need you to detail what you will be doing when you are not working of course, but if you are going away for any reason we need to know so we don’t think you’ve abandoned. | Link to your GitHub (or any other repository) profile, if you have one, so we can take a look at your previous work. | GSoC is a coding program: This means that ideas that are about testing (unless it involves coding something to test our programs ;) ), website design, etc, are out. | However, we want to have good documentation: Make sure you have time to write a good technical article explaining your work. | Be realistic and honest with the timeline. Consider each week you should work around 30 hours. If your timeline reserves a lot of time for minor things we’ll think that you are not going to be working full-time in GSoC. On the other hand if you promise to do things in a lot less than that it seems realistic to us it will seem that you don’t really know how much work things take. | If you are going to be using 3rd party libraries (that’s OK), make sure to validate that their license is compatible with GPLv2 (which is ours). List the libraries in your proposal. Check that they are cross-platform. If you will need to extend those libraries in any way please explain. In this case, your proposal should include time to get that extension submitted to the maintainers (we love to contribute to other projects). | . Something else: Mentors often have their fingers in several pies. If you send the same proposal to several orgs everyone will know. So do yourself a favor and don’t do that. You can apply to several organizations and that’s totally fine, but each organization will want to see that you have put the time to write a great proposal that is focused on them. . __The ideas we currently have__ . Important: If you have something else in mind that relates to subtitles and accessibility please get in touch. We prefer that you do something that you are passionate about even if it’s something we hadn’t considered. . Core subtitle tool (CCExtractor itself) | Name | Description | Tech you need to know | Tech you will learn | Difficulty | | —- | ———– | ——————— | ——————- | ———- | | Add support for streaming Live TV | A number of streaming platforms now offer support for internet based live TV, which is great: It lets you watch TV on the go, it lets you get rid of cable, satellite and areal antennas… unfortunately, this live TV is not standardized at all. Your job is to do the work to add suport for Hulu and Youtube. We will pay for the subscription costs as well as any required infrastructure. | Any | Video standards Subtitle standards Live streaming platforms | Unknown | | Complete 708 support | This is one of the big ones. Why? Because it’s been on our wish list for some time and until now no one has decided to really go for it; after the initial work it’s always been incremental improvements, but no one has raised their hand and said “I’m going to complete this”. It’s possible the code base it’s not really friendly. Who knows. If this is the case we’re OK with a total rewrite if that’s what it takes to get this done. The details page has some more information if this picked your interest. This project is guaranteed to be selected if the proposal is good. | C | Video standards Subtitle standards CCExtractor internals Internationalization | Hard | | Work on JokerTV integration | JokerTV is an excellent open hardware and software platform (/ccextractor-wiki-test/2020/02/20/think Arduino, but for TV). It’s still early days, and we really want to be among the first supporting this amazing new platform. JokerTV can receive signals from all TV standards around the world (/ccextractor-wiki-test/2020/02/20/finally!, no more European or American models, etc). We will buy one device for the student (/ccextractor-wiki-test/2020/02/20/or students, if their ideas are different) that works on this. Abylay Ospan, the genius behind JokerTV has agreed to mentor. | C | Hardware Video standards Joker (/ccextractor-wiki-test/2020/02/20/the platform) | Unknown | | Write Python bindings for CCExtractor | This was partially done during GSoC 2017, but it’s not complete. You may choose to continue the work already done, or you can come up with a more robust / fast / etc approach. What we currently have “sort of works” but we’ve seen leaks, crashes… so it’s definitely not production ready. | C Python | Obscure C+Python topics CCExtractor internals | Medium | | Write high speed subtitle synchronization tools | This one must be hard - it’s the one project that unfortunately failed during 2017, even though it’s a really interesting one that touches many areas (/ccextractor-wiki-test/2020/02/20/math, sound analysis…). We can provide you all the work done last year (/ccextractor-wiki-test/2020/02/20/including the winner’s proposal and current code) or you can start over. | Your choice | Audio Video formats Optimization Algorithms | Hard | | Add support for DTMB countries | DTMB is the standard for Chinese TV, also implemented by countries such as Cuba. What kind of student is ideal for this task? One with lots of analytic skills and patience. If you are one of those, don’t disregard this task just because you don’t speak (/ccextractor-wiki-test/2020/02/20/or maybe, even care) about Chinese. The experience on dealing with this will be extremely valuable in the future. We will use part of the organization funds to buy standard documents you might need, a capture device, and in general, anything required to make your life easier. | C | DTMB Video standards Hardware Research | Unknown | | Improve our OCR subsystem | We use tesseract to OCR bitmap based subtitles. In theory this is straight forward, but when you take into consideration all variants (/ccextractor-wiki-test/2020/02/20/color, languages, subtitles burned-in image, even moving text such as tickers) the complexity grows fast. Still, the work done by PhD students in the past is great, and we’re confident this year we can complete the work on this area if someone of the same caliber decides to join the effort. | C | Tesseract Imaging OCR | Suspected hard | . ** Artificial Intelligence and clever algorithms ** | Name | Description | Tech you need to know | Tech you will learn | Difficulty | | —- | ———– | ——————— | ——————- | ———- | | Poor’s man Rekognition | Amazon Rekognition is a (/ccextractor-wiki-test/2020/02/20/paid) service that is able to identify celebrity faces in a picture. We want to produce a free alternative. | Your choice | AI Computer vision | Unknown | . ** Support tools we and other orgs use as part of their development process** | Name | Description | Tech you need to know | Tech you will learn | Difficulty | | —- | ———– | ——————— | ——————- | ———- | | The sample platform (/ccextractor-wiki-test/2020/02/20/- continuous integration) project | The sample platform is a good way to help new contributors to check if their code doesn’t introduce any regressions. It’s pretty stable, but has some downsides that have been known for a while and that should finally be solved. Most of the items that are on the issue list (see the issues page) should all be solvable in less than a summer… The main focus this year should be on improving the comparison mechanism to determine regressions. | Python (/ccextractor-wiki-test/2020/02/20/majority) C# | Continuous Integration (/ccextractor-wiki-test/2020/02/20/CI) Automated deployments GitHub integration | Medium | . ** Cool things that use CCExtractor ** | Name | Description | Tech you need to know | Tech you will learn | Difficulty | | —- | ———– | ——————— | ——————- | ———- | | The Real time subtitles project | We have a great proof of concept on real time subtitles. It’s rock solid (/ccextractor-wiki-test/2020/02/20/except when we’re working on it), and we’re really proud of it. The part of sending the subtitles to the website is completed as you can see, but of course we need more functionality added to it. Which functionality? We’d like to hear proposals. Obvious things such as adding everything to a searchable database come to mind, but that’s not really a summer worth of work. So come up with 3 months worth of improvements you can think of. | NodeJS Web | Depends on your idea | Medium | . ** New things we’re currently interested on ** | Name | Description | Tech you need to know | Tech you will learn | Difficulty | | —- | ———– | ——————— | ——————- | ———- | | Improve PiPot | PiPot (/ccextractor-wiki-test/2020/02/20/Micro Honeypot for RPi) is a flexible honeypot for (/ccextractor-wiki-test/2020/02/20/industrial) environments that runs on a Raspberry Pi. We want to reduce the amount of open issues, which include new features | Python (/ccextractor-wiki-test/2020/02/20/majority) Bash | Security concepts | Medium to Hard | | Create a web interface for rclone (/ccextractor-wiki-test/2020/02/20/mentored by Nick Craig-Wood, rclone’s developer) | rclone is a fantastic tool to synchronize cloud storage. It’s rsync for the cloud. Amazing as it is it lacks a web interface. Your job is to create a great one. Really great. Not just a wrapper around the command line tool. | Cloud (/ccextractor-wiki-test/2020/02/20/lots) Web (/ccextractor-wiki-test/2020/02/20/different tech) | - | Medium | | SwagLyrics for Spotify | Fetches the currently playing song from Spotify on Windows, Linux and macOS and displays the lyrics in the command-line or in a browser tab. Refreshes automatically when song changes. The lyrics are fetched from Genius. Mainly built on Python and Flask but also uses HTML, CSS, JS, AppleScript and SQL under the hood. Of course we need more functionality added to it. Which functionality? We’d like to hear proposals. Things such as syncing lyrics to the song come to mind, but we want to hear what you can come up with. So come up with 3 months worth of improvements you can think of. | Python (/ccextractor-wiki-test/2020/02/20/mainly) Flask | Depends on your idea, some Web (/ccextractor-wiki-test/2020/02/20/different tech) | Medium to Unknown | .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-ideas_page_for_summer_of_code_2019.html",
            "relUrl": "/2020/02/20/public-gsoc-ideas_page_for_summer_of_code_2019.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post34": {
            "title": "Public:gsoc:ideas_page_for_summer_of_code_2018",
            "content": "~~META: title = Google Summer of Code (GSoC) 2018 ideas page ~~ . Google Summer of Code 2018 . Welcome to our ideas page. This is going to be an amazing year - lots of new things to work on, including JokerTV, a totally open TV receiver, plus several experimental/for fun projects. Projects in C, Node, Python… you name it, we have it. Plus resources for students - we’ll give access to a high speed server, all our samples (we’ll even ship a portable drive with them anywhere in the world, so don’t worry about slow connections). . You are welcome to check out our ideas page (this is it - actual ideas at the bottom of the page) and start early in the community bonding process as well as learning a bit about our code. And of course, we’d love you to stay around even if we are not invited to GSoC or if we cannot invite you as a student. . ** About us ** . We are a small org, which means that your contribution will have a large impact. It’s not going to mean a 0.5% improvement on a big project - it’s going to be more than 10% on a medium size one. If you like challenges and want a chance to shine this is your place. . We have -we think- statistically amazing continuity in the team: Most GSoC students from all the past years are still involved, even if they are no longer eligible as students. They still contribute code, and they mentor both in GSoC and the sister program GCi. As mentors, they also come to the Summer of Code summit which traditionally takes place in October. . We have mentors all over the world (/ccextractor-wiki-test/2020/02/20/North America, Europe, Asia and Australia), so time zones are never a problem. Our main channel of communication is a Slack channel to which everyone is welcome. We expect all accepted students to be available on Slack very often, even if you don’t need to talk to your mentor. This will help you ask questions when necessary, and you might be able to help others out as well while working on your project. . A mailing list is also available for those that prefer email over slack. It’s a new mailing list (the old one hasn’t been used in a long time) but it’s read by everyone involved in GSoC. . All our top committers will be mentoring. Many of them are former GSoC students. . ** About what we use ** . The core tool that names the organization (CCExtractor) is a command-line program written in C (not C++). The current Windows GUI is written in C#, and we have another GUI for Linux that’s written with Qt, and a small GUI that’s integrated into the main program (C). The testing tool we use to run regression tests is mainly written in Python, but it also used Javascript, CSS and some shell scripting. The Test suite is written in C#. The prototype real time subtitle website is written in NodeJS. We also have a number of support tools that do a number of different things, from downloading subtitles from streaming services to translating them with Google Translate or DeepL. Most of them are written in Python, but since they are small tools that do their job you don’t need to worry much about them. For totally new things you can use whatever tool you feel is best for the job. . ** About sample media and other resources ** . We work with huge files. Not all of them are huge, but many are. We know that many students don’t have access to high speed internet. To those students we will ship (as soon as they are selected) a portable hard drive with all our samples. So if your internet connection is not good, don’t worry - as long as you can plug a USB drive to your development computer you can participate with us. . We also have a shared Linux development server with lots of storage and a Gigabit uplink. Students get an account on it and they are welcome to use it. There’s nothing there except our own work, so it’s a trusted environment (for a server that is connected to internet of course). . The sample platform also hosts a bunch of samples, both which are small or decently sized. . ** About the projects and getting accepted ** . Qualification: On top of -of course- the quality of the proposal, we will be ranking students with a points system (we introduced this last year, and it worked pretty well). . We don’t have a minimum number of required points, but you definitely will need some (with equally good proposals we will rank based on acquired points). This means, the more points you get the more likely you are to be invited to join us during the summer, assuming that your proposal is good. . You can get points by doing one (or more) of the next options: . 1) By solving issues in our GitHub issue tracker (CCExtractor), Sample platform issues (default 1 points per issue unless specified somewhere in the issue page). Most issues have an explicit number of points that you can find in a comment. 2) By joining the community in Slack. You can invite yourself here. (/ccextractor-wiki-test/2020/02/20/1 point) 3) If you are a former Code-in finalist you start with 1 point. If you were a winner, you start with 2 points. Note that there are just a few developers that meet this, so don’t be discouraged if you aren’t one of them. Almost no one is, but we’d love to hear from those that are. 4) By sending us a TV sample that has something we don’t support. It doesn’t have to be from your own country (since hopefully, we already support it), but if it is, so much the better. This is probably hard to get, since we already got all the low hanging fruit. But if your local TV has subtitles you can turn on and off, we’d love a recording. . ** Best qualification tasks ** . If you don’t don’t know which issues in GitHub to do, here’s a list of the ones that are approachable (you don’t need to dig too deep or learn many parts of the code) and useful: . Terrible OCR results with Channel 5 (UK) Can’t extract multi-track subtitles from .mp4 [SOLVED] CCExtractor won’t extract subtitles from TS with no PAT/PMT Automatically switch to correct encoding for 708 subtitles based on PMT data French captions lack accents [SOLVED] CCExtractor is unable to recover position in file after finding a bad NAL due to input corruption Request: Allow to extract several teletext pages in one pass ‘live’ raw data problem DVB Teletext subtitle incomplete [SOLVED] Feature request: Write processed bytes to file Extract telemetry data (which is stored in a subtitle track) from a Drone recording . The sample platform’s issues are tagged with “gsoc-proposal-task”, so you can easily see what you can work on. . ** Community etiquette ** . It goes without saying that everyone in the community has to be polite and respectful, and consider everyone else a member of a team and not a competitor. . All developers are part of the team, by the way. Our Slack channel has mentors, code-in participants, other students, or developers and users that are none of the above but they all play some kind of role in CCExtractor’s community. . Part of being respectful is giving consideration to everyone else’s time. Most of us have day jobs, and as such are limited in the time we can use to guide you. We’d like to spend it on quality discussions, and not on things that are for example written on this website, things that you can easily retrieve by reading documentation on used libraries or on the software’s help screen. Asking this kind of questions in the Slack channel shows little respect for our time. This doesn’t mean you can’t ask questions, but remember that being a clueless user and a lazy developer are two very different things. If you ask those questions you will probably get an answer as if you were a clueless user (polite no matter what), but if you apply to GSoC you will be considered a lazy developer. Google is your friend ;) . Tell things as you see them. Politely -you’re not Linus-, but don’t sugar-coat it. We know some parts of our code is poorly written, poorly documented, etc. It stands out, so you will know when you dig in. No one is going to be offended by having that code rewritten or refactored. Peer review applies to everybody’s work and is done by everybody. . ** Cross project proposals ** . Because we use a number of libraries and in fact “are a library” ourselves (meaning other programs can link CCExtractor as a library, or invoke the binary) we interact with other communities and their software. From time to time there’s a chance to do something interesting that affects CCExtractor and something else (FFmpeg comes to mind, but also Kodi, VLC, libGPAC, Red Hen, to mention just a few of our friends that typically participate in Summer of Code). So how does this work? As long as the work benefits CCExtractor and it’s part of your summer project, we’re OK with you spending some time on the other project. For example if you are improving our MP4 support, for which we use libGPAC, and need to fix or improve something on libGPAC you are welcome to do so. If you do, make sure you submit your changes to their maintainers and follow through with their merge process. . ** Your proposal ** . You can propose to do any of the following ideas, or you can bring your own. In any case, make sure you run them by us before you actually submit your proposal. . At the very least your proposal needs to . Explain what you do want to do, why it is important to you (don’t make up a story here - the reason can be that you need it, that you just think it’s cool, that you have an itch to work on it, etc), and why it could be important or useful to us. | Explain how you intend to accomplish the goal, in enough detail that makes it clear that you have done your homework. For example, “I will modify the CCExtractor binary so that it’s able to convert audio to text with perfect accuracy” is the same thing as sending your proposal to the trash. You need to have a plan. | Detail the timeline explaining what the expected progress is for each week or every two weeks (pay special attention to the milestones within the GSoC timeline itself, of course) and how we should validate the results. | Detail what kind of support you will need from us. For example, if you are going to need test streams, hardware, access to a server, etc, let us know, so we can prepare everything for you as soon as possible. | Detail your expected working hours in UTC. We’re used to weird working schedules, so don’t worry about working in the middle of the night, or weekends instead of other days, etc. Knowing your hours may help us to match you better with a mentor. | Mention your planned absences. We don’t need you to detail what you will be doing when you are not working of course, but if you are going away for any reason we need to know so we don’t think you’ve abandoned. | Link to your GitHub (or any other repository) profile, if you have one, so we can take a look at your previous work. | GSoC is a coding program: This means that ideas that are about testing (unless it involves coding something to test our programs ;) ), website design, etc, are out. | However, we want to have good documentation: Make sure you have time to write a good technical article explaining your work. | Be realistic and honest with the timeline. Consider each week you should work around 30 hours. If your timeline reserves a lot of time for minor things we’ll think that you are not going to be working full-time in GSoC. On the other hand if you promise to do things in a lot less than that it seems realistic to us it will seem that you don’t really know how much work things take. | If you are going to be using 3rd party libraries (that’s OK), make sure to validate that their license is compatible with GPLv2 (which is ours). List the libraries in your proposal. Check that they are cross-platform. If you will need to extend those libraries in any way please explain. In this case, your proposal should include time to get that extension submitted to the maintainers (we love to contribute to other projects). | . Something else: Mentors often have their fingers in several pies. If you send the same proposal to several orgs everyone will know. So do yourself a favor and don’t do that. You can apply to several organizations and that’s totally fine, but each organization will want to see that you have put the time to write a great proposal that is focused on them. . __The ideas we currently have__ . Important: If you have something else in mind that relates to subtitles and accessibility please get in touch. We prefer that you do something that you are passionate about even if it’s something we hadn’t considered. . Name Description Tech you need to know Tech you will learn Difficulty . Complete 708 support | This is one of the big ones. Why? Because it’s been on our wish list for some time and until now no one has decided to really go for it; after the initial work it’s always been incremental improvements, but no one has raised their hand and said “I’m going to complete this”. It’s possible the code base it’s not really friendly. Who knows. If this is the case we’re OK with a total rewrite if that’s what it takes to get this done. The details page has some more information if this picked your interest. | C | Video standards Subtitle standards CCExtractor internals Internationalization | Hard | . Work on JokerTV integration | JokerTV is an excellent open hardware and software platform (/ccextractor-wiki-test/2020/02/20/think Arduino, but for TV). It’s still early days, and we really want to be among the first supporting this amazing new platform. JokerTV can receive signals from all TV standards around the world (/ccextractor-wiki-test/2020/02/20/finally!, no more European or American models, etc). We will buy one device for the student (/ccextractor-wiki-test/2020/02/20/or students, if their ideas are different) that works on this. Abylay Ospan, the genius behind JokerTV has agreed to mentor. | C | Hardware Video standards Joker (/ccextractor-wiki-test/2020/02/20/the platform) | Unknown | . Write Python bindings for CCExtractor | This was partially done during GSoC 2017, but it’s not complete. You may choose to continue the work already done, or you can come up with a more robust / fast / etc approach. What we currently have “sort of works” but we’ve seen leaks, crashes… so it’s definitely not production ready. | C Python | Obscure C+Python topics CCExtractor internals | Medium | . Write high speed subtitle synchronization tools | This one must be hard - it’s the one project that unfortunately failed during 2017, even though it’s a really interesting one that touches many areas (/ccextractor-wiki-test/2020/02/20/math, sound analysis…). We can provide you all the work done last year (/ccextractor-wiki-test/2020/02/20/including the winner’s proposal and current code) or you can start over. | Your choice | Audio Video formats Optimization Algorithms | Hard | . Add support for DTMB countries | DTMB is the standard for Chinese TV, also implemented by countries such as Cuba. What kind of student is ideal for this task? One with lots of analytic skills and patience. If you are one of those, don’t disregard this task just because you don’t speak (/ccextractor-wiki-test/2020/02/20/or maybe, even care) about Chinese. The experience on dealing with this will be extremely valuable in the future. We will use part of the organization funds to buy standard documents you might need, a capture device, and in general, anything required to make your life easier. | C | DTMB Video standards Hardware Research | Unknown | . Detect Automatically the most interesting bits of sample videos | Write software that is able to detect, for some kind of videos, the most interesting bits (/ccextractor-wiki-test/2020/02/20/highlights). | Your choice | Algorithms | Unknown | . Project Nephos | Cloud based storage for a massive collection of TV recordings | Your choice | Cloud services Scalability | Medium | . Improve our OCR subsystem | We use tesseract to OCR bitmap based subtitles. In theory this is straight forward, but when you take into consideration all variants (/ccextractor-wiki-test/2020/02/20/color, languages, subtitles burned-in image, even moving text such as tickers) the complexity grows fast. Still, the work done by PhD students in the past is great, and we’re confident this year we can complete the work on this area if someone of the same caliber decides to join the effort. | C | Tesseract Imaging OCR | Suspected hard | . The Real time subtitles project | We have a great proof of concept on real time subtitles. It’s rock solid (/ccextractor-wiki-test/2020/02/20/except when we’re working on it), and we’re really proud of it. The part of sending the subtitles to the website is completed as you can see, but of course we need more functionality added to it. Which functionality? We’d like to hear proposals. Obvious things such as adding everything to a searchable database come to mind, but that’s not really a summer worth of work. So come up with 3 months worth of improvements you can think of. | NodeJS Web | Depends on your idea | Medium | . The sample platform (/ccextractor-wiki-test/2020/02/20/- continuous integration) project | The sample platform is a good way to help new contributors to check if their code doesn’t introduce any regressions. It’s pretty stable, but has some downsides that have been known for a while and that should finally be solved. Most of the items that are on the issue list (see the issues page) should all be solvable in less than a summer… So if you plan on working on the platform, you’ll have to come up with some small extra things to make sure you’re busy the entire summer ;) | Python (/ccextractor-wiki-test/2020/02/20/majority) HTML, CSS JS Bash | Continuous Integration (/ccextractor-wiki-test/2020/02/20/CI) Automated deployments GitHub integration | Medium | . Add support for Live TV over the internet (/ccextractor-wiki-test/2020/02/20/such as YouTube TV) | A number of platforms are appearing these days to distribute local TV content over the internet. For example, YouTube now has live TV. The goal is to add support for these new content distribution platforms. We will take care of the subscription cost. | Network analysis | Live streaming techniques | Unknown | .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-ideas_page_for_summer_of_code_2018.html",
            "relUrl": "/2020/02/20/public-gsoc-ideas_page_for_summer_of_code_2018.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post35": {
            "title": "Public:gsoc:ideas_page_for_season_of_docs_2019",
            "content": "Season of Docs 2019 . This page is in constant development. We add things as we think of them. It’s not exhaustive, and we’re open to ideas brought by the technical writers as well. . ======= CCExtractor Website ======= . Rework our website, which is based on dokuwiki. We’re happy to switch to any other software that the technical writer is comfortable with. | . ======= User documentation ======= . We have a help screen (which is also exported as a “man” page) that shows all the options, but it’s just a list of parameters. Not a lot of examples (meaning maybe 1 or 2), no proper fonts… it could definitely use a do over. . | Our user tutorials are hopelessly outdated. There’s one to process a DVD, and a basic how-to. We need to generate a number of interest use cases. . | Write scripts for youtube videos. We don’t need you to actually produce the videos (but that would be fantastic, of course). The important thing is the script. We can get someone to read it. . | . ======= Developer documentation ======= . Tutorials on how to do a number of things: Write a new decoder, write a new encoder, how to integrate CCExtractor with other tools, compiling… . | Help us write an official “onboarding” tutorial to help new developers join the team without feeling overwhelmed by our code base. . | . Sample Platform . Write official documentation (a tutorial) on how to properly perform an install of the Sample Platform. . | Help with “onboarding” tutorials . | Proper documentation generation based on the python docstrings. . | . Google Summer of Code documentation . Our current documentation for past GSoC projects is “free style”, and there’s definitely a broad range of quality, possibly because of that. While we don’t want to limit great writers by enforcing a specific style it’s probably a good idea to have some “baseline” so that less gifted writers can deliver a minimum of quality. It’s a pity when a good project gets less-than-stellar documentation. | . Google Summer of Code Ideas pages . We can use help here. Really. We do our best to produce interesting ideas and amazing projects to work on but we seem to be failing on delivery. Given our ideas page for 2019 (some of them will appear in 2020) - how can be reorganize the content so that it’s clearer, more interesting…? | .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-ideas_page_for_season_of_docs_2019.html",
            "relUrl": "/2020/02/20/public-gsoc-ideas_page_for_season_of_docs_2019.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post36": {
            "title": "Public:gsoc:highspeedsync",
            "content": "~~META: title = Google Summer of Code 2018 - Write high speed subtitle synchronization tools ~~ . ** Write high speed subtitle synchronization tools ** . Tool A - sync between two versions of the same footage: This is a very common use case: Suppose you have raw recording of a TV show, with commercials, etc, then use CCExtractor get the subtitles from it. Then you remove the commercials, and have a really clean recording, but the subtitles are out of sync since the timing changed the video. . The project is to write a tool that takes: a) The original video b) The edited video c) The subtitles for the original video . and produces . d) The subtitles for the edited video . We recommend you use FFmpeg to do the heavy lifting for the video processing and DejaVu as a reference to do the audio fingerprinting which you will need for the synchronization. . A really important requirement is that this is a fast tool. This means that writing a script that first calls FFmpeg to generate a .wav file and then calls DejaVu to locate each segment will definitely not work (and also, it’s not a Summer of Code task). You need to write a C program that uses FFmpeg libraries and reimplement the audio fingerprinting in C. This should be “easy” since for DejaVu you have the source code, an amazing explanation of how everything works, and FFmpeg libraries have FFT functions so luckily you don’t need to implement them yourself. . You can also come up with a totally different solution that doesn’t follow our suggestion as long as it achieves the goal. . Tool B - Suppose you don’t have the original video, but you do have the original subtitles from it, so what you have is: a) The subtitles for the original video, which contains subtitles for commercials and possible a few minutes from the previous and following program. b) The edited version. . Doing the sync now is more difficult as you don’t have the original audio or video to compare. But you do have the audio for the edited version from which you can obtain timing for voice. For example if the subtitles for the original video contain three consecutive frames that last 3.45 seconds, 1.54 seconds and 2.34 seconds respectively, and doing audio analysis in the edited video you find 3 segments with voices with similar duration it’s likely that they are a match. . Requirements: 1) You cannot use any non open source dependency. For example, Mathlab is out, even if the run time is free. 2) Your program needs to be usable from a script, so it should be command line based. If there’s time, you can definitely provide a GUI, but that’s secondary to the main program. 3) High speed is really a priority. Prepare to spend time coming up with a good algorithm. 4) While GSoC is about coding, you will have to prepare really good documentation. As an example, check out DejaVu’s explanation on how everything works (even if you don’t use it at all, use it as a baseline of really good technical documentation). 5) Must be as portable as the libraries you use. For example FFmpeg builds in linux, windows, etc, so if you use FFmpeg then your program must also build on those platforms. . We will provide a fast speed server in which you can work. You don’t have to use it, but keep in mind that in general video files are very large. You will need to deal with files that are several gigabytes long. If you have the bandwidth, great. Otherwise you can just work remotely on our development server. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-highspeedsync.html",
            "relUrl": "/2020/02/20/public-gsoc-highspeedsync.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post37": {
            "title": "rutorrent mobile interface",
            "content": "Introduction rutorrent is the most popular web interface for rtorrent, which is possibly the most used BitTorrent client in linux. It is mostly a web application, but it has its own backend that connects to rtorrent. You could connect to rtorrent directly as well, but by doing that you would be missing lots of features that come with rutorrent, for example RSS support. . Yes, there are two things with almost the same name. To summarize: . rtorrent =&gt; The BitTorrent client, a console-based tool that also has an API to interact with it. rutorrent =&gt; A web interface for rtorrent that uses that API. It also does other things, for example, it can download torrents from an RSS feed. You configure RSS feeds in rutorrent’s web interface, but there’s also a backend service (written in PHP) that is part of rutorrent to do the actual download. . Your job The job is to write a Flutter based web interface that uses rutorrent’s backend service to provide a native interface. . The basic things (for example, torrent listing) are easy to do, but rutorrent is extensible (it has good plugin support) and your tool needs to support that, too. . The job is to write a native application that feels written for mobile. It’s not about cloning rutorrent’s interface. So yes there needs to be a torrent list but the columns may be different (definitely less), colors, sorting, how you interact with the tool and so on. . rtorrent, by the way, runs in a server, and rutorrent is the web interface that lets you interact with rtorrent. We don’t want to add BitTorrent capability to mobile or anything like that. This is a 100% frontend job, using pre-existing work in rutorrent to control rtorrent from the phone. . Notes In order to understand what to do you need to actually install rtorrent and rutorrent and play with them. . You don’t need to have previous experience (really, not important for this - it’s all about Flutter), but you won’t be able to come up with a good proposal if you don’t know how things work. . Also, if you are unable to run rtorrent and rutorrent on your system, please use this docker image. . Qualification tasks Take a look at this page. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-flutterrutorrent.html",
            "relUrl": "/2020/02/20/public-gsoc-flutterrutorrent.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post38": {
            "title": "FFmpeg + Rust: Code builder",
            "content": "Why is this a CCExtractor project and not an FFmpeg project? Because the FFmpeg team doesn’t need it :-) We do. . Introduction FFmpeg is, of course, everybody’s go-to tool when it comes to video manipulation: Resize, apply filters, convert to a different encoding or container, etc, it does it all. They even participate in GSoC every year! . If you read their documentation, you will see that FFmpeg, the command-line tool, is mostly a “shell” that actually builds a graph that then runs in their libraries. . For developers that need to use FFmpeg to do “something” specific with video, the usual way to do it it just by executing FFmpeg with the right parameters (using spawn, exec, or whatever it’s called in their language of choice), wait for it to finish, and then do something with the result. . Often that’s good enough, but many times it’s not: You can’t easily get progress, you absolutely can’t do anything in the middle of the process and so on. . Your job Your job here is to build a “source code generator” that given a FFmpeg command line is able to write the source code of a program, preferably in Rust, that executes the graph using FFmpeg’s libraries - but this is not about spawning FFmpeg! For example, given a command line like this: . ffmpeg -i input.mkv -vf scale=320:240 output.mp4 . You can see that it’s going to read the file “input.mkv”, resize it to 320x240, and write it as output.mp4, so there’s a resize filter there and also a container conversion. . What we want to get is a program that does that for exactly those files and those tasks, and it needs to use FFmpeg’s low level libraries so it’s possible to add code into the program that does whatever the developer needs to do: For example, they might want to modify each frame to add something that is not supported by an FFmpeg filter - may be something that needs to be fetched for an external source. . Your output program needs to be compilable (of course) and do exactly the same thing as FFmpeg would do if called with the specified parameters. . Of course, you are expected to dig into how FFmpeg does it and build from there. . We prefer Rust but C would also be OK. However, if you already know C or C++ learning Rust is not too hard and it’s totally worth it. . Qualification tasks Take a look at this page. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-ffmpeg-rust.html",
            "relUrl": "/2020/02/20/public-gsoc-ffmpeg-rust.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post39": {
            "title": "Extracting closed captions from a DVD step by step tutorial",
            "content": "// Note: This procedure may or may not be legal in your country, depending on whether they consider it fair use. I own the DVD used in the tutorial and I am not going to distribute anything from it, plus I live in a country where this sounds reasonable, so I believe I am in the safe side. But your mileage may vary.// . This tutorial was written years ago. Probably better tools exist already to do the same thing. . This tutorial will teach you how to go from a DVD in your shelf to a transcript of its closed captions. Basically there are these steps: . Install DVDDecrypter (a program to extract the DVD data from the physical DVD). You only need to do this once. Install CCExtractor (our beloved program; it gets the data from the previous step and extracts the closed caption track). You only need to do this once. Use DVDDecrypter to extract the DVD data into your hard disk. Use CCExtractor to extract the closed caption track from the DVD data. . As an example, I will be using the movie Merlin. Remember that DVD subtitles and closed captions are two different things. Closed captions come from the NTSC (USA and Canada) TV world, and they are usually prevent in DVDs from TV shows, documentaries, old movies and so on. If you buy a brand new DVD with a film from last year it’s unlikely to have closed captions - it will have DVD subtitles, which require different tools to extract. Many tutorials exist on DVD subtitle extraction. . 1 - Install DVDDecrypter . As explained before, DVDDecrypter is the tool we will use to copy the DVD data from the physical DVD into the hard disk. DVDDecrypter reads the DVD, decrypts it (so other tools can actually use the data) and writes it to the hard disk. There are other tools that do the same thing, so you can use whichever you prefer. DVDDecrypter is free, use to use, and does a good job, so it’s the one I use regularly. . First, download DVDDecrypter, which is available from this page. You can get the file directly here. Depending on your browser, it may ask you whether you want to run the program, or save it, etc. . Run it if possible directly, or save it somewhere and run it later if your browser insists. . If you are using Internet Explorer it might warn you about the file not being signed, and ask you again if you want to run it: . Say yes. If you are running Vista it will show you yet another window to reconfirm you haven’t changed your mind. I couldn’t get a snapshot but it you are a Vista user you have seen that windows a billion times anyway. The installation program starts. All defaults are correct, so the only thing you need to do is say Next at every chance. A screenshot of all screens follows: . When asked about whether you want DVDDecrypter to check for new versions say no. The program is no longer being maintained so it will never find a new version anyway. . The installation ends. In the last screen you have an option to start DVDDecrypter inmediately. Since we are going to install CCExtractor now, uncheck the box. . 2 - Install CCExtractor . CCExtractor is the program that does the actual work of getting the closed caption text from the data. It supports DVDs as well as many other formats. This is its home page (you probably know that already). Follow the link “Download Windows installer” (I don’t link to the installer directly because it’s updated from time to time and the link would be out of date soon). As before, run the installer if possible or save and run later if needed. . 3 - Extract the data from the DVD using DVDDecrypter . Insert the DVD in the DVD player if you haven’t done it already. Most likely it will start making noise for a few seconds, until Windows is done analyzing it. Wait for the noise to stop (so it’s ready) and then start DVDDecrypter, either by clicking on its icon (on your desktop) our by selecting it in the program menu (Start -&gt; Programs -&gt; DVD Decrypter -&gt; DVD Decrypter). Initially the screen looks like this (assuming DVDDecrypter detects the DVD correctly - if not you may have to select the correct drive from the combo box): . The first time, go to the settings area (Tools -&gt; Settings). There are a lot of things there but the default settings are fine, except for the file splitting. We don’t want the output video to be split in several files (the only exception would be if your hard drive couldn’t handle large files). Having all the output in one file makes things easier later. . So go to the settings area as explained, and the select the “IFO mode” tab. In file splitting choose “None” from the combox box and then press OK. Done with the settings. . Back to the main screen, you can see that there’s a “Destination” that DVD Decrypter automatically sets. You may need to choose a different folder. For me that directory is OK (F: MERLIN VIDEO_TS). Notice too that all the files in the DVD are selected. If were trying to get the data from say, one specific episode of a TV show (where usually there are 4 episodes or so in each DVD) we would have to guess which file is correct. Since this is a complete movie, we’re going to get all the files, so we leave the selection as is. . OK, so we press the large ‘Decrypt’ button (see below) and DVD Decrypter does its magic. . File selection . Take a look at the destination directory: . The VOB files are the actual video data. In DVDs, they usually have more stuff that just the movie. For example, the chapter selection video is there. In order to get a clean transcript, you need to tell CCExtractor which files to use. Usually the right files are easy to spot. In this example, you can see that the file VTS_01_0.VOB is 330 Mb long, while VTS_01_1.VOB is 1 Gb, VTS_02_2.VOB is one Gb too, etc. This is a clear indicator that it is not part of the same video stream. In order to verify it, we just play the file with any DVD capable player: . This is indeed the chapter selection video, which we don’t want. Just to make sure, we start playing VTS_01_1.VOB, which should be the actual start of the movie: . Indeed it is. . 4 - Extract the transcript with CCExtractor . Open CCExtractor, by click on its desktop icon or by selecting it from the program menu (Start -&gt; Programs -&gt; CCExtractor -&gt; CCExtractorGUI). . Now, open Windows Explorer if you didn’t have it already, and choose the files VTS_01_1.VOB up to VTS_01_01_8.VOB (so all of them except the one we already know not to be part of the movie): . Drag and drop the files from Windows Explorer to CCExtractor: . Now you can see that CCExtractor has queued the files: . You can notice that CCExtractor has a lot of tabs with lots of options. The good news is that the default settings are OK, so you don’t need to worry about them. The one thing you may want to change is the output format in the Output tab. By default it exports to .srt, which is the standard format that most players support. Suppose you want a plain transcript with no timing information. Just check the .txt option (transcript): . Finally, go to the Execution tab and press Start: screen-shot You can see the progress: . Once CCExtractor finishes, a file with the same name as the first file in the input is created in the same directory (this can all be changed in the settings). In this case, the file is called VTS_01_1.txt (note that it ends with .txt instead of .VOB). Here’s the contents (the first 10 lines): . ONCE UPON A TIME... NO, NO, THAT&#39;S NOT THE WAY TO START. YOU&#39;LL THINK THIS IS A FAIRY TALE, AND IT ISN&#39;T. IT HAS ELEMENTS OF A FAIRY TALE-- DRAGONS, ELVES GRIFFINS, FAIRIES AND SO ON-- AND IT HAS MAGIC. NOW, IN MY DAY, . We’re done. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-extract_from_dvd.html",
            "relUrl": "/2020/02/20/public-gsoc-extract_from_dvd.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post40": {
            "title": "DVD Subtitles Technical Documentation",
            "content": "Overview . This project was done as a part of GSoC 2016. DVD subtitles extraction works by filtering out the subtitle frames from the video stream and obtaining the RLE encoded bitmap based subtitles, which are then provided to Tesseract for OCR recognition. . Dependencies . Tesseract (OCR library by Google) . | Leptonica (C Image processing library) . | . The instructions for compilation along with the OCR can be found in the CCExtractor docs at docs/OCR.txt. General usage instructions can be found in the help screen of CCExtractor. . Code Structure . The DVD subtitle decoder is contained in the ‘‘dvd_subtitle_decoder.c’’ file and houses all required functions. The subtitles frames are selected from rest of the video and audio frames in ‘‘general_loop.c’’ and the ‘‘process_spu()’’ function receives only the subtitle packet in the buffer. . The structure ‘‘DVD_Ctx’’ has the context for the DVD subtitles while ‘‘ctrl_seq’’ has data of the control packet. The function ‘‘process_spu()’’ checks for and creates a usable packet as some data might be spread over multiple packets. . Now we need the data in the control sequence which is handled by ‘‘decode_packet()’’. Data from the control sequence including start and stop time, size of the subtitle, color, alpha and address of bitmap are extracted and stored in ‘‘ctrl_seq’’. . Now we need to obtain the bitmap (via ‘‘get_bitmap()’’). The bitmaps however are Run-Length Encoded (RLE) and are interlaced such that alternate lines follow each other. This is handled by providing first one half of the bitmap, followed by the other to ‘‘rle_decode’’ to account for the interlacing as well. At the end we get a clean bitmap which is then sent to the OCR invoked in ‘‘write_dvd_sub()’’. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-dvd_subtitles_technical_documentation_gsoc_16.html",
            "relUrl": "/2020/02/20/public-gsoc-dvd_subtitles_technical_documentation_gsoc_16.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post41": {
            "title": "Public:gsoc:dv_support_request",
            "content": "This seems interesting. Here’s the original request email: . Does CCExtractor have support for extracting captions contained in the VAUX area on DV streams, and I just can’t figure out how to use it? . If not, are there any plans to integrate this into CCExtractor? It seems to me that the only software available to do this is MacCaption, which costs many hundreds of dollars. . Here are some links to specifications I have run across: https://dvswitch.alioth.debian.org/wiki/DV_format/ http://ffmpeg.sourcearchive.com/documentation/0.6/dvdata_8h-source.html . This page contains links to two DV-stream-containing files that supposedly contain captions in their streams, meant for testing one’s equipment chain: http://www.cpcweb.com/dv/dv-hardware.htm http://www.cpcweb.com/samples/CPCDemo_DV_720x480_CC.mov http://www.cpcweb.com/samples/CPCDemo_DV_720x480_CC.avi . To extract the DV stream from those containers while retaining the VAUX stream, apparently one can use http://www.kinodv.org/article/view/182/1/11/ according to https://lists.libav.org/pipermail/ffmpeg-user/2010-March/024594.html . Here is a discussion where someone wants to transcribe a VHS via a DV camera while preserving closed captions. It seems they gave up and used (bought?) a DVD/VHS combo machine to dump directly to MPEG2, preserving Line 21 at the cost of quality and edit-ability: https://discussions.apple.com/thread/764469?start=0&amp;tstart=0 . If one wants to transcribe an NTSC source with captions and already owns a good analog source (LaserDisc, SVHS) and DV-based digitizer, it would be nice to have this capability in CCExtractor’s arsenal of features. . Thanks for your time and consideration. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-dv_support_request.html",
            "relUrl": "/2020/02/20/public-gsoc-dv_support_request.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post42": {
            "title": "Public:gsoc:dtmb",
            "content": "~~META: title = Google Summer of Code 2018 - Add support for DTMB countries ~~ . Add support for DTMB countries . DTMB is the Chinese TV standard, adopted by other countries such as Cuba. We still don’t know much about it. Due to this, your proposal must include: . a) A link to the relevant standard documents. We don’t know if they exist in English. If they don’t but you speak the language they are in, that’s fine. If you locate the documents but they require payment (as is often the case for technical specifications) send us a link to buy and we’ll allocate organization funds to purchase them. b) Some TV samples. Or, if you cannot get them directly, an explanation of how you will get them, for example by purchasing a capture card that is known to be compatible (send us an exact link), plugging it to an antenna or dish, etc, that you have access to (detail), etc. . In short, this is an “adventure” task. We’ll go all the way with the student that tries it, but we want to make sure the chances of success are reasonable. . This is what we (think we) know so far: DTMB regulates the physical transmission standard (signals, frequencies, etc). It seems to be available (for purchase) here. . Cuba follows it: http://www.globaltimes.cn/content/955479.shtml http://advanced-television.com/2013/03/22/cuba-adopts-chinese-tv-standard/ . The reason Cuba is interesting is that their subtitles will have Latin characters, which will make life a lot easier for most team members. Also, the Cuban government has a good website about their TV regulations. . Apparently the subtitles themselves follow the European DVB standard. We can see that in this document from the Hong Kong regulatory body which says: . Subtitles: Receivers shall include provisions to decode and display subtitles conforming to ETSI EN 300 743. . The Cuban government says the same thing: . That document (in English) says: The Brand and Model TV Set is intended for the reception of DTMB Digital Terrestrial Television in 6MHz bandwidth, according to the specifications GB 20600-2006. . and DVB subtitles (ETSI EN 300 743) – The DUT must support DVB subtitles (ETSI EN 300 743). . Important: Since Chinese is by far the most extended language among DTMB countries, its support is essential. We have some preliminary support for it, but whatever is missing you will need to add. This applies in particular to the .srt writer. Since .srt is text based, you need to OCR the bitmaps. This is already done but almost untested for Chinese. Don’t assume it’s going to work. Probably not. Give yourself time in your proposal for this. . **Related GitHub Issues** Extract subtitles in a Chinese newscast . Qualification tasks Take a look at this page. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-dtmb.html",
            "relUrl": "/2020/02/20/public-gsoc-dtmb.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post43": {
            "title": "Public:gsoc:complete708support",
            "content": "~~META: title = Google Summer of Code 2018 - Complete 708 support ~~ . Complete 708 support . 708 is the standard for digital TV in the US and a few other countries. We have preliminary support, but the goal is a 100% accurate implementation. This means: . a) Perfect timing. b) Perfect rendering, limited only by the output format. c) Full support to all languages for which samples are available. . We will provide hundreds of samples (for which you must complete support, no exceptions) and access to a high speed linux server for you to work with if needed. These samples are usually very large (hundreds of megabytes each) so working locally may not be feasible for you if you don’t have a great internet connection. . For developers in India we have someone there with an external 2 TB drive with a copy of all our samples. That drive goes from developer to developer, so if needed we can get it shipped to you. . If you are not in India or in a country in which just downloading the samples is the easy way, get in touch. We’ll figure something out so access to media is not a problem. . This is a high value task and we’d love to have it done, but in order to qualify you need to fix some of the existing bugs. . Also part of this idea: . https://github.com/CCExtractor/ccextractor/issues/733 . Which is about implementing .mcc support, which as the GitHub ticket says complements 708 very well. . Getting started: . The wikipedia page on 708 This is quite good actually. It’s not a complete description of the standard, but it’s quite useful to understand what 708 is about. . **Related GitHub Issues** Ver 0.85 CEA-708: 16 bit charset (Korean) Not support (problem extract Korean subtitles [CEA-708] Missing the last subtitle [CEA-708] [Timing] Catchable bug with timing Finish CEA-708 support . **Mentors** Carlos Fernandez Sanz (@carlos.fernandez on slack). Carlos wrote the original CEA-708 code. Evgeny Shulgin (@izaron on slack). Evgeny is a 2016 Code-In Winner with CCExtractor, and worked a lot on CEA-708. . **How to get started** Best thing you can do is download a few samples (/ccextractor-wiki-test/2020/02/20/check our TV samples page) and try to solve some of the CEA-708 issues we have listed on GitHub. . This is also the best way to get accepted into GSoC. . Qualification tasks Take a look at this page. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-complete708support.html",
            "relUrl": "/2020/02/20/public-gsoc-complete708support.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post44": {
            "title": "The next peer-to-peer protocol",
            "content": "Introduction BitTorrent is, of course, the world’s most used peer to peer protocol. It’s great, but it was designed before the cloud was ubiquitous and it doesn’t make use of the places where you have the most storage or the most bandwidth. Can we design something for the next decade? . BitTorrent is based on the concept of peers, which are BitTorrent clients, usually running on computers at home, that share data is a super-efficient manner. It works well, of course, but . It requires users to have their computers on for a long time | It requires users to expose their IP address | It requires users to use their home internet connection, making it hard to do other things at the same time such as streaming | . There are of course alternatives (you can rent servers in data centers for example), but they are not cheap, they’re not easy to set up, and they come with their own sets of problems, in general. . These days most people have lots of their data in the cloud: Dropbox, Google Drive and so on. . Your job The goal here is to come up (and implement the first version) with a system that let those personal storage systems exchange data . Securely | As cheap as possible | As fast as possible | As easily as possible | . A possible idea (one of many possibilities) would be to introduce the concept for “agent”. An agent would be a process that runs in the cloud on behalf of the user and that has access to his personal storage accounts. The agents can run anywhere, but their ideal place is the cloud, for example, AWS or Google Cloud. They can be managed by the final user or by a 3rd party that provides the service. . Agents find each other, and learn to trust each other, with the help of repositories, the equivalent of today’s trackers. . Agents that trust each other can vouch for other agents. . The chain of trust must always be preserved so agents can prune trees if the trust is broken. . Qualification tasks Take a look at this page. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-cloudtorrent.html",
            "relUrl": "/2020/02/20/public-gsoc-cloudtorrent.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post45": {
            "title": "Public:gsoc:ccextractor_unassigned_tasks_pick_what_like",
            "content": "Tasks here can be picked up by any student. Feel free to add them to your to-do list or if you like it better than something in your proposal you can replace. Please contact Carlos about it in any case. . Task Who Depends Planned dates Status Mentor notes . GXF Support | Unassigned |   |   | Not started | This is a request from a user; GXF is one of those professional formats (such as SCC) that we might never want to use personally but that would be really useful in the CC industry. | . DV Support | Unassigned |   |   | Not started | This is a request from a user; See DV Support Request for details. | .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-ccextractor_unassigned_tasks_pick_what_like.html",
            "relUrl": "/2020/02/20/public-gsoc-ccextractor_unassigned_tasks_pick_what_like.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post46": {
            "title": "CCExtractor tasks",
            "content": "This page is a compilation of the most important tasks from everyone’s proposals. Those of you that are going to be working on the same things please talk among yourselves. . Add tasks and edit as needed. . We know that there were some proposals that included the exact same tasks. We preferred to pick the best students and not just the best proposals for each task. If you find yourself in a situation in which someone else is doing what you were planning to do, just replace that task with even a more interesting one :-) Don’t get frustrated by this overlap. We are aware of it. . GSOC 2016 tasks . Task Who Depends Planned dates Status Mentor notes . Preprocessing burned in white subtitles | Abhinav |   | by Week 4 | Done |   | . Generating basic timed output files | Abhinav |   | by Week 5 | Done |   | . Adding support for colored and styled hard subtitles | Abhinav |   | by Week 7 | In Progress |   | . New user options and cascaded classifier | Abhinav | Working system for all types of subtitles | by Week 10 | In Progress |   | . Test suite integration of Hardsubx | Abhinav | Completion of above tasks | by Week 12 | Not started |   | . GSOC 2015 tasks . Task Who Depends Planned dates Status Mentor notes . Real time translation with Apertium | Nurendra |   |   | Finished |   | . Real time translation with Google Translate | Nurendra |   |   | Finished |   | . Statistics of Stock Prices and their dependence on Twitter-mentions, TV-mentions | Nurendra | Real time uploading (Ruslan) |   | Finished |   | . Extension of test suite | Willem |   |   | Finished (for now) |   | . Sample submission and testing platform | Willem |   |   | In progress |   | . GitHub bot | Willem |   |   | Finished (for now) |   | . Complete support for EIA-708 | Anshul |   |   | Not started |   | . Implement Multi-Program | Anshul |   |   | Complete |   | . Multi-language Forced Alignment | Sai |   |   | Not started |   | . Real time translation with Google Translate | Oleg |   |   | In Progress |   | . Implement Multi-Program | Oleg |   |   | Not started |   | . Complete support for EIA-708 | Oleg |   |   | Not started | Oleg: Please focus on Japanese support (and other non-Latin languages since Anshul will be finishing the decoder itself | . Linux GUI | Oleg |   |   | Not started | Oleg: Anshul has already something started, please coordinate with him | . OSX GUI | Oleg |   |   | Not started |   | . Networking - server side | Ruslan |   |   | Not started |   | . Networking - client side | Ruslan |   |   | Not started |   | . Complete refactoring | Ruslan |   |   | Not started |   | . Commercial detection | Vasanth |   |   | Finished |   | .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-ccextractor_tasks.html",
            "relUrl": "/2020/02/20/public-gsoc-ccextractor_tasks.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post47": {
            "title": "CCExtractor regresssion testing / GitHub bot",
            "content": "In 2014 Willem wrote a nice tool that allows you to compare CCExtractor’s output between versions to make sure code changes didn’t break things. This tool has been expanded in t he past two years to cover more scenario’s, as well as offering better integration. . All changes must be validated using this tool. As of 2016, it is fully integrated (using a webhook) with GitHub, so if you make a Pull Request, you should be able to see if you broke anything or not. . Pull Requests that break things severely won’t be accepted (due to the way the test suite compares the results, minor changes in timing are also indicated as failures, while they don’t necessarily have to be). . GitHub integration . As mentioned above, as part of GSoC 2016 a full integration was made with GitHub. This means that just as with other integrations, the regression test suite will now run automatically when you create a Pull Request or if you make a commit on the repository. . When creating a pull request (PR), the next steps happen: . Test get queued (another one might be running that needs to finish first) . | The platform kicks off the test suite: . Your code gets locally merged with the current master branch | The result is compiled | The test suite runs the tests on the compiled binary | . | . Several individual steps (preparation, building, compiling, …) are being reported back to the PR on GitHub, while the detailed overview is available by clicking on the “details” (as can be seen in the image below): . This link will take you to the detail page of the test, where you can check the status of the test in general, as well as the results for each category. . How to run your own tests on fork . If you want to run your own tests on your fork commit with selected regression tests and platforms, Follow these steps: . Ask for tester/contributor role from Willem. You can see your role here. | After role access, link your github profile in Manage account page. | You can run your own tests here. You have to enter commit hash of the fork repository.After that you need to select platforms and regression tests. Test Status is displayed on same page. | Obtaining individual regression samples . If you are aware your coding changes are going to break a specific sample, you can always download the sample from the platform to test your code changes locally. This has the advantage that you can test faster, as the complete test suite takes about 30-60 minutes to complete. . Media-info for the samples is also available (both partially visible on the sample detail page, as fully visible after downloading). . How to use the testing tool manually . If you have access to the dev server at gsocdev3.ccextractor.org, or have downloaded all the samples, you can run the test tool manually. This has the benefit that you can test just single categories, or specific samples only, whereas the GitHub integration does all the available tests. . The easiest way to test all the current samples against your own version of CCExtractor is using a shell script that does most of the work for you: ‘’ /repository/newRepository/TestSuite/runAllTests CCExtractorLocation ReportLocation’’ . The CCExtractorLocation is the location of your CCExtractor build that you want to test (/ccextractor-wiki-test/2020/02/20/against the latest official CCX version). The ReportLocation is optional (/ccextractor-wiki-test/2020/02/20/if omitted, the reports will be stored under your name in a subfolder of Willem’s public_html folder). . If you want to have more configuration options, you can create your own config or test files (there is a sample config at ‘‘/repository/newRepository/TestSuite/sampleconfig.xml’’ and for a sample test file you can look in the folders), and then call the ccextractortester bash script (located at ‘‘/repository/newRepository/TestSuite/ccextractortester’’) with the appropriate parameters. . If you want to know the available parameters that can be passed to the test suite, use the ‘’–help’’ (double -) argument. . Bugs, requests, etc. are welcome on the GitHub page of the test suite: https://github.com/canihavesomecoffee/ccx_testsuite .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-ccextractor_regression_testing.html",
            "relUrl": "/2020/02/20/public-gsoc-ccextractor_regression_testing.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post48": {
            "title": "CCExtractor bug hunt",
            "content": "The first 1-2 weeks are to be spent fixing bugs and closing issues in GitHub. This applies to all CCExtractor students that are going to be working on the core tool (that’s almost everyone). This serves some purposes: . It’s the best way to see first-hand what the problems are :-) | It will let you get used to the code. | It will give us a reliable version that is fun to work with | . The following table should be populated before the start of the coding period. You can either select your own bugs (just edit the table and add yourself) or they can be assigned to you :-) . The veteran students (Anshul, Ruslan, Willem) are expected to do the hard ones unless someone else do them first. . When you start working a bug please write it here. Don’t wait until it’s fixed to avoid the situation in which two people happen to work on the same thing unintentionally. Working on a bug and not being able to actually fix it is OK. Ask for help or discuss it in the mailing list so others can help you figure it out. . ID Details Who Status . 136 | Garbling in Tivo samples | Ruslan | Open | . 157 | 3 new samples that don’t work | Oleg | Resolved | . 151 | DVB subtitles from TNT (France) | Oleg | Support Required | . 158 | CEA-708 is not supported at all for MP4 | Oleg | Resolved | . 172 | alternate subtitles missing | Oleg | Support Required | . 284 | Issues with ISDB (Brazil) support | Abhinav | Open | . 286 | Missing subtitles in a Korean broadcast | Abhinav | Open | . 279 | Can’t extract DVB subtitles from a Spanish channel | Abhinav | Open | . 131 | Seeking DVD using the IFO file | Abhinav | Open | . 139 | Case fixing in teletext | Abhinav | Fixed | . 353 | High Memory Consumption | Abhinav | Fixed | . 359 | Teletext page number in -UCLA | Abhinav | Fixed | . 354 | Excessive XDS Notices | Shruti | Fixed | . 285 | No Preview in 0.78 and 0.79 | Abhishek | Resolved | . 304 | Premature end of file. | Abhishek | Open | . 356 | Premature end of file (2) | Abhishek | Open | . 315 | File Flushing issue | Abhishek | Resolved | . 345 | Ability to Rotate Files | Abhishek | Open | . 713 | One out of two Korean DTV TS not showing output | Siddharth | Open | .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-ccextractor_bug_hunt.html",
            "relUrl": "/2020/02/20/public-gsoc-ccextractor_bug_hunt.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post49": {
            "title": "PiPot - Micro Honeypot for RPi",
            "content": "Mentor: Willem Van Iseghem . Introduction . PiPot is a honeypot server which pretends as a potential target for attackers from network and collect the attack data. It also has the ability to deploy more instances to make it harder to get information from the real one. The goal of this GSOC project is to improve the functionality and scalability of the current PiPot. . Links . Project repo - https://github.com/PiPot . Completed work(PR) . Server Development(Every new feature is covered with unit test) - Create and run server inside python virtualenv set up virtualenv for server Run PiPot on non-Arm platform like RPi | . | allow user specific network interface | suppot image deployment on non-Arm platform Allow container-based service uploading | . | container based service upload Allow dynamic data report update | . | dynamic report update Allow service version update | . | fix service cannot upload properly | add service manager interface, upgrade from old to newer models from updated service | add test on invalid test update | . | Continuous Integration - travis setup, add test database setup and with some basic tests - notification management test - add codecov - start sql service explicity on travis | Python2 to Python3 migration - update enum attribute for sqlalchemy table - fix enum attribute iteration issue due to python3 update | Usage . To install pipot, please follow the installation section. When install sever, answer each question carefully to set up the right config. If you want to run the pipot server locally for test, you can simply run python run.py under server. (Assume you don’t use localhost as IP address in installation, otherwise you need to close nginx by service nginx stop to free the address) . Future work . have container based notification uploading, ideally check the requirement before actually applied to pip install | develop tests to improve the test coverage | update the image deployment to support the latest Raspberry Pi model | set up a mailing notification service to report the collected data | password change/get back user name using mail verification |",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2019-vertexc.html",
            "relUrl": "/2020/02/20/public-gsoc-2019-vertexc.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post50": {
            "title": "Poor Man’s Rekognition",
            "content": "Developed under Google Summer of Code 2019 by Sarfaraz Iraqui . Mentor: Johannes Von Lochter . Introduction . Poor Man’s Rekognition (PMR) aims to provide a free and open source alternative to Amazon Rekognition. . Amazon Rekognition is a fairly complex system. . During GSoC, the project focused on face detection and recognition only. . There are many libraries especially in Python that provide these functionality but they require a lot of expensive hardware for practical use. . This project is aimed to make everything run on CPU but still provide reasonable performance for a REST API. . Project Structure . The project is divided into three sub-projects: . Nodoface: A Nodejs C++ addon (binding) to C++ libraries that helped attain high performance on CPU for ML algorithms. . | PMR-Core: Nodejs library (with TypeScript support) that combines Nodoface and ML libraries that are not available in C++. For eg. there is no ArcFace model on C++ or Nodejs. This provides completely everything that is needed to build Amazon Rekognition like API. . | PMR-Server: The REST API for PMR-Core. This provides endpoints similar to Amazon Rekognition. Any API call generates response which is more or less identical to Rekognition. . | . Project links . Proposal - https://github.com/sziraqui/pmr-gsoc-tracker/blob/master/Proposal-PMR-CCExtractor.pdf . | Nodoface repository - https://github.com/sziraqui/nodoface . | PMR-Core repository - https://github.com/sziraqui/pmr-core . | PMR-Server repository - https://github.com/sziraqui/pmr-server . | Installation . Only Nodoface requires a tough installation because it depends on some C++ libraries. . PMR-Core and Server require just one command for setup. . Part 1: Install dependencies . Nodoface depends on- . OpenFace &gt;= 2.1.0 . | OpenCV &gt;= 3.4.0 . | dlib &gt;= 19.13 . All above libs must be compiled as a shared library . | node-addon-api &gt;= 1.6.3 . | . Step 1: Install OpenCV 3.4.x. . If opencv is already installed, ensure it is recognised by pkg-config by executing: . ’’’$ pkg-config –modversion opencv’’’ . Step 2: Install dlib 19.13 or greater as a shared library (default is static). . Check this answer by DavisKing for compiling it as shared library. . Ensure it is recognised by pkg-config: . ’’’$ pkg-config –modversion dlib’’’ . Step 3: Install OpenFace. The original repo can only compile as static library. . So use my OpenFace fork instead. I have modified CMakelists.txt to compile OpenFace as shared lib. . $ git clone https://github.com/sziraqui/OpenFace.git &amp;&amp; cd OpenFace $ git checkout dynamic-compile $ ./download_models.sh $ mkdir build &amp;&amp; cd build $ cmake -D CMAKE_BUILD_TYPE=RELEASE CMAKE_CXX_FLAGS=&quot;-std=c++11&quot; -D CMAKE_EXE_LINKER_FLAGS=&quot;-std=c++11&quot; $ make -j2 $ sudo make install . After this, Nodoface can be installed in any Node project with npm install nodoface . Part 2: Setup server . The server depends on PMR-Core and knn-classifier. . Step 1: Create a project folder. Let’s name it “pmr”. . ’&#39;’mkdir pmr’’’ . Step 2: Clone dependent repositories in project folder. . cd pmr git clone https://github.com/sziraqui/nodoface git clone https://github.com/sziraqui/pmr-core git clone https://github.com/sziraqui/pmr-server git clone https://github.com/tensorflow/tfjs-models/tree/master/knn-classifier . Step 3: Install packages in PMR-Core . cd pmr-core npm install cd ../ . Step 4: Setup KNN-classifier . cp -r tfjs-models/knn-classifier knn-classifier cd knn-classifier npm install cd ../ . Step 5: Setup server . cd pmr-server npm install cd ../ . Part 3: Setup database . The project uses PostgreSQL database. Face embeddings and PMR-Server data is stored in a database. Follow below instructions to setup a local database for the PMR-Server. . Step 1: Create DB schema . Install PostgreSQL and create a schema as per this ER diagram . Step 2: . Download LFW dataset from http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz . Extract it somewhere (say pmr/lfw-deepfunneled) . Step 3: Populate face embedding data in DB . cd pmr-server ./bin/add_faces_to_db.ts pmr/lfw-deepfunneled LFW DEEPFUNNELED . For more info on script usage, pass it ‘’’–help’’’ flag with no arguments. . Any other dataset can be used as long as the directory structure is same as that if LFW. . Start server . Run start-server script to start the server on localhost . ./bin/start-server . Usage docs . Nodoface: . Nodoface can be used without PMR-Core and Server. See nodoface/examples directory and nodoface/tests directory to learn the usage. . PMR-Core: . PMR-Core can be used without the Server but depends on Nodoface. Look for files ending with *test.ts in pmr-core/src to learn usage. Scripts provided in pmr-server/bin directory are also good place to explore. . PMR-Server: . See the endpoints in pmr-server/src/api/vX/*.ts. . Request/Response syntax can be understood by going through pmr-server/src/amzn-dtypes and pmr-server/src/pmr-dtypes. . At the time of writing, there is no UI for this server. I use Postman to test the endpoints. . Making requests to server . POST ‘‘/api/v0/detect-faces’’ Request body: . { “Image”: { “Bytes”: “base64-string-of-image” } } . | “Bytes” is the base64 string representation of input image. This is same as DataURL after removing the first intial characters “data:image/jpeg;base64,” (for jpeg image). I use https://www.base64-image.de to get base64 string while testing. . POST ‘‘/api/v0/recognize-celebrities’’ Request body: Same as that for detect-faces endpoint above. . | POST ‘‘/api/v0/celebrity-in-video’’ Request body: . { “Video”: { “Url”: “direct-downloadable-video-url” } } . | Handling response from server . The server follows a “Dispatch and Poll” method. Everytime a request is received, the server dispatches a “Job” and sends response immediately with the Job status. Sample response: . { &quot;JobId&quot;: &quot;string&quot;, &quot;JobStatus&quot;: &quot;PENDING&quot;, &quot;ResultUrl&quot;: &quot;url&quot; } . One can poll on the ResultUrl until JobStatus becomes “COMPLETED”. When that happens, the response will include output such as BoundingBox, Celebrity name, etc depending on the request. Also the RequestUrl of a COMPLETED job will point to output file with visualisations drawn (bonding boxes, labels, etc on image/video). Read this blogto learn more. . Useful links . My GSoC notes - https://github.com/sziraqui/pmr-gsoc-tracker/tree/master/notes . | Blog (GSoC final evaluation) - https://link.medium.com/qlbGEnFdyZ . | Contact details . Slack - @sziraqui . Email/Hangouts - sarfarazghlm[at]gmail[dot]com . LinkedIn - https://www.linkedin.com/in/sziraqui .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2019-sziraqui.html",
            "relUrl": "/2020/02/20/public-gsoc-2019-sziraqui.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post51": {
            "title": "Poor Man’s Rekognition",
            "content": "Mentor : Johannes Von Lochter . Developed under Google Summer of Code, 2019 with CCExtractor Development By Amit Kumar . Introduction . The main aim of the project is to make an open-source version of Amazon Rekognition which is a (paid) service that is able to identify objects, people, text, scenes, and activities in a picture. To accomplish this, I proposed a solution by using tech stacks such as Django, Django-Rest-Framework, ffmpeg, TensorFlow Serving and ReactJS. . Project Related Links . Project repository on GitHub: . https://github.com/pymit/Rekognition . https://github.com/pymit/RekoUI . Demo - Video: https://youtu.be/k_Xpy_oW1LQ . Project Progress: . https://github.com/pymit/Rekognition/projects . https://github.com/pymit/RekoUI/projects . Usage Docs . Once you setup the project locally, start the react app ( installation guide link is provided in installation section) visit http://localhost:3000/doc . Blog entry for final submission : (https://medium.com/@amkr/final-work-submission-gsoc19-ccextractor-development-40a2b6c6a946) . Installation . To setup the project locally follow below wiki link https://github.com/pymit/Rekognition/wiki/Project-Setup-in-Ubuntu-18.04 . Contact Details . Slack: @pymit . GitHub: @pymit . Twitter: @amit2rockon . Email: amit165@iiitkalyani.ac.in .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2019-pymit.html",
            "relUrl": "/2020/02/20/public-gsoc-2019-pymit.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post52": {
            "title": "Poor Man’s Rekognition",
            "content": "Mentor: Johannes Lochter . Introduction . Building a free version of Amazon rekognition with maximum possible feature during a 3 months’ time span. . Links . Proposal . GitHub(final submission) . Medium blog: https://medium.com/@b216029 (refer this for detailed information about each use-case) . independent github code: https://github.com/backSpace001/poor_man_rekognition . Use-cases . 1.Face and Eye Detection using OpenCV - - completed 👍 . 2.Facial recognition of a video using deep metric learning - - completed 👍 . 3.Celebrity Recognition - - completed 👍 . 4.Object Detection - - completed 👍 . 5.Read text in images - - completed . 6.Facial Analysis - - completed 👍 . Sad Happy Angry Disgust Fear Surprise Neutral . 7.Scene Detection - - completed 👍 . Libraries required . Note: (requirement.txt is already available in the repository) . OpenCV: For using cascade files Numpy: For array operations Matplotlib.pyplot : For plotting Pickle : For serializing and de-serializing Python object structures Keras : For importing neural network models Tensorflow : For CNN’s architecture and training Cython : To generate CPython extension modules Pillow : To load images from files Lxml : To use the ElementTree API Flask==1.1 gunicorn==19.3 werkzeug==0.15 opencv tesseract=3.02 numpy==1.11 scipy==0.18 scikit-learn&gt;=0.18 . Installation . 5 simple steps to download this repo, run in your local server and work on it accordingly. . Step 1. Download or clone this repo. . Step 2. Create a bin Folder inside the repo and download this weights from the link and paste it inside this bin folder https://drive.google.com/drive/folders/1hUY_n_H7jhdL9Z8yKKHZFB0wILGW_prH?usp=sharing (note-it is very big so couldn’t upload it in the github) . Step 3. Get the requirments by typing in the command. ‘&#39;’pip install -r requirements.txt’’’ . Step 4. You are good to go. RUN ‘&#39;’python app.py’’’ . Step 5. Open ‘&#39;’http://127.0.0.1:5000/’’’ in your browser . Use Cases . 1.Face and eyes detection using OpenCV: . OpenCV comes with a trainer as well as a detector. Here I have used OpenCV for detection and later in the project, I will use it to create an XML file of faces for Face recognition. OpenCV already contains many pre-trained classifiers for face, eyes, smiles, etc. Those XML files are stored in the Library/etc/haarcascades. In this part, I have used face cascade and eye cascade to detect face and eyes in an image. OpenCV uses a machine learning algorithm and it contains pre-trained cascade XML files which can detect a face, eyes, etc. This basically breaks the image into pixels and form blocks, it does a very rough and quick test. If that passes, it does a slightly more detailed test, and so on. The algorithm may have 30 to 50 of these stages or cascades, and it will only detect a face if all stages pass. This technique works on the Viola-Jones Algorithm, which is a part of deep learning. This statement was said on the context of:- deep learning is a class of machine learning algorithm that learns in supervised (e.g., classification) and/or unsupervised (e.g., pattern analysis) manners. This part of face detection is also used in facial recognition section and there I will use this the file as an unrecognized file to be saved in the database and to be used as another face with no name registered. Example rectangle features shown relative to the enclosing detection window. The sum of the pixels which lie within the white rectangles is subtracted from the sum of pixels in the grey rectangles. Two-rectangle features are shown in (A) and (B). Figure © shows a three-rectangle feature, and (D) a four-rectangle feature. . 2.Facial Recognition . I have used Deep Learning face recognition embedding. Here I am using deep learning and this technique is called deep metric learning.In deep learning typically a network is trained to: Accept a single input image And output a classification/label for that image However, deep metric learning is different. Instead, of trying to output a single label (or even the coordinates/bounding box of objects in an image), instead of outputting a real-valued feature vector. For the dlib facial recognition network, the output feature vector is 128-d (i.e., a list of 128 real-valued numbers) that is used to quantify the face. Training the network is done using triplets: Facial Recognition via Deep metric learning involves “triplet training step” I have first created a database for the training set and encoded (128-d) each face image into a numpy array and turn it into an XML file. Second I have imported that trained XML file into the main script to detect and recognize a face. . 3.Celebrity Recognition . This part is same as the above one the only reason I made it a different sector is because this feature is listed in Amazon’s rekognition project and as this is a similar project I have to add this additional name tag and create a whole new dataset consisting of many known actors. Here I have also used deep metric learning techniques. . 4.Object detection . Object Detection is the process of finding real-world object instances like car, bike, TV, flowers, and humans in still images or Videos. It allows for the recognition, localization, and detection of multiple objects within an image which provides us with a much better understanding of an image as a whole. It is commonly used in applications such as image retrieval, security, surveillance, and advanced driver assistance systems (ADAS). I have performed this using YOLOv2 on an image and a video file. You only look once (YOLO) is a state-of-the-art, real-time object detection system. On a Titan X, it processes images at 40–90 FPS and has an mAP on VOC 2007 of 78.6% and an mAP of 48.1% on COCO test-dev. One can find all the details about YOLOv2 here: https://arxiv.org/pdf/1612.08242.pdf https://www.youtube.com/watch?v=NM6lrxy0bxs . 5.Read text in images . Extraction of text from an image is a subpart of image processing and is called OPTICAL CHARACTER RECOGNITION (OCR). I have used Tesseract which is an OCR engine developed by Google. It supports Unicode and has the ability to recognize more than 100 languages. . 6.Facial expression recognition . https://medium.com/@b216029/report-3-494b2fdbb179 (refer this for this part) . 7.Scene detection . Citation - www.algorithmia.com I have coded to implement my part so as to perform the task, all the data will be provided by algorithmia and can be seen in the algorithmia website itself. My code will mere be a bridge. [note-this part is not included in the web app because of some complexity] Scene detection is used for detecting transitions between shots in a video to split it into basic temporal segments. It helps video editors to automate the process of quickly splitting videos in bulk rather than editing it frame by frame by hand. To run scene Detection Follow this steps: . 1.Create an account on Algorithmia (includes 5,000 free credits each month). . 2.Go to your profile page, click the Credentials tab, and find your API key. . 3.Find a test video. You can use a public URL (/ccextractor-wiki-test/2020/02/20/prefer Vimeo over youtube), or upload one to their hosted data storage. . 4.Install the Python Algorithmia client using the command “pip install algorithmia“. . 5.Copy the sample code below, replace YOUR_API_KEY with your own key, and run it to extract the scenes from your video! .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2019-faizkhan.html",
            "relUrl": "/2020/02/20/public-gsoc-2019-faizkhan.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post53": {
            "title": "Project Nephos",
            "content": "//Developed under Google Summer of Code, 2018 with CCExtractor Development By Shivam Kumar Jha// . . Introduction . Project Nephos aims at simplifying the process of moving samples from local storage to cloud for Universities by automating, almost, all the steps involved. It consists of three independent modules; recording module, processing module, and uploading module. . The recording module is responsible for managing the addition of channel lists, set up of recording jobs and saving the recorded streams. The processing module parses saved samples, associates tags, extracts subtitles and converts the video files to MP4 to reduce the file size. The uploading module then uploads the processed stream files to FTP server (if config is completed) and Google Drive, and also shares the sample with other universities (whose email addresses must be provided) if required. . Nephos has been developed, using Python and few other open source projects, to accomplish all the above-mentioned tasks with cent-percent reliability and zero failures (unless wrong data is input, which will get logged). Testing and logging has been an integral part of Nephos development and running cycle, respectively. . Project Related Links . Project Repository on GitHub Nephos . | My blogs on the project GSoC Blogs . | . Installation . &#39;’git clone https://github.com/thealphadollar/nephos.git’’ &amp;&amp; ‘‘cd nephos’’ . | On centOS 6 run the script, ‘‘sudo ./install.sh’’ . | Observe and modify configurations available in ‘‘$HOME/Nephos/config’’ (especially maintenance and module configurations, and processing script) . | Add nephos_start.sh as a cron job to be executed at startup in root crontab. ‘‘@restart /path/to/nephos_start.sh 2&amp;&gt; ~/Nephos/boot_start.log’’ . | Run nephos using ‘‘sudo ./nephos_start.sh’’. This command runs Nephos under a new screen session. Press ‘‘ctrl + a’’ and then ‘‘d’’ to detach from the session while it keeps running in the background. . | You can see the recordings in Google Drive of your linked Google Account. The logs of the program are uploaded to “Nephos_Logs” folder for Redhen account. . | . To Add Channels And Jobs . Please go to Nephos Config repository to modify the channels, jobs and share lists that Nephos works on. . Developer’s Documentation . Developers can view the documentation that is present for users since it is detailed and one needs to read it in order to understand how Nephos functions. Along with that, docstrings have been placed in HTML format in docs/DevDocs and can be accessed in a systematic manner by opening ‘‘docs/DevDocs/nephos.html’’ in a browser. . They can also be viewed here. . More Info . For more information regarding using Nephos and how it works, visit the wiki .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2018-thealphadollar.html",
            "relUrl": "/2020/02/20/public-gsoc-2018-thealphadollar.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post54": {
            "title": "CCExtractor Web : A web application for subtitle extraction through CCExtractor.",
            "content": "//Developed under Google Summer of Code, 2018 with CCExtractor Development By Saurabh Shrivastava // . Blog entry for final submission : (https:saurabhshri.github.io/gsoc-2018-final-submission) // . . . Introduction . The aim of the project is to create an easy to use web application that can be hosted on a web-server for subtitle extraction using CCExtractor. The idea is simple – the users do not need to install CCExtractor on their own machine, they can directly use the web application to process their files anytime, anywhere. It would also serve as an easy interface for first-time developers (notably GSoC and GCI students) to experience the extraction process. . The high-level workflow for this project basically involves obtaining files from the user along with suitable parameters, passing them to the CCExtractor, processing the files, obtaining output file and making it available for download. Other things include, but is not limited to, user management, file management, record maintenance, multiple CCExtractor binary options, and API. . Project Related Links . Project repository on Github: https://github.com/saurabhshri/ccextractor-web . | Project readme : https://github.com/saurabhshri/ccextractor-web/blob/development/README.adoc . | Project documentation : https://github.com/saurabhshri/ccextractor-web/blob/development/docs/ . | Project link on official GSoC web-app : https://summerofcode.withgoogle.com/projects/#5789900830408704 . | Mentors : @canihavesomecoffee and @alexbrt . | . The project was built by me individually with the invaluable help from my mentors. All the external libraries and code used are credited wherever due. . Technical Documentation . All the technical details are commented in the codes and the documentation is available in the readme of the repository (linked above). Code is properly commented and the variables, classes and other components are named properly in CamelCase for easier understanding of the code. Find compiling, installing, usage instructions and docs here : https://github.com/saurabhshri/ccextractor-web . Known Issues / Future Work Needed . The project is in its very early stage and is constantly evolving. The available functions, usage instructions et cetera are expected to refactor over time. Feel free to contribute and improve the project. Currently, files could only be uploaded from a user’s file system. In future, I would like to add the capability to add files from cloud storage like Google Drive and add batch processing. Feel free to raise any issue in the repository’s issue tracker : https://github.com/saurabhshri/ccextractor-web/issues . Read More . More information and news related to the project could be found at the links attached above and would be posted from time to time on my blog : https://saurabhshri.github.io .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2018-saurabh.html",
            "relUrl": "/2020/02/20/public-gsoc-2018-saurabh.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post55": {
            "title": "The sample platform / Continuous integration",
            "content": "//Developed under Google Summer of Code, 2018 with CCExtractor Development By Satyam Mittal // . . Introduction . The CCExtractor Sample Platform manages a test suite bot, sample upload and more. This platform allows for a unified place to report errors, submit samples, view existing samples and more. The sample platform has been a good way to test regression tests, but still lacks some features such as running customized tests. . The main aim of the project is to make sample platform fully finalized and be as stable as possible. It will include adding some new features and some fixes which will increase the stability of the platform. The features and fixes are given below. —- . Detailed Description/Timeline . Comment on the opened PR if a test fails . | Add support for running the bot in forks . | Add support for single test runs or smaller sample sets . | Foundation upgrade broke lay-out . | Migration to Python-3 . | Adding Restart / Stop for admin and user . | . . Original​ ​ Vs​ ​ Achieved​ ​ Goals . Comment on the opened PR if a test fails: Now users can easily see the textual overview of what is failing. It is always better to comment the all failing tests on the Pull Request. It will save the time of user by summarizing the error on the same pr and easily check the status of pull request. Template shown below: . | Add support for running the bot in forks: It has been added and working properly. Now Users can enter commit or select the commit from their fork repository that are not more than 30 days old. They can select the platforms (linux, platform) they want to run their tests. List of tests started by user are displayed on same page. . | Add support for single test runs or smaller sample sets: Now Users can customize tests based on selected regression tests and platforms. They can run their test on subset of regression tests. Test Progress will be displayed according to selected regression tests. Active Status has been added to Regression tests. Regression test status will tell whether it will run on test of main repository or not. Combined with previous feature, Customized Test would give the contributors full freedom to experiment with fixes on their forks. . | Foundation upgrade broke lay-out: After Foundation upgrade, there were some UI fixes left. All the pages are mobile responsive. I fixed broken layout, fixed design of some pages and made tables mobile-responsive. . | Python-3.6 Migration: Platform Python version has been migrated from 2.7 to 3+. . | Adding Restart / Stop for admin and user: A button has been added in the admin test panel to make it easy for admin to stop or restart the test. After adding single test, corresponding user can stop the test or restart if he thinks somewhere he went wrong before test completes to decrease the load in the platform. . | Documentation: All changed set has been properly documented. I have added pydocs from methods and inline comments. I have followed pep8 while adding pull request. User documentation has been updated. . | Unittesting: I have increase the test coverage to around 60%. It is still in progress. . | . . Project Related Links . Github Project repository: https://github.com/canihavesomecoffee/sample-platform . | Project documentation : https://github.com/canihavesomecoffee/sample-platform/blob/master/README.md . | Project Proposal: https://docs.google.com/document/d/1sOwdF_924WUYEGDB6IM-caZzepp0-tutLpjfUI-xT88/edit?usp=sharing . | Official GSoC Project Link: https://summerofcode.withgoogle.com/projects/#4548101499518976 . | Mentor: Willem Van Iseghem . | Hosted Project Server Link: https://sampleplatform.ccextractor.org/ . | . . Contributions[Commits/PRs] . All my commits to the repository can be found here: Commits . All my pull requests to the repository can be found here: Pull Requests . . Other Works . I keep on fixing new bugs/issues raised in issue tracker time to time. I will try my best to have smooth functioning of the sample platform. . . What I have learned . Doing​ ​this​ ​project​ ​is​ ​a ​lot​ ​fun​ ​with​ ​a lot​ ​of​ ​things​ ​to​ ​learn.​ ​The​ ​number​ ​of​ ​such​ ​things​ ​is​ ​more than​ ​I ​​can​ ​even​ ​write​ ​but​ ​summing​ ​up​ ​all​ ​this​ ​the​ ​major​ ​things​ ​which​ ​I ​learn​ ​includes​ ​ : . I have been contributing in CCExtractor CI platform from last 1.5 years and the journey has been great, I have learned a lot from working in different modules and also got an opportunity to discover many concepts behind some modules. The project help me how to work in a team and in systematic way. | Putting​ your​ doubts​ in​ front​ ​of​ ​others​ ​as​ ​during​ ​this​ ​period​ ​a number​ of​ errors​ ​will​ ​come and​ ​you​ ​should​ ​have​ ​to​ ​ convey​ ​what​ ​you​ ​want​ ​to​ ​say​ ​to​ ​others,​ ​seems​ ​easy​ ​but​ ​not​ ​that for​ ​me​ ​atleast. | Importance​ ​of​ unit-testing, ​indentation​, ​documentation​ ​as​ ​during​ ​this​ ​period​ | . Known Issues/ Future Work . Since the part of work that I have done in CCextractor’s Sample Platform was done with altmost care according to my knowledge, therefore I would try to remove any bug in part of my code reported by someone else or encountered by me. . | Apart from CI platform, I will try my best to contribute in other ongoing projects in CCExtractor organization. . | . . Addendum . I am doing my 4rth year of graduation. I will keep contributing to the sample platform. Apart from that, I will continue to do my best and contribute to the organization. . . Contact Details . If you have any doubts or suggestions you can contact me anytime you want. Here are the details : . Email address : satyammittalid@gmail.com . Github : satyammittal . Blog: Wordpress . Slack : bashtech . . Thanks .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2018-satyam.html",
            "relUrl": "/2020/02/20/public-gsoc-2018-satyam.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post56": {
            "title": "Introduction",
            "content": "Videos contain plethora of contextual information. For example, in a movie there are fighting scenes, sentimental scenes, romantic scenes, and many others. In a cricket match, there are wickets, sixes, fours et cetera. With the advent of the data-driven age, amateurs, researchers, and organisations alike require some specific part of this contextual information for their needs; maybe for creating a highlights reel of a sports match or mining data from movies for their machine learning models. This makes parts of certain types of videos very useful. FabBits tries to automate finding them. Following are the things it will be able to detect - . Action sequences in movies/shows - ✅ . | Summary of movies/shows - ✅ . | Actor-specific scenes in movies/shows - ✅ . | Jokes in sitcoms - ✅ . | Slo-mos in Sports - ❌ . | Goals in Soccer - ✅ . | Goal misses in Soccer - ⭕ . | Three pointers in Basketball - ✅ . | . Links . Project repo - github.com/achie27/FabBits Blog posts - medium.com/@achie27 Samples - Drive folder . Requirements . You need the following things to run FabBits- . Python3 | OpenCV - Used for image and video processing | Moviepy - Used for video editing and audio processing | PyQt5 - Used to make the GUI | Scipy - Used for audio processing | Tesserocr - Used for, well, OCR | Pillow - Used to preprocess images for OCR The python dependencies can be installed by running - . pip3 install scipy pip3 install opencv-python pip3 install moviepy pip3 install pyqt5 pip3 install Pillow pip3 install tesserocr . | or if you are the Anaconda kind - . conda install -c conda-forge scipy conda install -c conda-forge opencv conda install -c conda-forge moviepy conda install -c anaconda pyqt conda install -c conda-forge pillow conda install -c simonflueckiger tesserocr . Usage . Run the main GUI by - python3 main.py . To find your FabBit of choice - . Click ‘‘MOVIES’’ or ‘‘SPORTS’’ button for their respective use-cases . | Select the use-case from the sidebar A pop-up dialog will ask for the actor if actor-specific scene was chosen | . | Click on ‘‘Choose File’’ to select the input video . | Click on ‘‘Find FabBits’’ . | Move the slider in the blue areas, which are the extracted FabBits, and play the video . | Click on ‘‘Save FabBits’’ to save the extracted stuff into a video file | . You can also run the respective files of use-cases to get their FabBit, like - python3 goal_detector.py soccer_match.mp4 . References . All the references can be found listed in the repository’s readme. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2018-achie27.html",
            "relUrl": "/2020/02/20/public-gsoc-2018-achie27.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post57": {
            "title": "Project Nephos",
            "content": "//Developed under Google Summer of Code, 2018 with CCExtractor Development By Aaditya M Nair// . . Introduction . One of the function of the RedHen Organisation is to record and archive Television streams they receive for future research. Project Nephos is an effort by CCExtractor to automate the entire process. Archiving is done by compressing and uploading to Google Drive. In addition to downloading and archiving, Project Nephos provides the following functionalities: . Tagging of videos. | Searching archived videos. | Sharing videos with other entities | Project Related Links . Project Repository on GitHub Project Nephos . | My blogs on the project Blog Reports . | Sample Recordings here . | . Installation . git clone https://github.com/AadityaNair/ProjectNephos.git pip install ./ProjectNephos . Usage Documentation . Below is how you would manually use Nephos to perform actions manually. This requires the config file to be present. More information on the config file in the Configuration section. . Uploading files . nephos upload `&lt;filename&gt;` . Searching . nephos search --name `&lt;name&gt;` --tags `&lt;tag1&gt;` `&lt;tag2&gt;` ... --do_and . Search for files with &lt;name&gt; and/or tags &lt;tag1&gt; &lt;tag2&gt; …’’. The and/or part will be decided by the ‘‘do_and’’ parameter. If specified, all parameters (name, tags) will be joined by an AND i.e it will search for ”&lt;name&gt; AND &lt;tag1&gt; AND &lt;tag2&gt; …“ If not, ANDs will be replaced by ORs. . Atleast one of ‘’–name’’ and ‘’–tags’’ is required. . Tagging . nephos tag --for_name `&lt;name&gt;` --add_tags `&lt;tag1&gt;` `&lt;tag2&gt;` ... . This searches for all instances that contain &lt;name&gt; and for each of them, add the provided tags. . Processing . nephos process `&lt;input_file&gt;` `&lt;output_file&gt;` . Converts the input file to output file. The formats are guessed by their extensions. . Permissions . Share uploaded videos with people based on the video tags. . nephos permission add --for_tags `&lt;tag1&gt;` `&lt;tag2&gt;` --share_with `&lt;email&gt;` . This command is persistent. This means that all future videos with the tag will also be shared. To avoid this action pass ‘’–not_persistent’’ to the command. . Note, The tags provided follow the OR semantics. i.e. in the above example, every file with the tag tag1 . OR tag2 will be shared. . To view all permissions, . nephos permission list . More information can be found for each sub-command by using the ‘’–help’’ option after the sub-command . Automation . For the most part you want to just specify what to record and when leave Nephos at it. For that: . Add channels . Add channel to specify where to download stuff from . nephos channel add --name &#39;CNN&#39; --ip_string &#39;1.2.3.4:5678&#39; . Note that the ‘‘name’’ should be unique for each channel. . To view added channels. . nephos channel list . Add job. . Specify when to download other post download options. . nephos job add --name `&lt;jobname&gt;` --channel `&lt;channel&gt;` --start `&lt;starttime&gt;` --duration `&lt;length&gt;` --upload --convert_to `&lt;format&gt;` --tag `&lt;tag1&gt;` `&lt;tag2&gt;` . Following are mandatory arguments: ‘’–name’’ is the name of the job. This should be unique for each job. ‘’–channel’’ is the name of the associated channel. This channel should have already been added by the ‘‘channel add’’ subcommand. ‘’–start’’ is the start time of the job written in the popular cron format. For more info on the format go here. This was used as an reference. ‘’–duration’’ is how long you want to record. This is provided in minutes. . Rest are optional arguments: ‘’–upload’’ instructs nephos to upload the file to Google Drive. This will most likely be the default case in the future versions. In such a case, this option will be removed. ‘’–convert_to’’ makes so that the downloaded file is converted to the provided format before being uploaded. ‘’–tag’’ tags the uploaded file with the provided tags. . Note that ‘’–tag’’ is dependent providing the ‘’–upload’’ option. If it not provided ‘’–tag’’ is a NOOP. . TV Listings . Nephos also has a crude API that supports TV listings. . nephos schedule add --name `&lt;program_name&gt;` --channel `&lt;channel&gt;` --start `&lt;starttime&gt;` --duration `&lt;length&gt;` --tags `&lt;tag1&gt;` `&lt;tag2&gt;` . This syntax is pretty much exactly the same as for the ‘‘job add’’ above. The tags are associated with the program. This allows for a separate syntax to add a job: . nephos job add --name `&lt;jobname&gt;` --program_tags `&lt;tag1&gt;` `&lt;tag2&gt;` .. --upload --convert_to `&lt;format&gt;` --tag `&lt;tag1&gt;` `&lt;tag2&gt;` . This will find all programs with any of the provided tags and add them as jobs. . Initialise Server . This starts the orchestration server which is responsible for the record -&gt; process -&gt; upload pipeline. This will also create all the relevant directories and perform OAuth with google drive, if not done already. . nephos init . Currently, if a job is added after the server is started, it will not be picked up by the server. So, make sure you add all the jobs before starting the server. This will be fixed in a later version. . Contributing and other information . Currently the project lives on the above provided github link. . The wiki contains more information about the internals of the project. . There is still a lot of stuff that can be improved here. Have a look at the issues to know what can be done and don’t hesitate to create a new one if you find something new. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2018-aaditya.html",
            "relUrl": "/2020/02/20/public-gsoc-2018-aaditya.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post58": {
            "title": "CCAligner : Word by Word Audio Subtitle Synchronisation",
            "content": "//Developed under Google Summer of Code, 2017 with CCExtractor Development By Saurabh Shrivastava // . Blog entry for final submission : (https:saurabhshri.github.io/gsoc-final-submission/) // . Introduction . The usual subtitle files (such as SubRips) have line by line synchronisation in them i.e. the subtitles containing the dialogue appear when the person starts talking and disappears when the dialogue finishes. This continues for the whole video. For example : . 1274 01:55:48,484 -&gt; 01:55:50,860 The Force is strong with this one . In the above example, the dialogue ‘‘#1274’’ - ‘‘The Force is strong with this one’’ appears at ‘‘1:55:48’’ remains in the screen for two seconds and disappears at ‘‘1:55:50’’. . The aim of my GSoC project was to build a tool for word by word synchronisation of subtitles with audio present in the video by tagging each individual word as it is spoken, similar to that in karaoke systems. I have named my project CCAligner as it conveniently lays out it’s basic functionality. . E.g. . The [6948484:6948500] Force [6948501:6948633] is [6948634:6948710] strong [6948711:6949999] with [6949100:6949313] . In the above example each word from subtitle is tagged with beginning and ending timestamps based on audio. . . CCAligner makes use of automatic speech recognition to analyse audio and recognise words to perform alignment. The project comprises of both user friendly tool and developer friendly API. . Project Related Links . Project repository on Github: https://github.com/saurabhshri/CCAligner . | Project readme : https://github.com/saurabhshri/CCAligner/blob/master/README.adoc . | Project documentation : https://github.com/saurabhshri/CCAligner/blob/master/docs/ . | My blog (includes weekly GSoC posts) : https://saurabhshri.github.io . | Milestones and deliverable checklist : https://saurabhshri.github.io/gsoc/ . | Project link on official GSoC web-app : https://summerofcode.withgoogle.com/projects/#5589068587991040 . | Project proposal : https://github.com/saurabhshri/saurabhshri.github.io/blob/master/GSoC/ . | Mentors : @cfsmp3 and @AlexBratosin2001 . | . The project was built by me individually. All the external libraries and code used are credited wherever due. . Technical Documentation . All the technical details are commented in the codes and the documentation is available in the readme of the repository (linked above). Code is properly commented and the variables, classes and other components are named properly in Camel Case for easier understanding of the code. Find compiling, installing, usage instructions and docs here : . https://github.com/saurabhshri/CCAligner | . Additional Work . In addition to my main project, I also worked on creating a single header SubRip subtitle parser library in C++ and contributing to various open source projects, including, but not limited to CCExtractor, Sample-Platform, AutoEdit2, Rhubarb Lip Sync, CMUSphinx. . Created a single header SubRip subtitle parser library in C++. This served as a core in CCAligner subtitle handling. It has very huge number of options available, and is very simple to use. | Project repository : https://github.com/saurabhshri/simple-yet-powerful-srt-subtitle-parser-cpp . | Documentation : https://github.com/saurabhshri/CCAligner/tree/master/docs . | . Improving existing CCExtractor features, fixing issues and help in PR and code reviews. | All my commits to CCExtractor repository : https://github.com/CCExtractor/ccextractor/commits?author=saurabhshri | . Improving CCExtractor’s sample-platform, fixing and reporting issues, and help in PR and code reviews. | All my commits to Sample-Platform repository : https://github.com/canihavesomecoffee/sample-platform/commits?author=saurabhshri | . Link to my Github profile : https://github.com/saurabhshri | Some Demostrations . Karaoke Demo 2 [Ted Talk] | . . Karaoke Demo 3 [Cartoon Show] | . . Karaoke Demo 4 [Discussion Video] | . . Transcription Demo [Reality Show] | . . Third party libraries and dependencies . All the third party libraries are located in src/lib_ext and along with their individual licenses. . PocketSphinx : PocketSphinx is a lightweight speech recognition engine. It is portable and is used in ASR based alignment. (https:github.com/cmusphinx/pocketsphinx)// . | SphinxBase : Basic libraries as well as some common utilities for manipulating acoustic feature and audio files. This is used by PocketSphinx. (https:github.com/cmusphinx/sphinxbase)// . | srtparser.h : srtparser.h is a single header, simple and powerful C++ srt subtitle parsing library that allows to easily handle, process and manipulate srt subtitle files. (https:github.com/saurabhshri/simple-yet-powerful-srt-subtitle-parser-cpp)// . | webRTC : WebRTC is a free, open project that provides browsers and mobile applications with Real-Time Communications (RTC) capabilities via simple APIs. It is used to perform VAD in the project. (https:webrtc.org)// . | Known Issues / Future Work Needed . The project is in it’s very early stage and is constantly evolving. The available functions, usage instructions et cetera are expected to refactor over time. Feel free to contribute and improve the project. Currently, officially only US English is supported. For other languages and accents, a proper trained acoustic model could be supplied and experimented with. Text tokenisation within the program needs improvement. Feel free to raise any issue in the repository’s issue tracker : https://github.com/saurabhshri/ccaligner/issues . Read More . More information and news related to project could be found at the links attached above and would be posted from time to time on my blog : https://saurabhshri.github.io .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2017-saurabh.html",
            "relUrl": "/2020/02/20/public-gsoc-2017-saurabh.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post59": {
            "title": "Enable automated testing on windows and other general sample platform improvements",
            "content": "//Developed under Google Summer of Code, 2017 with CCExtractor Development By Satyam Mittal // . . Introduction . The CCExtractor Sample Platform manages a test suite bot, sample upload and more. This platform allows for a unified place to report errors, submit samples, view existing samples and more. The sample platform has been a good way to test regression tests, but still lacks windows support. It needs some improvements that are listed on issue tracker. . The main aim of the project is to extend the support of sample platform to windows. The focus of the project would be to add some add-on features to sample platform such as FTP upload support, improved error detection and github integration that helps user to have a single place to upload,view samples and associated test results. —- . Detailed Description/Timeline . Windows Support . | FTP Upload Support . | Github Integration . | Improved error detection . | Other small listed improvements on the issue tracker . | . . Original​ ​ Vs​ ​ Achieved​ ​ Goals . Windows CI Testing: Now Windows Testing Support has been added and it is done in parallel to linux testing. After addition of Windows Support, It will help to report errors of running ccextractor on windows and to check samples supported on windows of various PRs. . | FTP support: It has been added and working properly. Using FTP, a user can perform a mass upload to a server, not having to worry about repeatedly having to re browse for files and re-upload them using one form. User can easily upload large files using FTP. . | Github integration: Now Users can connect their github account to sample platform that enables them to report issue regarding a sample. They can see the list of issues and their status (active/closed) through sample platform. . | Waiting time feature: Users will see the estimated waiting for each test on sample platform while test is in queue. They don’t have to sit on the platform for whole time. They could take a leap and come after estimated time. . | Media info: Now Platform will hide the sample info that has no media info or just partial media info. . | Improved Error Detection: Improved mimetype checks: I have added a back-end check for file upload through mimetype prediction. However It will not be 100% accurate. But safer than just frontend check. | Cmake, builddebug, autoconf scripts: Now I have added different build checks whether they are successful or not. | . | Auto-update of test progress: While the test runs, it automatically updates the page on transition from preparation-&gt;building-&gt;testing-&gt;completed. . | Maintenance Mode: Added maintenance mode such that admin can easily make put virtual machines under maintenance mode and can make changes in it without taking care of future tests. . | Documentation: All changed set has been properly documented. I have added pydocs from methods and inline comments. I have followed pep8 while adding pull request. . | Unittesting: This needs to be done. | . . Project Related Links . Github Project repository: https://github.com/canihavesomecoffee/sample-platform . | Project documentation : https://github.com/canihavesomecoffee/sample-platform/blob/master/README.md . | Project Proposal: https://docs.google.com/document/d/1BEE4wh7wSyGYLQPU3f5jUotSHqfDQ__za1xMt6NNvNs/edit?usp=sharing . | Official GSoC Project Link: https://summerofcode.withgoogle.com/projects/#5205435270299648 . | Mentor: Willem Van Iseghem . | My blog (updates on weekly basis): https://satyammittal.wordpress.com/ . | Hosted Project Server Link: https://sampleplatform.ccextractor.org/ . | . . Contributions[Commits/PRs] . All my commits to the repository can be found here: Commits . All my pull requests to the repository can be found here: Pull Requests . . Other Works . I keep on fixing new bugs/issues raised in issue tracker time to time. I will try my best to have smooth functioning of the sample platform. . . What I have learned . Doing​ ​this​ ​project​ ​is​ ​a ​lot​ ​fun​ ​with​ ​a lot​ ​of​ ​things​ ​to​ ​learn.​ ​The​ ​number​ ​of​ ​such​ ​things​ ​is​ ​more than​ ​I ​​can​ ​even​ ​write​ ​but​ ​summing​ ​up​ ​all​ ​this​ ​the​ ​major​ ​things​ ​which​ ​I ​learn​ ​includes​ ​ : . I have been contributing in CCextractor testing platform from last 5-6 months and the journey has been great, I have learned a lot from working in different modules and also got an opportunity to discover many concepts behind some modules. The project help me how to work in a team and in systematic way. | Putting​ your​ doubts​ in​ front​ ​of​ ​others​ ​as​ ​during​ ​this​ ​period​ ​a number​ of​ errors​ ​will​ ​come and​ ​you​ ​should​ ​have​ ​to​ ​ convey​ ​what​ ​you​ ​want​ ​to​ ​say​ ​to​ ​others,​ ​seems​ ​easy​ ​but​ ​not​ ​that for​ ​me​ ​atleast. | Importance​ ​of​ ​indentation​ ​and​ ​documentation​ ​as​ ​during​ ​this​ ​period​ | . Known Issues/ Future Work . There are still some issues listed in issue tracker. I ​ have a good understanding of how the current CCextractor’s Testing platform works. I could track down the cause of the bugs quickly. I would like to fix them. . | Since the part of work that I have done in CCextractor’s Sample Platform was done with altmost care according to my knowledge, therefore I would try to remove any bug in part of my code reported by someone else or encountered by me. . | . . Addendum . I am doing my 3rd year of graduation. I will keep contributing to the sample platform. Apart from that, I will try to become active contributor of main repository. I would like to seek the opportunity to do 2nd time GSoC with the CCextractor. . . Contact Details . If you have any doubts or suggestions you can contact me anytime you want. Here are the details : . Email address : satyammittalid@gmail.com . Github : satyammittal . Blog: Wordpress . Slack : bashtech . . Thanks .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2017-satyam.html",
            "relUrl": "/2020/02/20/public-gsoc-2017-satyam.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post60": {
            "title": "Python Extension Module (bindings) for CCExtractor",
            "content": "//Developed under Google Summer of Code, 2017 with CCExtractor Development By Diptanshu Jamgade// . . Introduction . CCExtractor is a software written in C language. The main aim of this project was to generate the python extension module for CCExtractor which would then help Python developers to extend the applications of CCExtractor in Python. . The main ideology of the module was to extract the captions using CCExtractor and parse the extracted captions to Python for processing them. The module was desired to be structured in such a way that the captions arrive in Python as soon as they are extracted by CCExtractor. Thus, the captions could be processed in real-time via Python rather than waiting for the extraction to finish. Also, the extension module is expected to be silent, i.e. not outputting any STDOUT information. . The module was needed to be silent in terms of all the output generated by CCExtractor. The output files were to be generated via Python and not via CCExtractor as the module’s prime duty was to extract the captions in CCExtractor and parse the extracted captions to Python for processing. . . Project Related Links . Project Repository on GitHub CCExtractor . | Project Documentation Documentation . | Project Proposal for GSOC 2017 . | Official GSOC Project link Project . | My blog Blog . | Mentor @cfsmp3 . | . . Installation . For installing the Python extension module, the user needs to make sure that the user has compiled/installed all the dependencies for CCExtractor (mentioned here). . After the user has compiled/installed all the dependencies for CCExtractor, for installing Python extension module, the user needs to install two dependencies: . SWIG swig | Python-dev package ubuntu For other operating systems, the user has to install python-dev package as mentioned in the corresponding system’s documentation. | After the user has compiled/installed the additional dependencies for Python Extension module, the user can install the extension module by sudo pip install ccextractor OR pip install ccextractor –user (the above method has been successfully tested on unbuntu16.04 - Xenial) . In case of virtual environments, the user can install the Python Extension module by pip install ccextractor . After the user has successfully installed the extension module, the user can test the module as per the test script which is used for processing a single sample. However, if the user desires to process all the samples in a particular directory then the user can use this test script. . NOTE: In case the installation fails, make sure you have updated setuptools, pip and also installed/compiled all the dependencies mentioned in this section. . Technical Documentation . Architectural Documentation . The overall documentation for the extension module as to how has the module architecture designed and how the further contributors can continue development has been done in this documentation. . Dependency Documentation . For the contributors who want to either just install the dependencies for the extension module documentation would help them understand the dependency compilation. . Contributor Documentation . For contributors who wish to understand how exactly is the CCExtractor Extension module compiled and installed on a system, this documentaion contains relevant information. . . Contributions [PRs/Commits] . All the commits made by me to the CCExtractor repository could be found here. . All the pull requests by me to the CCExtractor repository could be found here. . . Bugs Tracked . I have worked on solving issue #705 and submitted a PR(merged), thus solving the issue. . | I have also worked on issue #304. I analyzed the issue’s sample and found some errors in the way the sample information was encoded. A detailed discussion is present at our Slack under channel bug304. . | . . GSOC 2017 Experience . The overall GSOC experience was really wonderful and the entire team here at CCExtractor was really helpful. The project was really challenging and helped me learn a great deal of basic as well as advanced concepts for software development. . The project included additions in CCExtractor source code as well as additions in Python extension module part to continue the processing of captions via Python. Thus, the project was really helpful in exploring concepts of C as well as Python. In addition to these, I also learnt a number of technologies such as SWIG, Python C-API, GCC- compiler basics as well as advanced topics, GDB, etc. . Moreover, this project helped me get a much deeper knowledge of Open Source Software Development. . . About me . I am final year student studying at IIT Kharagpur, India. I would definitely be an active contributor not only for CCExtractor extension module but also the Sample-Platform as well as CCExtractor. . Email address : diptanshuj@gmail.com . Blog : https://diptanshujamgade.wordpress.com . GitHub profile: https://github.com/Diptanshu8 . Slack : skrill . . Thank you. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2017-diptanshu.html",
            "relUrl": "/2020/02/20/public-gsoc-2017-diptanshu.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post61": {
            "title": "Improving GitHub CI",
            "content": "This year of GSoC focused on improving the existing tools I wrote the previous years (2014 &amp; 2015) to achieve full GitHub integration. . This was achieved through: . A full rewrite of the existing sample platform for compatibility reasons . | Migrating the VirtualBox VM environment to a KVM enviroment to ensure that tests run in a decent amount of time, while staying secure. . | Running tests under the Windows platform. . | Integrating the platform with GitHub using webhooks . | . Rewrite of the sample platform . Last year’s sample platform was written using PHP (https://github.com/canihavesomecoffee/ccx_submissionplatform/), and that choice induced some problems regarding the ease of operating when combining the platform with the bot. . To get rid of these issues, a rewrite of the platform was required. A switch to python (in which the previous github bot was written already) was made. . The platform is currently running live at https://sampleplatform.ccextractor.org/, and the source code for the entire platform &amp; GitHub integration can be found on https://github.com/canihavesomecoffee/sample-platform. . The platform isn’t fully finished yet, though it is usable; These things still need to be done: . Re-enable FTP upload . | Finish the management of regression tests . | Let users schedule tests from forks . Migration from VirtualBox to KVM . | . As the VirtualBox solution from last year proved to be terribly slow, this year, a migration to KVM was done. . This involved the following steps: . Installing KVM . | Getting the API bindings . | Create a Linux VM, and configure it . | Program the platform to revert to a snapshot and run the test suite . | . The code for this is fully integrated into the Sample Platform, and as such can be found there. . Windows testing . This part is unfinished. A windows VM needs to be created &amp; configured, a startup service needs to be written (that can handle the automated compilation of CCExtractor under Windows), and the lines of code in the platform that handle the VM need to be uncommented. . Integration with GitHub . Using the webhooks GitHub provides, a full integration with their platform could be made. . GitHub informs us of new pushes and pull requests, and the platform subsequently queues and executes the tests for given commit or PR. This code is also fully integrated into the platform, but mod_ci is the place where all the magic happens. . Other work . Besides the work detailed above, some patches for CCExtractor were contributed: . https://github.com/CCExtractor/ccextractor/pull/363 https://github.com/CCExtractor/ccextractor/pull/365 https://github.com/CCExtractor/ccextractor/pull/382 https://github.com/CCExtractor/ccextractor/pull/383 https://github.com/CCExtractor/ccextractor/pull/386 https://github.com/CCExtractor/ccextractor/pull/399 https://github.com/CCExtractor/ccextractor/pull/403 . Next to that, some fixes to the test suite also were made: . https://github.com/canihavesomecoffee/ccx_testsuite/commits/master .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2016-willem.html",
            "relUrl": "/2020/02/20/public-gsoc-2016-willem.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post62": {
            "title": "Introduction",
            "content": "The commercial detection system identifies and reports the location of commercials in a given segment of TV recording. Once a database of commercials is created using the interface provided, it is able to achieve a detection accuracy of 100%. There is a command line interface which takes as input a video and outputs the location and contents of each of the commercials. The person who is maintaining the system can then seek through the video and classify parts of the video using a web interface. Once this is done, another command is executed which updates the database with the ads classified by the maintainer. Usually, with good maintenance, the system is able to detect all the commercials on TV. . Formats . Input video . All formats accepted by ffmpeg. Popularly MPEG, MP4, AVI, MKV. . Output txt file . The program by default creates a file called output.txt. This can be changed by editing src/constants.py. The format of the file is as follows: . start - end = Name of content . Eg: 00:00:38 - 00:00:53 = ad by jeopardy 00:00:53 - 00:01:06 = ad by jerome’s . Working of the entire system . The system works based on the concept of audio fingerprinting. The main logic is, fingerprint the audio of the regions initially hand picked and marked by the user. Store these fingerprints in a database. To identify commercials on an unknown stream of video, we obtain the audio for the given video file. We scan through the audio to detect matching fingerprints in the database. We store these matched segments as commercials in the output and the undetected segments as “Unclassified”. A sample output from the system is as below. . 00:01:39 - 00:02:09 = ad by honda 00:02:09 - 00:02:16 = ad by eye witness news 00:02:16 - 00:04:19 = unclassified 00:04:19 - 00:04:48 = ad by hbo 00:04:48 - 00:05:04 = ad by el polo loco 00:05:04 - 00:05:34 = ad by Northrop grumman 00:05:34 - 00:06:05 = ad by TobaccoFreeCa.com . Now, it is seen that section 2:16 till 4:19 is unclassified. If a human could watch this segment of the video then the person can tag this segment correctly. Such an option is provided by the web interface (to seek to the required portion of the video and tag the content). Once all such unclassified regions are viewed by the human another command has to be executed, which updates the database with these new commercials. . Generating the database . To start the system, one has to create a file for a given video which has the list of commercials which are present in the video. This file has to be manually created by watching the video. The format of the file, should match the format of the output file as shown above. Once this is ready, the database is generated with the help of the following command. . python main.py -g labels.txt video.mpg . Where labels.txt should contain the location and the content of the commercials in video.mpg. The program updates the database only if a commercial having the same name is not already present in the database. . This part of the program, requires the directories data/, data/audio and data/video to be present. The commercials found in those regions are stored in data/video, their corresponding audio, for fingerprinting purpose, stored in data/audio. The files are created in serial order of the commercials found. . Another file called commercial.csv is also created. This file contains a visual view of the database in excel form. It is best to not edit this file, since the creation of the output file by the system relies on the order of the contents in this file. . Note:When running generate for the first time, see to that there is no file called commercials.csv, the tables songs and fingerprints in dejavu detabase are empty and in db/audio and db/video, there is only file “.temp”. If all of these conditions are not met, then it leads to errors . Detection of commercials . The detection of commercials for a given video is done by first obtaining the audio of the video. The audio by default is named temp.wav. It is a single channel audio file. This file is automatically deleted when the program finishes execution. The audio-fingerprinting method obtains a 100% match with just 4 seconds of audio sample obtained from any location of the commercial. VIDEO_GAP, VIDEO_SPAN are two parameters which decide how this analysis should be done. VIDEO_SPAN, how much of the audio is to be taken. VIDEO_SPAN, how much of the audio to be skipped for analysis. The following command runs the detection on the video . python main.py -r video.mpg . The command creates a file called output.txt in the same directory where the command was executed. If such a file already exists, then it over writes that file. . Manually classifying content . The most basic way to tag unclassified content would be to edit output.txt and run the steps to populate the database again. But this is a cumbersome procedure so there is an interface provided to make the entire procedure easy. The interface can be seen using the following commands. . python main.py -l output.txt video.mpg . By default this command searches for output.txt in the current working directory of the terminal, it assumes that this file corresponds to video.mpg and starts a local server where contents can easily be tagged. To change the default setting of output.txt, change the variable name OUTPUT in constants.py. . To start the web interface, we have to run gunicorn as a daemon, this is done in start_server.sh present in src/web. Run the shell script as follows in src/web: . chmod +x start_server.sh ./start_server.sh . This makes gunicorn, run on port 127.0.0.1:8000. . In the web interface, there is are seek and edit buttons. “seek” seeks the video to the required starting point of the block and edit allows the user to edit the tag given to that block. Once done tagging the content, one may chose to click on “Save changes”. This saves the changes made and stores it in output.txt. After the changes have been saved, to make the update in the database, run the following command. . python main.py -g output.txt video.mpg . This concludes all the features of the system. . When tagging unclassified content, if it is a commercial, it should start with “ad”, this helps the system detect it is a commercial so that it can fingerprint it in the database. . Note:The ads currently present in the database at any time can be viewed by navigating to the folder db/video. . Common unnoticeable bugs . Check if all the versions of the software comply with the system requirements mentioned on the github page. Even if it does not comply, the program will run, but the output will be erroneous. One example is, most ubuntu 12.04 distributions come with ffmpeg installed, but it is version 1.8. This version of ffmpeg has a different way of decoding the video, so even though no errors pop up, the output will be wrong. . Note about the proposal . The GSOC proposal I wrote stated that I would incorporate both audio based and video based methods into the system , theoretically this should give better user interface since the entire video is divided into blocks, which is more easy for the user to deal with. . I implemented the entire thing as per the proposal and it turned out that it became more work for the user since the video+audio based classification method of dividing the video into blocks gave an accuracy of only 94%. Even though this accuracy is great, that 6% of blocks this misses adds a lot more work to the user. Which is why I decided to create a new branch for this part of the code and keep the neat part in the master branch. The master branch hence has code which is more user friendly. . Web interface of the system . The web interface appears as follows, the interface is made as similar to the current interface for tagging content in Red Hen Labs. http://www.redhenlab.org/home/tutorials-and-educational-resources/how-to-use-the-online-tagging-interface. . The figure below, shows the first screen when the interface is opened. . We can go to each of the labels and edit in place, changes will be made immediately through AJAX. ‘+’ button is used to split a label into two parts. When we click on that button, we get an image, that looks similar to this. . Deploying the system on your local machine . Installing dependencies . This is done by running dependencies.sh file. Please edit the file for the corresponding architecture of your machine(x86 or amd64). . General configurations . All configuration can be done by editing the file constants.py. There is no need in general to edit this file, however, when you are running the system for the first time, you will have to do the following. . Create a mysql database named dejavu(preferably) | Edit the variable “CONFIG” in constants.py to reflect the username, password of the database, also the name of the database too. An example of the config variable is as follows: | CONFIG = { &quot;database&quot;: { &quot;host&quot;: &quot;127.0.0.1&quot;, #The default mysql IP &quot;user&quot;: &quot;root&quot;, #Username of mysql &quot;passwd&quot;: &quot;pass&quot;, #Password of mysql &quot;db&quot;: &quot;dejavu&quot; #Name of the database just created } } . Configuring the web server . I found that deploying the django app on Nginx + Gunicorn is the easiest, Apache gave rise to too many bugs and lighttpd gave some fastcgi bugs which I could not resolve. The following are the steps to follow to deploy your own server. . sudo nano /etc/nginx/sites-enabled/nginx.conf . Now, in the config file type the following: . server { listen 89; #Can be changed accordingly access_log /new/path/to/access.log; error_log /new/path/to/error.log; location /static { root /path/to/CommercialDetection/src/web/output/; } location / { proxy_pass http://127.0.0.1:8000; #Communicate with gunicorn. } } . Once this is done, we restart the server. . sudo service nginx restart . Note:The above config file cannot be copied as is, the paths have to be specified. It is best to keep CommercialDetection in /var/www/ where it is accessible to nginx. . Evaluating the system . The system contains a manually tagged database of 60 commercials. The database can be built by running generate on data/filename.txt with the corresponding filename.mpg in RawFilesWithCommercials. It detects all the commercials for 2015-04-28_0100_US_KABC_Eyewitness_News_6PM.mpg, since this was the video that was tested on innumerable number of times during development you can expect the best result from this. . The channels KABC and CBC have been used for generating ads. The remaining channels serve as a good ground for testing the system. . The system can be thoroughly evaluated by doing the following: . First clone the system from git | Run dependencies.sh (If not done already) | Run ‘generate’ on the videos using the labels provided in data/ = This will build a database, which can be verified by looking at the database dejavu. | Run ‘recognize’ on any video. | Run ‘Manually tagging ads’ on the same video, with the output file obtained. | Label at least one new commercial, to test the web interface. Also, verify the working of the buttons. | Now, the button “save changes” will save the changes in labels.txt | Run generate on labels.txt to get new commercials into the db. | The content of the db can be viewed through commercials.csv. | Blog report . A commercial detection system was built, which obtained 100% detection of commercials. The system detects the location and the content of ads in any stream of video, regardless of the content being being broadcast and other transmission noise in the video. An online interface was built along with the system to allow regular maintenance. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2016-vasanth.html",
            "relUrl": "/2020/02/20/public-gsoc-2016-vasanth.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post63": {
            "title": "Description",
            "content": "My project is documented at https://shrutigullapuram.wordpress.com/2016/08/22/gsoc-work-product-submission/. My project was for Red Hen Lab, which is a sister org of CCExtractor. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2016-shruti.html",
            "relUrl": "/2020/02/20/public-gsoc-2016-shruti.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post64": {
            "title": "GSoC 2016 Report. Ruslan Kuchumov",
            "content": "The main goal of this year was to bring real-time repository to more stable, less resource demanding and usable version. A lot of decisions made in GSoC 2014 and 2015 turned out to be wrong. So this year I had to start everything almost from scratch. The things that were achieved to this date are: . Completely changed architecture: - All captions extraction (BIN -&gt; CC) is done on “tuners side” instead of sending BIN to special servers for extracting - CCExtractor itself doesn’t connect to repository servers, instead a client program ccr should be used. ccr sends both extracted captions and BIN data - My own socket connection protocol between “tuners side” and servers was replaced by long running HTTP connection. It handles connection losses easily, as they happens quiet often and also allows to define an API. - Communication between web browser and servers is done now via WebSockets. Compared to previous implementations with polling, long polling and server-side events (yes, I tried all of them :( ) it doesn’t overload servers’s CPUs as much. - Repository servers are now handling HTTP and WebSockets requests only. All the received data is stored in Redis cache and backed up to persistent database every few minutes. (In previous versions there were no cache) | Created client program ccr | Changed web servers - My own implementation of MVC pattern and routing was replaced by FatFree framework, then it turned out that it doesn’t have required features and then was changed by Laravel - The same happened to JavaScript client. At the end it was done with Backbone framework. Also now it allows to view multiple channels at the same time - WebSocket servers were created using Node.js (check broadcasting/ in repo) | Defined an RESTful API | Deployed it in Kubernetes in Google Container Engine with working autoscaling | Besides that: . I fixed this issue (which is not actually CCExtractor fault:) ) | And figured out issue #136 (which is not CCExtractor fault as well) | The first half of the summer went as planned but then some problems arouse. The first version used Google Datastore and App Engine. Turned out hosting it cost $300 per two week which was very expensive. So we decided to use Amazon AWS. I changed the code for their services and then I wasted a lot of time trying to deploy it, but I couldn’t and I still don’t know why (although I used it in the previous year). Then I switched to Google Container Engine, it worked, but my app used a lot of CPU %, so I had to redesign it again and reconsider a lot of decisions (in panic). Because of this the following features were not done: . E-mail notifications | Creating .deb and .rpm packets for CCExtractor | Searching and downloading feature (in API and web site) is not completed |",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2016-ruslan.html",
            "relUrl": "/2020/02/20/public-gsoc-2016-ruslan.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post65": {
            "title": "GSoC’16 Project Documentation",
            "content": "Commits . All my work done during GSoC commited to the mainstream master branch can be found here. . Technical Documentation . The technical documentation on how the code is structured as well as installation is available here. . About the Project . DVD Subtitle Extraction . My project was to add support for DVD subtitles. CCExtractor had support for DVD Closed Caption however new DVDs contain DVD subtitles instead of the older DVD Closed Captions. I have added support such that supplying a VOB file normally to CCExtractor works to extract the DVD Subtitles. DVD subtitles extraction works by filtering out the subtitle frames from the video stream and obtaining the RLE encoded bitmap based subtitles, which are then provided to Tesseract for OCR recognition. . A part of my project was to support CEA-708 subtitles. It is a closed captioning standard used in the US and Canada. CCExtractor has support for CEA-708 but it is not complete. . Other Work . In addition to the project, I worked on bug fixes and other features. All my merged pull requests can be found here. . Initially, Vob files were new to me and to understand their data arrangement I wrote a program which is in another repository. . Known Issues and Future Work . I hope to continue to add improvements to DVD subtitles extraction as well as CCExtractor. . There is no support for IFO files at the moment. IFO files contain information regarding the data in the DVD. I hope to add support for IFO files pretty soon. . | Episode selection is not supported. To be added with IFO files. . | .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2016-rishabh.html",
            "relUrl": "/2020/02/20/public-gsoc-2016-rishabh.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post66": {
            "title": "User Documentation for Subtitle Downloader",
            "content": "Introduction . The project deals with downloading of subtitles from popular online TV Services like Netflix, BBC,Hulu. The project aims to perform this task without the need for the user to interact with the browser. The process is automated completely. The user just needs to input the URL of the video and the application will download the subtitles. For services like YouTube, CrunchyRoll which have subtitles in multiple languages, the user gets an option to choose the preferred language. For Netflix, Amazon the user needs to have a valid login and subscription to the videos, only then the subtitles will be downloaded. . INSTALLATION INSTRUCTIONS . Clone the repository - git clone https://github.com/abhishek-vinjamoori/SubtitleExtractor.git . Ensure that “python 3” is installed on your computer. sudo apt-get install python3 . [DEPENDENCIES] . Dependencies to be installed - . pip install requests . If pip3 is not installed - . sudo apt-get install python3-setuptools sudo easy_install3 pip sudo mv /usr/local/bin/pip /usr/local/bin/pip-3 sudo pip3 install -U selenium pip install beautifulsoup4 . Disclaimer: Use it at your own risk. . //Note : For Amazon,Netflix subtitle downloads - “Stable release of Google Chrome is required.”// . For Amazon, Netflix : . Make sure you already have Google Chrome installed. Then download and extract the contents of - http://chromedriver.storage.googleapis.com/index.html?path=2.22/ You will get a file named “chromedriver” Then go to the directory where “chromedriver” is present and execute the following command : . sudo mv -t /usr/local/bin/ chromedriver (Move the chromedriver file into /usr/local/bin) . HULU . ———————Instructions for Hulu——————— . Ensure that SubtitleExtractor.py executable. (Command for making it executable - chmod +x SubtitleExtractor.py) . | Run the python file - ./SubtitleExtractor.py . | Paste the desired URL (from Hulu website) for which Subtitles have to extracted and press “ENTER”. . | If multiple languages are available you will be prompted to choose the desired language option. . | Subtitles will be downloaded. . | . . YouTube . ———————Instructions for YouTube——————— . Ensure that SubtitleExtractor.py executable. (Command for making it executable - chmod +x SubtitleExtractor.py) . | Run the python file - ./SubtitleExtractor.py . | Paste the desired YouTube URL from which Subtitles have to extracted and press “ENTER”. . | If multiple languages are available you will be prompted to choose the desired language option. . | Subtitles will be downloaded. . | . . Amazon . ———————Instructions for Amazon——————— . Note ~ Amazon requires that you have a valid subscription for that particular video to download the subtitles . These instructions need to followed whenever you want to “change login details”. - . Ensure that SubtitleExtractor.py and “setup.py” are executable. (Command for making them executable - chmod +x SubtitleExtractor.py setup.py) . | Open the file “userconfig.ini”. . | Type in your new Amazon Username and Amazon Password in the respective fields. . | Save the file and exit. . | Now run the file setup.py - ./setup.py . | If the setup is successfully done, you will see no errors. . | . These instructions need to be followed when you are done with the one time setup file. From now on, you can just follow these instructions unless you want to change your login details ~ . Run the python file - ./SubtitleExtractor.py . | Paste the desired Amazon URL from which Subtitles have to be extracted and press “ENTER”. . | If it is a movie, Subtitles will be downloaded normally. . | If it is a TV Series, all the episodes of that season will be downloaded in a new folder with the corresponding title. . | . . BBC . ———————Instructions for BBC——————— . Note ~ Please check that you are able to stream the video without any geo-location errors. . Ensure that SubtitleExtractor.py executable. (Command for making it executable - chmod +x SubtitleExtractor.py) . | Run the python file - ./SubtitleExtractor.py . | Paste the desired URL (from BBC website) for which Subtitles have to extracted and press “ENTER”. . | Subtitles will be downloaded. . | . . CrunchyRoll . ———————Instructions for CrunchyRoll——————— . Ensure that SubtitleExtractor.py executable. (Command for making it executable - chmod +x SubtitleExtractor.py) . | Run the python file - ./SubtitleExtractor.py . | Paste the desired URL (from Crunchyroll website) for which Subtitles have to extracted and press “ENTER”. . | You will be asked to choose the language in which the subtitles have to be downloaded based on the availability. Enter the corresponding number. . | Subtitles will be downloaded in the chosen language. . | . . Netflix . ———————Instructions for Netflix——————— . Note ~ Please check that you are able to stream the video without any geo-location errors. . Ensure that SubtitleExtractor.py executable. (Command for making it executable - chmod +x SubtitleExtractor.py) . | Open the file “userconfig.ini”. . | Type in your new Netflix Username and Netflix Password in the respective fields. . | Save and exit. . | Run the python file - ./SubtitleExtractor.py . | Paste the desired URL of the video (from Netflix website) for which Subtitles have to extracted and press “ENTER”. . | Subtitles will be downloaded. . | . . FOX . ———————Instructions for FOX——————— . Note ~ Please check that you are able to stream the video without any geo-location errors. . Ensure that SubtitleExtractor.py executable. (Command for making it executable - chmod +x SubtitleExtractor.py) . | Run the python file - ./SubtitleExtractor.py . | Paste the desired URL (from FOX website) for which Subtitles have to extracted and press “ENTER”. . | Subtitles will be downloaded. . | . . Crackle . ———————Instructions for Crackle——————— . //Note: . Please check that you are able to stream the video without any geo-location errors. . | After clicking on a TV show ensure that the URL contains some integer ID in it. Or else, click again on the episode from the playlist below to obtain the desired URL.// . | Ensure that SubtitleExtractor.py executable. (Command for making it executable - chmod +x SubtitleExtractor.py) . | Run the python file - ./SubtitleExtractor.py . | Paste the desired URL (from Crackle website) for which Subtitles have to extracted and press “ENTER”. . | Subtitles will be downloaded. . | . . Please report any errors on GitHub along with the error message for support. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2016-abishek-subtitle_downloader.html",
            "relUrl": "/2020/02/20/public-gsoc-2016-abishek-subtitle_downloader.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post67": {
            "title": "GSOC 2016 Documentation",
            "content": "Projects . Subtitle Extractor | Details . All the technical details are commented in the codes and the documentation is available in the Readme’s of their directories. The variables, classes and other components of the code are named properly in Camel Case for easier understanding of the code. . Repositories: . https://github.com/abhishek-vinjamoori/SubtitleExtractor - Subtitle Extractor | . I am the only contributor to this repository. Started it from scratch. . How to use? . The usage is listed in the README file of the GitHub repository and also in the USER DOCUMENTATION WIKI PAGE . Technical Documentation . The technical documentation about the code architecture and how to add support for new services has been written in the Technical Documentation Wiki . About the Project . The project deals with downloading of subtitles from popular online TV Services like Netflix, BBC,Hulu. The project aims to perform this task without the need for the user to interact with the browser. The process is automated completely. The user just needs to input the URL of the video and the application will download the subtitles. For services like YouTube, CrunchyRoll which have subtitles in multiple languages, the user gets an option to choose the preferred language. For Netflix, Amazon the user needs to have a valid login and subscription to the videos, only then the subtitles will be downloaded. . The whole application was written from scratch. It was coded in Python 3 and it uses a few external libraries like BeautifulSoup, selenium for Python. . The commits to this project repository can be found in the link - . Subtitle Extractor Commits . Future Work . In the future support for new services like ComedyCentral, Channel5 will be added. As the application depends on the individual services websites, the repository will be checked regularly for errors. Accordingly the bugs would be tackled. I also plan upon adding features like - . Batch Downloading of Subtitles. (Currently on Amazon supports this feature) . | Choice of episode selection. . | Preference for file naming. . | . Other work . Besides the work mentioned above, also contributed a few patches for bugs and features for CCExtractor: . https://github.com/CCExtractor/ccextractor/pull/387 . | https://github.com/CCExtractor/ccextractor/pull/379 . | https://github.com/CCExtractor/ccextractor/pull/367 . | https://github.com/CCExtractor/ccextractor/pull/351 . | https://github.com/CCExtractor/ccextractor/pull/329 . | . The detailed list of commits can be found here on this page - My commits to the main repository .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2016-abhishek-projects.html",
            "relUrl": "/2020/02/20/public-gsoc-2016-abhishek-projects.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post68": {
            "title": "Public:gsoc:2016:abhinav",
            "content": "Documentation for my project can be seen here. . Description . My project was to add the capability of extracting burned-in (hard) subtitles from videos to CCExtractor. As of now, CCExtractor works by only extracting caption data in the video if it is present in specific structures in the stream, and skips the actual video data (pixels) completely. However a lot of videos have hard subtitles burned into them, extracting which is a computer vision problem, and something which CCExtractor did not earlier have the capability to process. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2016-abhinav.html",
            "relUrl": "/2020/02/20/public-gsoc-2016-abhinav.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post69": {
            "title": "Public:gsoc:2015:willem",
            "content": "======= GSOC 2015 Documentation ======= . Technical Documentation . All technical documentation has been posted to the GitHub repositories, either in the form of the README, or in form of comments. . The repositories are located here: . https://github.com/canihavesomecoffee/ccx_testsuite (Project from GSoC 2014, not that much changes this year, except for some fixes and improvements) https://github.com/canihavesomecoffee/ccx_gitbot https://github.com/canihavesomecoffee/ccx_submissionplatform . How to use? . Test Suite . No changes from last year, still as described in the first section of CCExtractor regresssion testing / GitHub bot. . GitHub bot . Refer to the bot section in the CCExtractor regresssion testing / GitHub bot page. . Submission platform . To view samples, test results and download samples there is no need for an account. To upload samples, registration is required. Samples (&lt;1GB) can be uploaded through HTTP; FTP allows all sizes. Special care has been taken to keep all samples anonymous (except to the user itself and the admin), and if required, a user can anonymize his/her account. . How to evaluate? . The bot can be evaluated (/ccextractor-wiki-test/2020/02/20/user-side) by issuing commands to it on GitHub (/ccextractor-wiki-test/2020/02/20/see CCExtractor regresssion testing - GitHub bot for instructions). It’s been used already by Anshul, Kisselef and Ruslan for the last PR they made. . The sample submission platform can be tested (user-side) by either browsing around on the site and/or creating an account (the latter is required to upload samples). At this moment, a limited section of regression samples was already added, and this will be expanded very soon. . To test the admin parts of both the bot &amp; the sample platform I refer to the mail I wrote to Carlos. . Contribution for blog . The submission of new samples has been quite chaotic in the past of CCExtractor, with users submitting samples through FTP, GitHub, Google Drive, upload websites, email, … The sample submission platform aims to create a single place to retrieve and upload new samples, as well as showing the current state (fixed, broken, …) for those samples. Besides that, a GitHub bot was introduced to allow other contributors run the regression tests without having to download all the samples. This should improve the stability of CCExtractor and hopefully lower the barrier for new contributions. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2015-willem.html",
            "relUrl": "/2020/02/20/public-gsoc-2015-willem.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post70": {
            "title": "GSOC 2015 Documentation",
            "content": "Projects . Realtime Translation using Google Translate | Realtime Translation using Apertium | Web application to compare statistics of Stock Price, TV Mentions and Twitter | Technical Documentation . All the technical details are commented in the codes and the documentation is available in the Readme’s of their directories. The variables, classes and other components of the code are named properly in Camel Case for easier understanding of the code. . Repositories: . https://github.com/Akirato/goslateTranslator - Google Translate Translator . | https://github.com/Akirato/apertiumTranslator - Apertium Translator . | https://github.com/Akirato/sentimentAnalysisTool - Tool for Sentiment Analysis . | https://github.com/Akirato/statsChart - The entire web application for statistics comparison . | https://github.com/Akirato/statsChart-backend - The backend of the statistics web application . | . How to use? . Google Translate and Apertium Realtime Translation . The instruction to use the codes directly are given in the Readme of the repositories. A sample of translator from English to Spanish is available at http://gsocdev.ccextractor.org/~nurendra/translated/test2/tail.php . Web Application for comparing Statistics . The application is presently hosted at https://95.211.109.210/statsChart/default/index It has been built on Web2py framework. . Make a MySQL database called “statschart” and run the three scripts given in https://github.com/Akirato/statsChart-backend | Download web2py from http://web2py.com/init/default/download | Clone https://github.com/Akirato/statsChart into web2py/applications/ | Go to web2py/application/statsChart/models/db.py and connect your databases. | Run the web2py server. | The application should be hosted at &lt;host-server&gt;/statsChart/default/index | Deployment on a new server: . Make a MySQL database on the server called “statschart” and run the three scripts given in https://github.com/Akirato/statsChart-backend | Install and deploy web2py on a new server. | Several Deployment Recipes for common servers are given at http://web2py.com/books/default/chapter/29/13/deployment-recipes | After this is done, a web2py/ directory will be made in the server. | Clone https://github.com/Akirato/statsChart into web2py/applications/ | Go to web2py/application/statsChart/models/db.py and connect your databases. | Run the web2py server. | The application should be hosted at &lt;host-server&gt;/statsChart/default/index | How to evaluate? . Google Translate and Apertium Realtime Translation . Repositories of both the translators have methodAnalysis/analyse.py file. Execute this file if the code is working properly. Also English-&gt;Spanish realtime translation is available at http://gsocdev.ccextractor.org/~nurendra/translated/test2/tail.php . Web Application for comparing Statistics . The web application is hosted on https://95.211.109.210/statsChart/default/index To look at the entire code, go to https://95.211.109.210/admin/default/index Give the password: “akirato123” and select “statsChart” to check the entire code. . Contribution to blog . The subtitles generated by CCExtractor can now be translated and be made available to a larger audience due to the realtime translation tool. The tool uses Google Translate and Apertium to provide online and offline translation respectively. The Statistics website collects data from Twitter using Twitter API, from TV advertisements using CCExtractor and shows it effects on the Stock Price which are updated using Google Finance. This will be very useful for opinion collection and looking at the effects of advertisements on Social Media. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-gsoc-2015-nurendra.html",
            "relUrl": "/2020/02/20/public-gsoc-2015-nurendra.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post71": {
            "title": "Working with HDHomeRun",
            "content": "Starting in version 0.65, CCExtractor can process a stream being delivered via UDP, so there’s no need to capture video to a file in order to get the subtitles. . What devices are supported? While it should work with any device that is able to send the stream via UDP, at this time it’s only been tested with HDHomeRun (both European and American models). . Will other devices be supported? . HDHomeRun works so well that it’s unlikely I’ll bother with any other device unless it finds its way to me for free and development is sponsored. . How do I use it? . Make sure you have HDHomeRun’s software installed. You will need the command line tool “hdhomerun_config” (it’s available for Linux and Windows, possibly OSX too). GUI frontends are available, too, but the following instructions use just the command line tool. . Because you can have more than one HDHomeRun in the network, the first thing is to look for the IDs of each of them: . # ./hdhomerun_config discover hdhomerun device 12206E95 found at 192.168.20.117 . I only have one, and its ID is 12206E95. When I want to do anything with that tuner, I need to pass the ID to hdhomerun_config (note: since I only have one I could just pass FFFFFFFF which is accepted in this scenario). . Then, have HDHomeRun scan for channels: . ./hdhomerun_config 12206E95 scan /tuner0 . The first parameter is of course the ID of my HDHomeRun. I also need to pass /tuner0 because the device is dual-tuner, so I specify which one I want to use. The output is rather large - only a part of it is shown: . SCANNING: 778000000 (eu-bcast:59) LOCK: t8qam64 (ss=90 snq=66 seq=100) TSID: 0x000F PROGRAM 184: 0 Boing PROGRAM 185: 0 Telecinco HD PROGRAM 304: 0 MTV PROGRAM 305: 0 Paramount Chann SCANNING: 770000000 (eu-bcast:58) LOCK: t8qam64 (ss=97 snq=28 seq=100) TSID: 0x03F4 PROGRAM 530: 0 La 1 PROGRAM 531: 0 La 2 PROGRAM 532: 0 24h PROGRAM 533: 0 Clan PROGRAM 535: 0 Radio Nacional PROGRAM 536: 0 Radio 5 Todo No . In this output, the number after eu-bcast is the channel. A channel is a bundle of several programs (a program being a station) that are broadcast together. For example you can see that channel 58 contains 6 programs. . Suppose we want the subtitles from “La 1”. First, tune to the channel that carries it: . #./hdhomerun_config 12206E95 set /tuner0/channel 58 . Then, select the specific program. Note that we could get away without selecting a program and then the HDHomeRun would deliver all of them to CCExtractor. However because CCExtractor only processses only program at a time it’s best to filter directly in the tuner than have CCExtractor discard everything it doesn’t need. . ./hdhomerun_config 12206E95 set /tuner0/program 530 . Finally, tell HDHomeRun where to send the stream to: . ./hdhomerun_config FFFFFFFF set /tuner0/target 192.168.20.15:1235 . The parameter there is the IP address of the computer where CCExtractor is running (or will be running) and the port it’s listening to. CCExtractor can be running already when you do this, or you can start it at a later point. Of course the stream before it’s started is lost - it will start processing data as it arrives from the tuner. . Finally, start CCExtractor if you hadn’t done it already: . ccextractor -srt -udp 1235 -stdout CCExtractor 0.65, Carlos Fernandez Sanz, Volker Quetschke. Teletext portions taken from Petr Kutalek&#39;s telxcc Input: Network, UDP/1235 [Raw Mode: Broadcast] [Extract: 1] [Stream mode: Autodetect] [Program : Auto ] [Hauppage mode: No] [Use MythTV code: Auto] [Timing mode: Auto] [Debug: No] [Buffer input: Yes] [Use pic_order_cnt_lsb for H.264: No] [Print CC decoder traces: No] [Target format: .srt] [Encoding: Latin-1] [Delay: 0] [Trim lines: No] [Add font color data: Yes] [Add font typesetting: Yes] [Convert case: No] [Video-edit join: No] [Extraction start time: not set (from start)] [Extraction end time: not set (to end)] [Live stream: No] [Clock frequency: 90000] Teletext page: Autodetect] Start credits text: [None] Sending captions to stdout. Reading from UDP socket 1235 File seems to be a transport stream, enabling TS mode Analyzing data in general mode [...] Program Master Table for program 530, PMT PID: 100 101 | MPEG-2 video 922 | MPEG-2 video 102 | MPEG-2 private data 2675 | Unknown 115 | Unknown 2051 | MPEG-4 video 1546 | Unknown 256 | Unknown 4102 | Unknown 353 | Unknown 2544 | Unknown 4976 | MPEG-2 audio 111 | MPEG-2 private data 2163 | Unknown 1 | MPEG-4 video 3301 | Unknown 768 | Unknown VBI/teletext stream ID 102 (0x66) for SID 530 (0x212) Skip forward to the next TS header mark. Programme Identification Data = La 1 Universal Time Co-ordinated = Mon Mar 11 21:36:23 2013 1 00:00:00,240 --&gt; 00:00:02,560 Su voz suena en los altavoces. [...] . As expected, in this example CCExtractor would run forever. You can control this with the time related parameters, in case you want CCExtractor to exit after a given number of seconds. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-working_with_hdhomerun.html",
            "relUrl": "/2020/02/20/public-general-working_with_hdhomerun.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post72": {
            "title": "Public:general:win_gui_usage",
            "content": "The new interface is all you need, as it includes all the options. After installing CCExtractor you will have a shortcut in your desktop and a new entry in the Program Files folder (CCExtractor -&gt; CCExtractorGUI). . From the GUI you have a lot of options. Usually, you will never need to use them (and if you do, you can save them as default) for regular usage. . There are several tabs. These are two that you will definitely need to use: The ‘input files’ tab, where you drag and drop (from Windows Explorer for example) the files you want to process, and the ‘Execution’ tab from where you launch the extraction process and see the progress. . This is the ‘input files’ tab: . This is the ‘execution’ tab: . As you can see, when a extraction is in progress you can see a preview of the subtitles (as they are being produced), the actual output Windows from the extraction process, progress, and more. . By default, CCExtractor produces .srt (SubRip) subtitles, as they are universally supported by all players, and they are easy to edit. There are however other formats that CCExtractor can generate. . This is the ‘output’ tab: . Modifying how subtitles look like . By default, CCExtractor does it best to produce subtitles that look as they do on the TV. Depending on personal tastes, this is a good thing or it can be extremely annoying. In particular, there are two things that you may want to change: Position: Real closed captions are displayed on 32 columns by 15 rows grid. The person producing the captions can position them anywhere in the screen. For deaf people this is useful to know who’s talking or where the sound is coming from. In the produces files, it might look like this: . SG. FERNANDEZ VOLKER. . If this is annoying for you, you can select the ‘center text’ option in the decoder tab. Capitalization: Many stations broadcast their captions IN ALL CAPS, which is usually harder to read. I believe the reason is that the very first decoders (from decades ago) didn’t support lowercase, and some stations or captions producers really really want to be on the safe side. Anyway, CCExtractor can apply the standard (English) capitalization rules and fix this. There is a small list of words that CCExtractor knows that must be capitalized, and you can also supply a file with a more complete list. . This is the ‘decoder’ tab from where you can change these and other things: . Installation details (i.e. what are you installing on my computer?) . Starting with version 0.64, the installer registers a DLL in your computer. This is a DirectShow filter that allows extraction of CC data from wtv files. If you don’t want or can’t (because you don’t have administrator privileges) register this DLL, everything will still work except wtv support. Other than this the installer just copies the same files included in the .zip file with the windows binaries. No other changes are made. . The GUI needs the .NET runtime (it comes with Vista and 7, and most likely you already have it for other programs). If it is not installed it will download it from Microsoft’s website. . You can uninstall everything from the Add &amp; Remove programs option in the control panel and nothing is left behind (I think, because the Windows installer creator in Visual Studio is a bit of a black box…). .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-win_gui_usage.html",
            "relUrl": "/2020/02/20/public-general-win_gui_usage.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post73": {
            "title": "Public:general:whatsccextractor",
            "content": "~~META: title = What’s CCExtractor? ~~ . What’s CCExtractor? . A tool that analyzes video files and produces independent subtitle files from the closed captions data. CCExtractor is portable, small, and very fast. It works in Linux, Windows, and OSX. . What kind of closed captions does CCExtractor support? . Almost all of them: . American TV captions (CEA-608 is well supported, and CEA-708 is starting to look good) | European Teletext | European DVB | Brazilian ISBD | DVD | MXF | . Missing: . DTMB (Chinese) | . How easy is it to use CCExtractor? . Very. Just tell it what file to process and it does everything for you. . CCExtractor integration with other tools . It is possible to integrate CCExtractor in a larger process. A couple of tools already call CCExtractor as part their video process - this way they get subtitle support for free. Starting in 0.52, CCExtractor is very front-end friendly. Front-ends can easily get real-time status information. The GUI source code is provided and can be used for reference. Any tool, commercial or not, is specifically allowed to use CCExtractor for any use the authors seem fit. So if your favourite video tools still lacks captioning tool, feel free to send the authors here. . You can also use CCExtractor as a library (as opposed to just running the binary), or take parts of the code. Keep in mind however that CCExtractor is GPLv2 so if you take parts or all of the source code your code must also be GPLv2. . What’s the point of generating separate files for subtitles, if they are already in the source file? There are several reasons to have subtitles separated from the video file, including: . Closed captions never survive MPEG processing. If you take a MPEG file and encode it to any format (such as divx), your result file will not have closed captions. This means that if you want to keep the subtitles, you need to keep the original file. This is hardly practical if you are archiving HDTV shows for example. | Subtitles files are small - so small (around 250 Kb for a movie) that you can quickly download them, or email them, etc, in case you have a recording without subtitles. | Subtitles files are indexable: You can have a database with all your subtitles if you want (there are many available), so you can search the dialogs. | Subtitles files are a de-facto standard: Almost every player can use them. In fact, many setbox players accept subtitles files in .srt format - so you can have subtitles in your .mp4/.mkv/.avi./etc movies and not just in your original DVDs. | Closed captions are stored in many different formats by capture cards. Upgrading to a new card, if it comes with a new player, may mean that you can’t use your previously recorded closed captions, even if the audio/video are fine. | Closed captions require a closed caption decoder. All US TV have one (it’s a legal requirement), but no European TV does, since there are not closed captions in Europe (teletext and DVB subtitles are used instead). Basically this means that if you buy a DVD in the US which has closed captions but no DVD subtitles, you are out of luck. This is a problem with many (most) old TV shows DVDs, which only come with closed captions. DVD producers don’t bother doing DVD subs, since it’s another way to segment the market, same as with DVD regions. | . How I do use subtitles once they are in a separate file? CCExtractor generates files in the two most common formats: .srt (SubRip) and .smi (which is a Microsoft standard). Most players support at least .srt natively. You just need to name the .srt file as the file you want to play it with, for example sample.avi and sample.srt. . Other formats just as .txt (transcripts) are supported as well. . What kind of files can I extract closed captions from? CCExtractor currently handles: . Most HDTV captures (where you save the Transport Stream). | Captures where captions are recorded in bttv format. The number of cards that use this card is huge. My test samples came from a Hauppage PVR-250. You can check the complete list here. | DVR-MS (microsoft digital video recording). | Tivo files | ReplayTV files | Dish Network files | DVDs | . Usually, if you record a TV show with your capture card and CCExtractor produces the expected result, it will work for your all recordings. If it doesn’t, which means that your card uses a format CCExtractor can’t handle, please contact me and we’ll try to make it work. . Can I edit the subtitles? .srt files are just text files, with time information (when subtitles are supposed to be shown and for how long) and some basic formatting (use italics, bold, etc). So you can edit them with any text editor. If you need to do serious editing (such as adjusting timing), you can use subtitle editing tools - there are many available. . Can CCExtractor generate other subtitles formats? At this time, CCExtractor can generate .srt, .smi and raw and bin files. . What’s a raw file? A raw file is a file that contains an exact dump of the closed captions bytes, without any processing. This lets you use any tool of your choice to process the data. For example, McPoodle’s excellent tools can generate subtitles files in several formats, adjust timing, etc. . What’s a bin file? How is it different from a raw file? A bin file contains a dump of the closed captions bytes (same as a raw file) but it also includes timing information. This is a format that we made up for CCExtractor, i.e. it’s not any kind of industry standard. However, it’s the most useful (to us) for debugging purposes, so if you need to send us a sample please use this format. Also, a bin format can hold several CC streams (several languages, even from both analog and digital). A raw file cannot. . How long does it take to process a MPEG file? Obviously, it depends on the computer and the length of the file. In my (really old) computer it took around 90 seconds for a 45 minutes show in HDTV, with CPU usage around 3% (I/O operations are what’s holding it back). Currently (2018) we’re processing as many as 20 TV channels in real time using a single computer with a i5 CPU. . What platforms does CCExtractor work on? CCExtractor is developed and tested in Windows and Linux. It is also known to compile and run fine in OSX (a build script is included in the source .zip). . Where can I download it? The source code is hosted on github. Check out our download page for links to everything. Old versions were hosted on sourceforge. We’re keeping those there for statistical purposes. This is the old download page and this is the old project summary page. . How I can contact the author? There’s no longer one author. Carlos is still the official maintainer but there’s a lot of people contributing to the project. Best thing is to check out our support page. . How do I use this tool (parameters, etc)? . Run it without parameters and you will get a help screen. Basically, you just give it the input file name, like this: . ccextractor the.sopranos.ts . As for the lack of documentation: There is no lack of documentation! It’s just included in the program itself. Just run it without parameters and you will get complete details. . How can I contribute to this project? There are several ways: . If you are a developer, since the source code is available, you can fix things or add features yourself and submit a patch. | If you are an user and find any bug, or have good suggestions, let me know. | If you are doing your own recordings and have any particular one that CCExtractor can’t process correctly, I’d definitely like to take a look at it and try to fix it. | If you really hate that there is not a lot of documentation, you can write it yourself. I’ll answer any question you might have. | . Does CCExtractor use code from other projects? Yes. Lots of code came originally from McPoodle’s tools (even though it was ported from Perl to C). We’ve also taken code from MythTV (which in turn took some from other places) and FFmpeg. The teletext code is 95% Petr Kutalek’s and was integrated with permission. . A good thing about Open Source is that you don’t need to reinvent the wheel unless you want to (or unless you think you can come up with a ‘rounder’ wheel). .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-whatsccextractor.html",
            "relUrl": "/2020/02/20/public-general-whatsccextractor.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post74": {
            "title": "Using Vagrant",
            "content": "What is Vagrant? . Vagrant provides easy to configure, reproducible, and portable work environments built on top of industry-standard technology and controlled by a single consistent workflow to help maximize the productivity and flexibility of you and your team. Vagrant will isolate dependencies and their configuration within a single disposable, consistent environment, without sacrificing any of the tools you are used to working with (editors, browsers, debuggers, etc.). Once you or someone else creates a single Vagrantfile, you just need to ‘’%%vagrant up%%’’ and everything is installed and configured for you to work. You can read more about the advantages of Vagrant at https://www.vagrantup.com/docs/why-vagrant/ . Installation . Install vagrant for your OS https://www.vagrantup.com/downloads.html . | Install VirtualBox for your OS https://www.virtualbox.org/wiki/Download_Old_Builds Warning: Install VirtualBox 5.0 (Newer versions are not supported yet in vagrant). Version VirtualBox 5.0.30 at the top will be OK . | . vagrant up . Download repository of CCExtractor from GitHub https://github.com/CCExtractor/ccextractor (Or your fork of this repo) . The repository contains a file Vagrantfile that looks like this . Vagrant.configure(2) do |config| config.vm.box = &quot;ubuntu/xenial64&quot; # Uncomment this line if you want to sync other folders # config.vm.synced_folder &quot;/home/user/video&quot;, &quot;/video&quot; config.vm.provision &quot;shell&quot;, inline: &lt;&lt;-SHELL sudo apt-get install -y gcc sudo apt-get install -y libcurl4-gnutls-dev sudo apt-get install -y tesseract-ocr sudo apt-get install -y tesseract-ocr-dev sudo apt-get install -y libleptonica-dev SHELL end . If you have not Vagrantfile, simply create it in project folder and copy and paste in Vagrantfile all of the code from above. . Here it is clear that the system of the environment (or box, or virtual machine) is Ubuntu 16.04. After ‘vagrant up’ vagrant installs additional libraries in environment (not on host system!) for compiling CCExtractor. . To start the environment, go to the folder with the project and run: . vagrant up . At first time it may take a while to create virtual machine and install dependencies (about a minute or more), but in the next launches it will take place much faster. This command launch the virtual machine. For stop the virtual machine run: . vagrant halt . vagrant ssh . To connect to the environment (environment must be launched), run in project folder . vagrant ssh . If you want to return to your computer terminal, run . logout . By default, the project folder is synchronized with environment (that is available in your computer, and in a virtual machine). The project folder is located in /vagrant. . Lets build the project . cd /vagrant cd linux ./build . Now virtual environment and computer both have built CCExtractor in folder linux. Even if your computer does not have curl, tesseract, leptonica, gcc. Run in environment’s linux folder ‘’%%./ccextractor%%’’ and you will see a description of the program. Run ‘’%%./ccextractor [arguments]%%’’ to get subtitles. . Synced folders . Synced folders - those folders that are both available and in the environment, and on the host computer. Initially synchronized folder is only the project folder (where is Vagrantfile exists). You can synchronize more folders - just uncomment this line in Vagrantfile (delete the character ‘#’ at the beginning of the line) . config.vm.synced_folder &quot;/home/user/video&quot;, &quot;/video&quot; . This means that the folder with the path to “/home/user/video” will be available in the envitonment with the path “/video”. You can add any number of folders, each folder on your line. Example changed Vagrantfile: . Vagrant.configure(2) do |config| config.vm.box = &quot;ubuntu/xenial64&quot; config.vm.synced_folder &quot;/home/MyName/video&quot;, &quot;/video&quot; config.vm.synced_folder &quot;/home/MyName/Desktop&quot;, &quot;/desk&quot; config.vm.synced_folder &quot;/home/MyName/Downloads/videofiles&quot;, &quot;/stuff&quot; config.vm.provision &quot;shell&quot;, inline: &lt;&lt;-SHELL sudo apt-get install -y gcc sudo apt-get install -y libcurl4-gnutls-dev sudo apt-get install -y tesseract-ocr sudo apt-get install -y tesseract-ocr-dev sudo apt-get install -y libleptonica-dev SHELL end . Now, after changing Vagrantfile, if you have environment is launched, you have to perform in the host computer terminal ‘’%%vagrant reload –provision %%’’, or if stopped, run ‘’%%vagrant up%%’’ . Example - subtitles will be created in synced folder /video . You can edit the code from both the host computer and the virtual machine, and build it in virtual machine. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-vagrant.html",
            "relUrl": "/2020/02/20/public-general-vagrant.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post75": {
            "title": "What does SPUPNG mean?",
            "content": "SPUPNG is two acronyms: . SPU Sub-Picture Unit. According to wikibooks.org: “Subpictures are used to display subtitles as well as menu buttons, overlaid on the video. These are stored in an MPEG stream (private stream 1) as a sequence of Sub-Picture Units (SPUs).” . PNG Portable Network Graphics. According to libpng.org: “An Open, Extensible Image Format with Lossless Compression.” . Why SPUPNG? . The SPUPNG format is intended for use with authoring DVDs. The SPUPNG format does a better job of preserving the original closed caption format than the text based formats supported by ccextractor. Some of the problems with the text based formats are: . They lose row information. Closed captions can be displayed anywhere in a grid of 15 rows by 32 columns. But the text based formats do not indicate on what rows the captions should be displayed. So most applications will display captions near the bottom of the video, where most closed captions are usually placed. However, there are times when the video contains information that closed caption authors take care to not obscure by placing captions on the top rows, and sometimes even in the middle of a video. Captions are often placed at the top of video when the video is displaying text, such as credits, or the name of a speaker in a documentary. . | They may lose column information. ccextractor provides whitespace in the text based formats so it is clear where captions should be placed horizontally. But some applications ignore the leading whitespace and simply center the text horizontally. In addition, fonts used to display captions are often proportional width fonts. If the user doesn’t (or cannot) configure the application to use a fixed width font, the way captions are laid out horizontally can be skewed. Information, such as whether the person to the left or right of the video is speaking, can be lost. . | They usually don’t look like closed captions. Perhaps this isn’t a bad thing, but if you like the look of closed captions, you’ll like the SPUPNG format. . | . Some examples . A picture is worth a thousand words. So here are some screenshots that show how the same caption in the same scene is displayed depending on the ccextractor output format, how an application displays the caption, and how the user configures the application to display the caption. The scene in question has two people engaged in conversation, the caption captures what both people are saying, and it is near the beginning of the show, so credits are displayed near the bottom of the scene. . The above screenshot shows how a SRT formatted caption is displayed by VLC using VLC’s default configuration where captions are displayed using the Arial font. Both people are talking, but can you tell who is saying what? Can you read the credit? Here is how the caption is encoded in the .srt file: . 20 00:02:15,636 --&gt; 00:02:18,770 Wow. How long did that take? About a month. . The above screenshot shows how the dvdauthor tool, spumux, renders the same SRT formatted caption. I’ll explain spumux in a later section. Now you can tell who is saying what, but it is still hard to read the credit. . The above screenshot shows how a SAMI formatted caption is displayed by VLC after VLC’s Subtitles/OSD preferences have been configured to use a fixed width font, Lucida Console, and the “Add a background” option has been checked. Here is how the caption is encoded in the .smi file: . `&lt;SYNC start=135636&gt;``&lt;P class=&quot;UNKNOWNCC&quot;&gt;` Wow. How long`&lt;br&gt;` did that take?`&lt;br&gt;` About a month. `&lt;br&gt;` `&lt;/P&gt;``&lt;/SYNC&gt;` . Who is speaking is clear in the .smi file, but not when VLC displays the caption. And the credit is even harder to read with the “Add a background” option enabled. . The above screenshot shows how spumux renders the same SAMI formatted caption. In this case, spumux centers the text, so who is speaking is lost. . The above screenshot shows how spumux renders the SPUPNG formatted caption. It is clear who is saying what, and the credit is not obscured by the caption. . How to use the SPUPNG output format . The SPUPNG format was designed to be used with the dvdauthor tool, spumux. According to the dvdauthor home page: “DVDAuthor is a set of tools to help you author the file and directory structure of a DVD-Video disc, including programmatic commands for implementing interactive behaviour.” According to the spumux man page: “spumux – generates and multiplexes subtitles into an existing mpeg2 program stream” . This section describes how to use the SPUPNG format to create a very simple DVD-Video that plays one video. The procedure assumes a computer with a DVD burner running a Ubuntu flavor of Linux with the dvdauthor, ffmpeg (or libav-tools) and dvd+rw-tools packages installed. The tools in these packages are designed to be used from the command line and the dvdauthor tools are driven by XML files. A number of graphical user interface front ends for these packages are also available, some of which have been ported to Windows, along with the underlying dvdauthor and ffmpeg/libav-tools packages. More information can be found at the dvdauthor home page. I have not used any of the Windows applications, so their use is beyond my area of expertise. . Extract closed captions in SPUPNG format . ccextractor -out=spupng -o spumux.xml source-video-file . | . This command will create the file, spumux.xml and a sub-directory, spumux.d. The sub-directory will contain lots of PNG files named subNNNN.png where NNNN is the 4 digit number of a closed caption starting at 0000. For example, the source video file used for the example screenshots, was one hour long and generated 1052 PNG files named sub0000.png to sub1052.png. Longer videos or videos with roll-up captions will generate more PNG files. . Transcode video to DVD-Video format | . Different Linux distributions will support either the ffmpeg package or the libav-tools package. The ffmpeg/avconv programs are complex and require many command line options to get the desired result. I maintain a shell script, do-ffmpeg, which I edit as needed to select: . Cropping options, useful when the source video is letterboxed, . | Video bit rate (which determines how many hours can fit on a DVD with a tradeoff on quality), . | Video resolution (the DVD standard allows four different resolutions for NTSC and PAL each, I will usually use the most common, 720x480, but if the source video width is 704, I will use 704x480), . | Audio codec. I always try to copy the source video audio, but sometimes there is noise in the source that throws audio and video out of sync. In that case, I use options that transcode the audio and help maintain a/v sync. . | Whether to deinterlace. I usually do. . | Aspect ratio, either. 16:9 or 4:3. . | . Here is the do-ffmpeg script for ffmpeg version 0.6: . #!/bin/bash # Transcode video to DVD-Video compatible format. # Usage: do-ffmpeg infile outfile if [ $# != 2 ] then echo &quot;Usage: do-ffmpeg infile outfile&quot; exit 1 fi # options of interest (applicable to ffmpeg version 0.6): # Cropping: # If a widescreen video is letterboxed in a 4:3 aspect ratio, # you might want to crop the letterboxed format, using the following: #crop=&quot;-croptop 60 -cropbottom 60&quot; # Sometimes you get a 4:3 video that&#39;s been letterboxed on the sides, too: crop=&quot;-croptop 60 -cropbottom 60 -cropleft 90 -cropright 90&quot; # The numbers need to be adjusted for the source video resolution # Bitrate determines the size and quality of the video: # 4670k = approx 2 hours of video on a 4.7GB single layer DVD # 3200k = approx 3 hours of video on a 4.7GB single layer DVD # 2400k = approx 4 hours of video on a 4.7GB single layer DVD bitrate=2400k # Video resolution: # Valid values for NTSC DVD-Video are: 720x480 704x480 352x480 352x240 # Valid values for PAL DVD-Video are: 720x576 704x576 352x576 352x288 # I usually use 720x480, unless the input is 704 wide, then I use 704x480 size=720x480 # Audio codec # If input file&#39;s audio is AC-3 or MPEG layer-2, you can usually let # ffmpeg copy it, using the following value for $acodec #acodec=&quot;-acodec copy&quot; # If the input audio isn&#39;t one of the above, or if there is noise in the audio # stream that throws audio-video out of sync, the following usually fixes it. acodec=&quot;-acodec ac3 -ab 192k -ac 2 -async 1200&quot; # Whether to deinterlace video: deint=&quot;-deinterlace&quot; # Aspect ratio: # 16:6 = widescreen # 4:3 = fullscreen aspect=&quot;4:3&quot; ffmpeg -threads 4 -v 1 -i $1 $deint $crop -r ntsc -target ntsc-dvd -b $bitrate -s $size $acodec -copyts -aspect $aspect -y $2 . If you are using a Linux distribution that supports libav-tools you will need a somewhat different script do-avconv: . #!/bin/bash # Transcode video to DVD-Video compatible format. # Usage: do-avconv infile outfile if [ $# != 2 ] then echo &quot;Usage: do-avconv infile outfile&quot; exit 1 fi # options of interest (applicable to avconv version 0.8.9): # Cropping: # If a widescreen video is letterboxed in a 4:3 aspect ratio, # you might want to crop the letterboxed format, using the following: #crop=&quot;-vf crop=in_w:in_h*3/4,scale=720:480&quot; # Sometimes you get a 4:3 video that&#39;s been letterboxed on the sides, too: crop=&quot;-vf crop=in_w*3/4:in_h*3/4,scale=720:480&quot; # The scale should match the target video resolution # i.e. same as size below # Bitrate determines the size and quality of the video: # 4670k = approx 2 hours of video on a 4.7GB single layer DVD # 3200k = approx 3 hours of video on a 4.7GB single layer DVD # 2400k = approx 4 hours of video on a 4.7GB single layer DVD bitrate=2400k # Video resolution: # Valid values for NTSC DVD-Video are: 720x480 704x480 352x480 352x240 # Valid values for PAL DVD-Video are: 720x576 704x576 352x576 352x288 # I usually use 720x480, unless the input is 704 wide, then I use 704x480 size=720x480 # Audio codec # If input file&#39;s audio is AC-3 or MPEG layer-2, you can usually let # avconv copy it, using the following value for $acodec #acodec=&quot;-c:a copy&quot; # If the input audio isn&#39;t one of the above, or if there is noise in the audio # stream that throws audio-video out of sync, the following usually fixes it. acodec=&quot;-c:a ac3 -b:a 192k -ac 2 -async 1200&quot; # Whether to deinterlace video: deint=&quot;-vf yadif&quot; # Aspect ratio: # 16:6 = widescreen # 4:3 = fullscreen aspect=&quot;4:3&quot; avconv -threads 4 -v debug -i $1 $deint $crop -r ntsc -target ntsc-dvd -b:v $bitrate -s $size $acodec -copyts -aspect $aspect -y $2 . After editing the script, transcode the source video with the command: . do-ffmpeg source-video-file transcoded.mpg . or . do-avconv source-video-file transcoded.mpg . Multiplex SPUPNG captions into subtitle stream . spumux spumux.xml `&lt; transcoded.mpg &gt;` subtitles.mpg . Create DVD-Video directory structure . Dvdauthor requires an XML file as input. Following is an extremely simple example that should start playing the subtitles.mpg as soon as the DVD is loaded in your DVD player. Paste it into a file called dvdauthor.xml. . `&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;` `&lt;dvdauthor&gt;` `&lt;vmgm /&gt;` `&lt;titleset&gt;` `&lt;titles&gt;` `&lt;video aspect=&quot;4:3&quot; format=&quot;ntsc&quot; /&gt;` `&lt;audio format=&quot;ac3&quot; lang=&quot;en&quot;/&gt;` `&lt;subpicture lang=&quot;en&quot; &gt;` &lt;!-- doesn&#39;t work w/ dvdauthor 0.6.18 despite being documented in man page `&lt;stream mode=&quot;normal&quot; id=&quot;0&quot; content=&quot;forced&quot; /&gt;` --&gt; `&lt;/subpicture&gt;` `&lt;pgc&gt;` `&lt;vob file=&quot;subtitles.mpg&quot; /&gt;` `&lt;/pgc&gt;` `&lt;/titles&gt;` `&lt;/titleset&gt;` `&lt;/dvdauthor&gt;` . If you change the name of the output file, subtitles.mpg, in step 3, be sure to change it in the &lt;vob&gt; element. Create the DVD-Video directory structure in a sub-directory called dvd with the command: . dvdauthor -o dvd -x dvdauthor.xml . If you repeat the command, be sure to first delete the dvd sub-directory. . Burn DVD . Load a blank DVD into your DVD burner. Then burn with this command: . growisofs -dvd-video -V &#39;MyLabel&#39; –Z /dev/dvd dvd . Play DVD . The video should start playing as soon as the DVD is read by your player. You will need to turn on subtitles using whatever mechanism your player supports, perhaps by pressing a subtitle key on the remote. Enjoy! . Contact If you have questions or comments about the SPUPNG output format, please direct them to: .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-using_spupng.html",
            "relUrl": "/2020/02/20/public-general-using_spupng.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post76": {
            "title": "Public:general:tvsamples",
            "content": "We often get requests for samples from other developers and users. Our full collection is available to developers that need it (/ccextractor-wiki-test/2020/02/20/some of the samples were submitted by people who explicitly told us not to make them public, which we honor) However we’re starting to build a small public repository for everyone who wants to test. . The following link contains 10 minutes recorded of over 30 US TV channels. They were made with a HDHomeRun on Dec 14, 2016. The provider is Comcast. Nothing really interesting in content - 10 minutes per channel, recording in the West Coast morning, so just daytime TV, whatever was on. . US TV recordings, 10 minutes samples, HDHomeRun, Comcast . US TV recordings from 2017, unknown provider . The following link contains short recordings from some non-subscription UK channels. Some of them come from a multicast stream and some were recorded with a HDHomeRun. Whatever was on at the time (8 pm to 10 pm UK time). Be aware that the UK considers their citizens to be adults that can just switch channels if they don’t like what they see. . UK TV recordings . The following link contains 15 minute recording from the same UK channels as above. We have the original .ts files (that would be the input for any CCExtractor processing) and the same files with the DVB subtitles burned-in with FFMpeg in .mp4, which is very convenient to check timing. Also the .srt files with default CCExtractor settings (as of 0.85 prelease) and with -ignoreptsjumps are included. . 2017-01-09 UK samples (ts/mp4 with burned in subtitles) . The following link contains some recordings from Scandinavian countries. Teletext. . Scandinavian recordings . The following link contains some Russian samples. Teletext. . Russian teletext samples . And this one, more (unclassified) Russian samples. Some seem to have DVB. . [[https://drive.google.com/drive/folders/0B_61ywKPmI0TVm8wVEpXampjblU?usp=sharing | Russian unclassified samples]] | —————————— . Multiprogram transport streams. multiprogram_spanish.ts is quite interesting in that there’s a mix of DVB and teletext plus TV and radio channels. . Multiprogram transport streams . Korean samples. See this issue in GitHub for details. . Korean samples . The following link is a TV show with both regular closed captions and burned-in subtitles (in English, when the characters speak in Russian). This is the original unedited transport stream, with commercials. For development purposes only. . Dual closed captions - burned-in subtitles transport stream . Arabic samples . Brazilian samples . Chinese samples . Some transport streams with no PAT or PMT . European samples, teletext . __Misc files__ . ccextractor_bugs_allcaps_29fps_leftjustify.m2ts dvb-sub captions containing multiple lines of text. . big_buck_bunny_eac3_4.m2ts DVB-sub captions which prior versions of ccextractor failed to extract. . channel5-2018-02-12.ts A recording from Channel 5 (UK). Forget about the content itself (it’s in the middle of two random programs). The important thing is that we do a terrible job with the OCR. . DJI_0019.MP4 A recording (.mp4) from a Drone in which the telemetry data is saved as subtitles. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-tvsamples.html",
            "relUrl": "/2020/02/20/public-general-tvsamples.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post77": {
            "title": "Public:general:support",
            "content": "Slack . Slack is a great communication tool. Most CCExtractor developers hang out in a slack team. You’re welcome to request an invitation here: {slackinvite} . Technical issues . By far the best way to get report issues is by opening a ticket at GitHub’s issue tracker. . When creating a ticket: . Make sure you are using the last CCExtractor version. | If it’s a new thing (for example a video file that a previous CCExtractor version processed OK and now causes a crash) mention the last version you know was correct. | If the issue is about a specific file, make that file available for us. Don’t just send us the output from CCExtractor, we can’t do anything about a screenshot that shows a crash, we need the input that actually causes it. Preferably you make it available for us on the Sample Platform, but you can also upload the file to Dropbox, Google Drive, etc, and add a download link to your ticket. | If you cannot make the file public for any (/ccextractor-wiki-test/2020/02/20/reasonable) reason you can send us a private invitation (/ccextractor-wiki-test/2020/02/20/both Dropbox and Google Drive allow that). In this case we will download the file and upload it to the private developer repository. | Do not upload your file to any location that will require us to sign up or endure a wait list, slow downloads, etc. | If your upload expires make sure you keep it active somehow (replace links if needed). Keep in mind that while we go over all tickets some may take a few days, and it’s important we have the file available when we actually need it. | Make sure you set an alert in GitHub so you get notifications about your ticket. We may need to ask questions and we do everything inside GitHub’s system. | Please use English. | It goes without saying, we like polite people. | . Mailing list . We do have a mailing list available on https://groups.google.com/forum/#!forum/ccextractor-dev, and all GitHub issues are posted here. . It’s read by the right people; you can use it if you prefer it to Slack. . Email . If you need to use email, you can reach the organisation’s admin on the next email address: .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-support.html",
            "relUrl": "/2020/02/20/public-general-support.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post78": {
            "title": "Public:general:subtitle_standards_around_the_world",
            "content": "(document produced by Code-In student Deborah Chan) . Countries under ATSC standards: Old: CEA-608 New: CEA-708 . Asia/Pacific: South Korea United States Minor Outlying Islands (American Samoa, Guam, Northern Mariana Islands) . North America: Bahamas Canada Dominican Republic El Salvador Mexico United States (including Puerto Rico and U.S. Virgin Islands) . South America: Suriname . Countries under DVB standards: EN 300-743 http://www.etsi.org/deliver/etsi_en/300700_300799/300743/01.05.01_60/en_300743v010501p.pdf . Africa: Kenya South Africa Madagascar . Asia: China Hong Kong Iran Israel Japan Malaysia Philippines Taiwan . Europe: Cyprus Denmark Finland Iceland Italy Netherlands Norway Poland Portugal Romania Russia Sweden United Kingdom . Australia: http://www.abc.net.au/mediawatch/transcripts/1105_freetvguidelines.pdf . Croatia: http://dhap.hr/en/articles/criteria-for-quality-subtitlin/8 . France: (only available in French) http://www.csa.fr/content/download/20043/334122/file/Chartesoustitrage122011.pdf . Ireland: www.bai.ie/en/download/128530/ . Countries/Areas with more than 1 standard found: Canada: https://www.dcmp.org/caai/nadh218.pdf http://www.cab-acr.ca/english/social/captioning/captioning.pdf http://www.crtc.gc.ca/eng/archive/2012/2012-362.pdf . EU: https://tech.ebu.ch/docs/tech/tech3350.pdf?vers=1.0 . United Kingdom: http://bbc.github.io/subtitle-guidelines/ http://www.bbc.co.uk/guidelines/futuremedia/accessibility/subtitling_guides/online_sub_editorial_guidelines_vs1_1.pdf http://www.channel4.com/media/documents/corporate/foi-docs/SG_FLP.pdf . Unites States: https://backlothelp.netflix.com/hc/en-us/articles/215758617-Timed-Text-Style-Guide-General-Requirements http://main.wgbh.org/wgbh/pages/mag/services/captioning/faq/sugg-styles-conv-faq.html http://transition.fcc.gov/cgb/consumerfacts/closedcaption.pdf http://www.ecfr.gov/cgi-bin/text-idx?SID=72eb5a624e8dc043293819a5663dff41&amp;node=47:4.0.1.1.6.1.1.1&amp;rgn=div8=47 https://www.smpte.org/sites/default/files/24TB-FCC-Technical-Requirements-20120908.pdf .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-subtitle_standards_around_the_world.html",
            "relUrl": "/2020/02/20/public-general-subtitle_standards_around_the_world.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post79": {
            "title": "Public:general:rust_resources:rust",
            "content": "About Rust . What can do you with Rust? . Why the Rust language is on the rise . My first impressions of Rust . Useful reads . From Python into Rust . into_rust() : Screencasts for learning Rust! . Stanford course on Rust . Comparing C and Rust network protocol exercises . Vectors and Hash Maps . Big Data Benchmarks . Journey to Async/Await . Rust once and share it with Android, iOS and Flutter . Problems (hint: we use these resources ourselves for tasks) . Thread on reddit . Rust examples and exercises . Paid courses . (we will buy them for students that get the rewards by doing tasks) . Rust in motion .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-rust_resources-rust.html",
            "relUrl": "/2020/02/20/public-general-rust_resources-rust.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post80": {
            "title": "Rotating capture system with HDHomeRun",
            "content": "This is Carlos’ quick and dirty solution to have a grid with captions from all stations using a few tuners, obviously by rotating them to cover all channels. . File directories: . /bin/ -&gt; Scripts . | /channels/ -&gt; Channels, each file being a channel. If name starts with a C then it’s cable, if it’s a B it’s broadcast, anything else is ignored. . | /tuners/ -&gt; One file per tuner, with this naming $devicetype-$tunertype-$masterorregular-$deviceid-$tunernumber where $devicetype is always HDR (for now only HDHomeRun is supported) $tunertype is USC (US-cable) or USB (US-broadcast) $masterorregular is M or R, if M then this tuner will be used to scan for channels by the chanscan script that populates the /channels/ directory $deviceid is the device ID. For HDHomeRun is returned by hdhomerun_config $tunernumber is the number within the device, so for a device with 3 tuners it’s 0-2 . | . Scripts: . /bin/tuner_scan -&gt; Discover HDHomeRun devices and features, build contents of /tuners/ . | /bin/channel_scan -&gt; Scan for channels, build contents of /channels/ . | /bin/cc_boot -&gt; Starts one capture process per tuner . | /bin/cc_capture -&gt; Using one of the tuners, capture data from a channel in round-robin . | . The /channels/ directory contains one file per channel. When a channel is being recorded its file must be renamed to $name.inuse. When done, touched, then renamed back to $name.free. If a process attempts to rename a channel file and fails it must assume that some other process picked up that channel and must continue to the next one. . The cc_capture script always reads contents of /channels/ and picks the oldest file that is free (meaning there isn’t another process capturing it). . Done: . Create system user (/ccextractor-wiki-test/2020/02/20/captions), copy public key . | Edit sudoers . | . To-do: . Create tuner_scan . | Create channel_scan . | Create cc_capture . | Create cc_boot . | .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-rotating_capture_system_with_hdhomerun.html",
            "relUrl": "/2020/02/20/public-general-rotating_capture_system_with_hdhomerun.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post81": {
            "title": "Public:general:misc:vim",
            "content": "Using Vim as your main editor for web development .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-misc-vim.html",
            "relUrl": "/2020/02/20/public-general-misc-vim.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post82": {
            "title": "Public:general:misc:useful_linux_tools",
            "content": "Tmate - Instant terminal sharing .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-misc-useful_linux_tools.html",
            "relUrl": "/2020/02/20/public-general-misc-useful_linux_tools.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post83": {
            "title": "Public:general:misc:interview_preparation",
            "content": "For now this is quite disorganized, just a collection of links. But it will get better :-) . Data Structures and Algorithms coding challenge #2 . 101 Coding Problems and few Tips to Crack Your Next Programming Interviews .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-misc-interview_preparation.html",
            "relUrl": "/2020/02/20/public-general-misc-interview_preparation.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post84": {
            "title": "Public:general:http:sourceforge.net_donate_index.php",
            "content": "If you like CCExtractor but can’t submit code patches, or video samples, you can contribute a bit by inviting the developers to a beer which is just as fine as all other kinds of support. . Donate via sourceforge .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-http-sourceforge.net_donate_index.php.html",
            "relUrl": "/2020/02/20/public-general-http-sourceforge.net_donate_index.php.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post85": {
            "title": "Public:general:how_to_hire_us",
            "content": "If you need custom work regarding CCExtractor you can send Carlos an email: . Carlos is currently in San Francisco. . An important thing: CCExtractor changes always become part of the mainstream version. We don’t keep one open source version and many private versions for clients. . Work related to CCExtractor that does not require changes to CCExtractor itself (GUIs, monitoring system, integration with 3rd party software) can be closed source, subject to NDAs, etc. . In general jobs are offered to everyone in the team as this encourages developers to continue their involvement with CCExtractor. This means that even if Carlos is the first point of contact, it’s likely that someone else from the team will be available to help with the job. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-how_to_hire_us.html",
            "relUrl": "/2020/02/20/public-general-how_to_hire_us.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post86": {
            "title": "Getting started with CCExtractor’s source code",
            "content": "This page is currently being written (a bit every day, actively) so new developers that want to join us don’t have to learn the basics from scratch. . We often get questions about how to get started with our code. The most important thing would be: Don’t try to read and understand every file, because it’s pointless and there’s no need. While it’s definitely not the linux kernel, CCExtractor’s code is not trivial, and it’s been written by a number of people during a long time. Often, that people was learning as they went, and it shows in parts of the code. . However, it’s important to have a general idea of how things are organized so you know where to look for things and how to add new features. . This page tries to explain the most important concepts and introduces the important files in the core CCExtractor tool. Note that we have additional tools such as our regression test platform, or the real time subtitle database. Those will be explained in their own pages. . CCExtractor is written in C. If you are a C++ developer that will have pretty much zero impact in your ability to contribute, because the really important differences are abstracted in functions anyway. Sure we don’t have classes and our I/O is different, but that’s really not a big deal here - you will need to understand file formats anyway, or how to read specification documents. None of that depends on the language of choice. . CCExtractor reads binary streams (a stream may be a file, but it can also be data coming from network - so don’t assume) and writes subtitle files. . Container formats . The usual audio/video streams come in a number of variants. You know how in files you have .avi, .mkv, .mp4, .mpeg and so on? Those are container formats, because they “contain” the parts of the media: Video, audio and subtitles. Each of those have some limitations, but in general, the contain format doesn’t specify how each part of the media is encoded. You have can a .mkv (Matroska) that contains the video encoded as MPEG-2, or H264, etc, then the audio as MP3, or AAC and so on. . In TV broadcast, the typical container is the Transport Stream (.ts). A Transport Stream can carry more than one TV program (for example, BBC One, BBC Two and BBC News), each of them with its own video, audio, and subtitles (and for each, maybe more than one language). . Streaming services such as iTunes uses .mp4. . The parts of CCExtractor that handle the containers are called demuxers. A demuxer is capable of reading a specific container and return parts of it. . Subtitles . Our input streams are files that contain subtitles. These subtitles can be encoded in a different ways depending on the country they come from or the technology used to make the recording. Focusing on recordings made from a TV broadcast, we have: . CEA-608, which is the “old” format used in North America. It comes from the analog days of NTSC, but while the transmission was analog, in the end you have 2 bytes (that’s digital) of subtitle data in each frame, and that’s the one thing that is important to keep in mind. You don’t need to bother understanding the analog part of the transmission, because what we process is just those two bytes. . By the way, in North America those subtitles that you can turn on and off are called closed captions. . CEA-708, is the “new” format used in North America. It’s all digital, and because when it was designed the TVs were a lot better, they had much more bandwidth for subtitles, they have lots more capabilities. . Teletext, is the old format in Europe. It’s still around, but it’s quickly being replaced with DVB. . DVB is the current format in Europe. It’s a bitmap based format, which means that instead of characters being transmitted it’s images (for example, for “CCExtractor” you would have the representation of the letters in graphics format, not one byte for each letter as you could expect). This makes DVB more capable, but also a lot harder to transcript to text, since a OCR is required. . ISDB is the format used in Brazil. . In CCExtractor, the parts of code responsible for handling the different subtitle formats are called decoders. . Combination of containers and subtitle formats . As explained, subtitles come in a number of encodings, and they can be carried in different containers. So you can have subtitles encoded in CEA-608 inside a .ts or a .mp4. And you can also have a .ts file or a .mp4 that contains subtitles in CEA-608 and DVB. . Once you have the subtitle data it doesn’t matter where it came from (what the container type is). Similarly, when processing a container, it doesn’t matter what type of subtitles are there. . Reading the containers . The first thing that we do is identify (unless the user specified it manually) the type of container we’re going to process. This is done by reading the first bytes and figuring it out for ourselves. . This happens in the function . void detect_stream_type (struct ccx_demuxer *ctx) . which is in the file stream_functions.c . That function (please check the code) sets the type format (best guess; identifying without fault is a lot harder than you’d think, but that’s not important for an introduction) for the context (more on contexts later). . Once we know what type of stream we’re processing we know which demuxer to use to read it. . We have demuxers for Transport Streams (in ts_functions.c), mp4 (in mp4.c) and more. The block that, after knowing the type of container, decides what to do, is in the main file, ccextractor.c, . /* -- MAIN LOOP -- */ switch (stream_mode) { ... } . User options, contexts, and in general where stuff is saved . When adding a new user option (that can be selected via command line argument) the steps are always the same: . 1) Add the corresponding variable in the structure . struct ccx_s_options // Options from user parameters { int extract; // Extract 1st, 2nd or both fields int no_rollup; int noscte20; int webvtt_create_css; ... } . which is defined in src/lib_ccx/ccx_common_option.h . 2) Initialize it to the correct default value in this function: . void init_options (struct ccx_s_options *options) { #ifdef _WIN32 options-&gt;buffer_input = 1; // In Windows buffering seems to help #else options-&gt;buffer_input = 0; // In linux, not so much. #endif options-&gt;nofontcolor=0; // 1 = don&#39;t put &lt;font color&gt; tags options-&gt;notypesetting=0; // 1 = Don&#39;t put &lt;i&gt;, &lt;u&gt;, etc typesetting tags . which is defined src/lib_ccx/ccx_common_option.c . 3) Add the corresponding parsing code in the function . int parse_parameters (struct ccx_s_options *opt, int argc, char *argv[]) { // Parse parameters for (int i=1; i&lt;argc; i++) { if (!strcmp (argv[i],&quot;--help&quot;) || !strcmp(argv[i], &quot;-h&quot;)) ... } . which is defined on src/lib_ccx/params.c . 4) Add usage instruction on the function . void print_usage (void) { mprint (&quot;Originally based on McPoodle&#39;s tools. Check his page for lots of information n&quot;); mprint (&quot;on closed captions technical details. n&quot;); ... } . which is also defined on src/lib_ccx/params.c . 5) Depending on what part of the code is going to actually be using that parameter you will need to copy it on the right place. The “place”, in general, is a context. A context is a structure that contain status values relevant to a group of functions, such as a decoder or an encoder. For example, if the new parameter applied to a decoder, we could copy it in the function that initializes the decoder contexts with user options: . static struct ccx_decoders_common_settings_t *init_decoder_setting( struct ccx_s_options *opt) { struct ccx_decoders_common_settings_t *setting; setting = malloc(sizeof(struct ccx_decoders_common_settings_t)); ... . Note that the function receives the same structure used in steps 2 and 3, and is going to return a struct ccx_decoders_common_settings_t* . . Finally, there’s the function that really initializes the decoder context from the decoder settings: . struct lib_cc_decode* init_cc_decode (struct ccx_decoders_common_settings_t *setting) { struct lib_cc_decode *ctx = NULL; . That struct lib_cc_decode* is what the decoders will have with all the options plus all the values they need to store as flow progresses. . 6) Use the variable. . A sample commit that does all the steps and adds a new option. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-gettingstartedwithourcode.html",
            "relUrl": "/2020/02/20/public-general-gettingstartedwithourcode.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post87": {
            "title": "Public:general:flutter_resources:flutter",
            "content": "======= Flutter resources ====== . Tutorials . Building a portfolio website . Game of Life with Flutter . 12 Useful libraries to support development using flutter . Flutter Tutorial: Real Estate App . Flutter Tutorial: Courses App . Handwriting number recognizer with Flutter and Tensorflow (part I) . A very sexy Flutter template app with great focus on UI . 60 Days Of Flutter : Building a Messenger from Scratch . Hotel Booking App UI . ChatBot in Flutter using DialogFlow . Roadmap To Become A Flutter Developer (Resources for Beginners) .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-flutter_resources-flutter.html",
            "relUrl": "/2020/02/20/public-general-flutter_resources-flutter.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post88": {
            "title": "Public:general:downloads",
            "content": "~~META: title = CCExtractor downloads ~~ . Current version: 0.88 (May 21st, 2019) . CCExtractor’s source code . CLI Source code full . CLI Source code without Windows blobs (reduced size) . Windows GUI Source code (Windows only; requires Visual Studio) . Cross platform GUI . Windows binaries . Windows binaries (just the GUI and the command line programs, without installation) . Windows installer, first attempt with InstallShield - if it doesn’t work just use the zipped binaries above . Note: Starting with 0.84 we’re bundling two binaries for the main program: With and without OCR. The reason is that the OCR (needed to convert the bitmap based European DVB subtitles into .srt, and also DVD) has its own dependencies, which may or may not be available in the user system. So if you don’t need the OCR and don’t feel like fighting with dependencies just use the non-OCR version which has no external dependencies and should work fine in everything from XP up. . About the Windows installer, we used to generate .msi installers but that seems to be discontinued by Microsoft - Visual Studio generates them with an expired certificate which causes warnings. We’ve prepared a new installer using InstallShield. Please report issues if any. Things we are already aware of: . It doesn’t check for NET 2.0 being present, because it’s too old. However we’re still targeting it because for now we don’t need anything advanced and NET 2.0 works in XP. If you are wondering why we care about XP it’s because it’s the last OS that supports some ancient hardware that is still in use that cannot be replaced for a number of reasons. | It says “Unknown publisher”, because we currently don’t have a code signing certificate. | You need to uninstall any previous version before installing, it cannot just update, even if all it would take is just to overwrite files. | . Mac . Homebrew package (3rd party, not maintained by the CCExtractor team) . Additional software written by the team . User Documentation for Subtitle Downloader . User Documentation for Activity Extractor . CCAligner - Word by Word Audio Subtitle Synchronisation Tool and API . Dependencies . Visual C++ Redistributable Packages for Visual Studio 2013 (this might be needed to run CCExtractor 0.70 and above in XP). . Dependencies for the full CCExtractor version (with FFmpeg, OCR, etc) (they are included in the distribution packages but we have them separately for convenience). .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-downloads.html",
            "relUrl": "/2020/02/20/public-general-downloads.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post89": {
            "title": "Public:general:coollinkswithsubfs",
            "content": "~~META: title = Cool external projects that use subtitles or do sorcery with a video stream ~~ . Note to GSoC applicants: Yes, you can use them. That’s what open source is for. But if you decide to base on work on any of these: 1) Contact the original developer(s) and share your plan. They may be able to help you, but it’s just a courtesy. 2) You proposal should consider that you are not starting from scratch. 3) Make sure you keep original credits intact, even in the cases where the license allows you to remove them. 4) Make sure you share your work with the original author. . Videodigest: Automatic Video Summaries . Videogrep . Some More Videogreping With Python . Videoparts . C-SPAN Excerpts . Cinemini . aeneas is a Python/C library and a set of tools to automagically synchronize audio and text (aka forced alignment). . lachesis automates the segmentation of a transcript into closed captions (CCs). . This example demonstrates how to generate GIFs from automatically determined video highlights . Pytube is a Python library (and command line tool) to download Youtube videos, including subtitles. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-coollinkswithsubfs.html",
            "relUrl": "/2020/02/20/public-general-coollinkswithsubfs.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post90": {
            "title": "Public:general:command_line_usage",
            "content": "CCExtractor’s main program is console based. There’s a GUI for Windows, as well as provisions so other programs can easily interface with CCExtractor, but the heavy lefting is done by a command line program (that can be called by scripts so integration with larger processes is straightforward). . Running CCExtractor without any parameter will display a help screen with all the options. As of version 0.81 the help screen is as follows: . CCExtractor 0.81, Carlos Fernandez Sanz, Volker Quetschke. Teletext portions taken from Petr Kutalek&#39;s telxcc -- Originally based on McPoodle&#39;s tools. Check his page for lots of information on closed captions technical details. (http://www.theneitherworld.com/mcpoodle/SCC_TOOLS/DOCS/SCC_TOOLS.HTML) This tool home page: http://www.ccextractor.org Extracts closed captions and teletext subtitles from video streams. (DVB, .TS, ReplayTV 4000 and 5000, dvr-ms, bttv, Tivo, Dish Network, .mp4, HDHomeRun are known to work). Syntax: ccextractor [options] inputfile1 [inputfile2...] [-o outputfilename] To see This Help Message: -h or --help File name related options: inputfile: file(s) to process -o outputfilename: Use -o parameters to define output filename if you don&#39;t like the default ones (same as infile plus _1 or _2 when needed and file extension, e.g. .srt). -o or -o1 -&gt; Name of the first (maybe only) output file. -o2 -&gt; Name of the second output file, when it applies. -cf filename: Write &#39;clean&#39; data to a file. Cleans means the ES without TS or PES headers. -stdout: Write output to stdout (console) instead of file. If stdout is used, then -o, -o1 and -o2 can&#39;t be used. Also -stdout will redirect all messages to stderr (error). -stdin: Reads input from stdin (console) instead of file. You can pass as many input files as you need. They will be processed in order. If a file name is suffixed by +, ccextractor will try to follow a numerical sequence. For example, DVD001.VOB+ means DVD001.VOB, DVD002.VOB and so on until there are no more files. Output will be one single file (either raw or srt). Use this if you made your recording in several cuts (to skip commercials for example) but you want one subtitle file with contiguous timing. Effect output files -outinterval x output in interval of x seconds Network support: -udp port: Read the input via UDP (listening in the specified port) instead of reading a file. -udp [host:]port: Read the input via UDP (listening in the specified port) instead of reading a file. Host can be a hostname or IPv4 address. If host is not specified then listens on the local host. -sendto host[:port]: Sends data in BIN format to the server according to the CCExtractor&#39;s protocol over TCP. For IPv6 use [addres]:port -tcp port: Reads the input data in BIN format according to CCExtractor&#39;s protocol, listening specified port on the local host -tcppassword password: Sets server password for new connections to tcp server -tcpdesc description: Sends to the server short description about captions e.g. channel name or file name Options that affect what will be processed: -1, -2, -12: Output Field 1 data, Field 2 data, or both (DEFAULT is -1) Use --append to prevent overwriting of existing files. The output will be appended instead. -cc2: When in srt/sami mode, process captions in channel 2 instead of channel 1. -svc --service N1[cs1],N2[cs2]...: Enable CEA-708 (DTVCC) captions processing for the listed services. The parameter is a comma delimited list of services numbers, such as &quot;1,2&quot; to process the primary and secondary language services. Pass &quot;all&quot; to process all services found. If captions in a service are stored in 16-bit encoding, you can specify what charset or encoding was used. Pass its name after service number (e.g. &quot;1[EUC-KR],3&quot; or &quot;all[EUC-KR]&quot;) and it will encode specified charset to UTF-8 using iconv. See iconv documentation to check if required encoding/charset is supported. In general, if you want English subtitles you don&#39;t need to use these options as they are broadcast in field 1, channel 1. If you want the second language (usually Spanish) you may need to try -2, or -cc2, or both. Input formats: With the exception of McPoodle&#39;s raw format, which is just the closed caption data with no other info, CCExtractor can usually detect the input format correctly. To force a specific format: -in=format where format is one of these: ts -&gt; For Transport Streams. ps -&gt; For Program Streams. es -&gt; For Elementary Streams. asf -&gt; ASF container (such as DVR-MS). wtv -&gt; Windows Television (WTV) bin -&gt; CCExtractor&#39;s own binary format. raw -&gt; For McPoodle&#39;s raw files. mp4 -&gt; MP4/MOV/M4V and similar. -ts, -ps, -es, -mp4, -wtv and -asf (or --dvr-ms) can be used as shorts. Output formats: -out=format where format is one of these: srt -&gt; SubRip (default, so not actually needed). ass/ssa -&gt; SubStation Alpha. webvtt -&gt; WebVTT format sami -&gt; MS Synchronized Accesible Media Interface. bin -&gt; CC data in CCExtractor&#39;s own binary format. raw -&gt; CC data in McPoodle&#39;s Broadcast format. dvdraw -&gt; CC data in McPoodle&#39;s DVD format. txt -&gt; Transcript (no time codes, no roll-up captions, just the plain transcription. ttxt -&gt; Timed Transcript (transcription with time info) smptett -&gt; SMPTE Timed Text (W3C TTML) format. spupng -&gt; Set of .xml and .png files for use with dvdauthor&#39;s spumux. See &quot;Notes on spupng output format&quot; null -&gt; Don&#39;t produce any file output report -&gt; Prints to stdout information about captions in specified input. Don&#39;t produce any file output Options that affect how input files will be processed. -gt --goptime: Use GOP for timing instead of PTS. This only applies to Program or Transport Streams with MPEG2 data and overrides the default PTS timing. GOP timing is always used for Elementary Streams. -nogt --nogoptime: Never use GOP timing (use PTS), even if ccextractor detects GOP timing is the reasonable choice. -fp --fixpadding: Fix padding - some cards (or providers, or whatever) seem to send 0000 as CC padding instead of 8080. If you get bad timing, this might solve it. -90090: Use 90090 (instead of 90000) as MPEG clock frequency. (reported to be needed at least by Panasonic DMR-ES15 DVD Recorder) -ve --videoedited: By default, ccextractor will process input files in sequence as if they were all one large file (i.e. split by a generic, non video-aware tool. If you are processing video hat was split with a editing tool, use -ve so ccextractor doesn&#39;t try to rebuild the original timing. -s --stream [secs]: Consider the file as a continuous stream that is growing as ccextractor processes it, so don&#39;t try to figure out its size and don&#39;t terminate processing when reaching the current end (i.e. wait for more data to arrive). If the optional parameter secs is present, it means the number of seconds without any new data after which ccextractor should exit. Use this parameter if you want to process a live stream but not kill ccextractor externally. Note: If -s is used then only one input file is allowed. -poc --usepicorder: Use the pic_order_cnt_lsb in AVC/H.264 data streams to order the CC information. The default way is to use the PTS information. Use this switch only when needed. -myth: Force MythTV code branch. -nomyth: Disable MythTV code branch. The MythTV branch is needed for analog captures where the closed caption data is stored in the VBI, such as those with bttv cards (Hauppage 250 for example). This is detected automatically so you don&#39;t need to worry about this unless autodetection doesn&#39;t work for you. -wtvconvertfix: This switch works around a bug in Windows 7&#39;s built in software to convert *.wtv to *.dvr-ms. For analog NTSC recordings the CC information is marked as digital captions. Use this switch only when needed. -wtvmpeg2: Read the captions from the MPEG2 video stream rather than the captions stream in WTV files -pn --program-number: In TS mode, specifically select a program to process. Not needed if the TS only has one. If this parameter is not specified and CCExtractor detects more than one program in the input, it will list the programs found and terminate without doing anything, unless -autoprogram (see below) is used. -autoprogram: If there&#39;s more than one program in the stream, just use the first one we find that contains a suitable stream. -datapid: Don&#39;t try to find out the stream for caption/teletext data, just use this one instead. -datastreamtype: Instead of selecting the stream by its PID, select it by its type (pick the stream that has this type in the PMT) -streamtype: Assume the data is of this type, don&#39;t autodetect. This parameter may be needed if -datapid or -datastreamtype is used and CCExtractor cannot determine how to process the stream. The value will usually be 2 (MPEG video) or 6 (MPEG private data). -haup --hauppauge: If the video was recorder using a Hauppauge card, it might need special processing. This parameter will force the special treatment. -mp4vidtrack: In MP4 files the closed caption data can be embedded in the video track or in a dedicated CC track. If a dedicated track is detected it will be processed instead of the video track. If you need to force the video track to be processed instead use this option. -noautotimeref: Some streams come with broadcast date information. When such data is available, CCExtractor will set its time reference to the received data. Use this parameter if you prefer your own reference. Note: Current this only affects Teletext in timed transcript with -datets. --noscte20: Ignore SCTE-20 data if present. Options that affect what kind of output will be produced: -bom: Append a BOM (Byte Order Mark) to output files. Note that most text processing tools in linux will not like BOM. This is the default in Windows builds. -nobom: Do not append a BOM (Byte Order Mark) to output files. Note that this may break files when using Windows. This is the default in non-Windows builds. -unicode: Encode subtitles in Unicode instead of Latin-1. -utf8: Encode subtitles in UTF-8 (no longer needed. because UTF-8 is now the default). -latin1: Encode subtitles in Latin-1 -nofc --nofontcolor: For .srt/.sami/.vtt, don&#39;t add font color tags. --nohtmlescape: For .srt/.sami/.vtt, don&#39;t covert html unsafe character -nots --notypesetting: For .srt/.sami/.vtt, don&#39;t add typesetting tags. -trim: Trim lines. -dc --defaultcolor: Select a different default color (instead of white). This causes all output in .srt/.smi/.vtt files to have a font tag, which makes the files larger. Add the color you want in RGB, such as -dc #FF0000 for red. -sc --sentencecap: Sentence capitalization. Use if you hate ALL CAPS in subtitles. --capfile -caf file: Add the contents of &#39;file&#39; to the list of words that must be capitalized. For example, if file is a plain text file that contains Tony Alan Whenever those words are found they will be written exactly as they appear in the file. Use one line per word. Lines starting with # are considered comments and discarded. -unixts REF: For timed transcripts that have an absolute date instead of a timestamp relative to the file start), use this time reference (UNIX timestamp). 0 =&gt; Use current system time. ccextractor will automatically switch to transport stream UTC timestamps when available. -datets: In transcripts, write time as YYYYMMDDHHMMss,ms. -sects: In transcripts, write time as ss,ms -UCLA: Transcripts are generated with a specific format that is convenient for a specific project, feel free to play with it but be aware that this format is really live - don&#39;t rely on its output format not changing between versions. -lf: Use LF (UNIX) instead of CRLF (DOS, Windows) as line terminator. -autodash: Based on position on screen, attempt to determine the different speakers and a dash (-) when each of them talks (.srt/.vtt only, -trim required). -xmltv mode: produce an XMLTV file containing the EPG data from the source TS file. Mode: 1 = full output 2 = live output. 3 = both -sem: Create a .sem file for each output file that is open and delete it on file close. Options that affect how ccextractor reads and writes (buffering): -bi --bufferinput: Forces input buffering. -nobi -nobufferinput: Disables input buffering. -bs --buffersize val: Specify a size for reading, in bytes (suffix with K or or M for kilobytes and megabytes). Default is 16M. -koc: keep-output-close. If used then CCExtractor will close the output file after writing each subtitle frame and attempt to create it again when needed. -ff --forceflush: Flush the file buffer whenever content is written. Options that affect the built-in closed caption decoder: -dru: Direct Roll-Up. When in roll-up mode, write character by character instead of line by line. Note that this produces (much) larger files. -noru --norollup: If you hate the repeated lines caused by the roll-up emulation, you can have ccextractor write only one line at a time, getting rid of these repeated lines. -ru1 / ru2 / ru3: roll-up captions can consist of 2, 3 or 4 visible lines at any time (the number of lines is part of the transmission). If having 3 or 4 lines annoys you you can use -ru to force the decoder to always use 1, 2 or 3 lines. Note that 1 line is not a real mode rollup mode, so CCExtractor does what it can. In -ru1 the start timestamp is actually the timestamp of the first character received which is possibly more accurate. Options that affect timing: -delay ms: For srt/sami/webvtt, add this number of milliseconds to all times. For example, -delay 400 makes subtitles appear 400ms late. You can also use negative numbers to make subs appear early. Notes on times: -startat and -endat times are used first, then -delay. So if you use -srt -startat 3:00 -endat 5:00 -delay 120000, ccextractor will generate a .srt file, with only data from 3:00 to 5:00 in the input file(s) and then add that (huge) delay, which would make the final file start at 5:00 and end at 7:00. Options that affect what segment of the input file(s) to process: -startat time: Only write caption information that starts after the given time. Time can be seconds, MM:SS or HH:MM:SS. For example, -startat 3:00 means &#39;start writing from minute 3. -endat time: Stop processing after the given time (same format as -startat). The -startat and -endat options are honored in all output formats. In all formats with timing information the times are unchanged. -scr --screenfuls num: Write &#39;num&#39; screenfuls and terminate processing. Options that affect which codec is to be used have to be searched in input If codec type is not selected then first elementary stream suitable for subtitle is selected, please consider -teletext -noteletext override this option. -codec dvbsub select the dvb subtitle from all elementary stream, if stream of dvb subtitle type is not found then nothing is selected and no subtitle is generated -nocodec dvbsub ignore dvb subtitle and follow default behaviour -codec teletext select the teletext subtitle from elementary stream -nocodec teletext ignore teletext subtitle NOTE: option given in form -foo=bar ,-foo = bar and --foo=bar are invalid valid option are only in form -foo bar nocodec and codec parameter must not be same if found to be same then parameter of nocodec is ignored, this flag should be passed once, more then one are not supported yet and last parameter would taken in consideration Adding start and end credits: CCExtractor can _try_ to add a custom message (for credits for example) at the start and end of the file, looking for a window where there are no captions. If there is no such window, then no text will be added. The start window must be between the times given and must have enough time to display the message for at least the specified time. --startcreditstext txt: Write this text as start credits. If there are several lines, separate them with the characters n, for example Line1 nLine 2. --startcreditsnotbefore time: Don&#39;t display the start credits before this time (S, or MM:SS). Default: 0 --startcreditsnotafter time: Don&#39;t display the start credits after this time (S, or MM:SS). Default: 5:00 --startcreditsforatleast time: Start credits need to be displayed for at least this time (S, or MM:SS). Default: 2 --startcreditsforatmost time: Start credits should be displayed for at most this time (S, or MM:SS). Default: 5 --endcreditstext txt: Write this text as end credits. If there are several lines, separate them with the characters n, for example Line1 nLine 2. --endcreditsforatleast time: End credits need to be displayed for at least this time (S, or MM:SS). Default: 2 --endcreditsforatmost time: End credits should be displayed for at most this time (S, or MM:SS). Default: 5 Options that affect debug data: -debug: Show lots of debugging output. -608: Print debug traces from the EIA-608 decoder. If you need to submit a bug report, please send the output from this option. -708: Print debug information from the (currently in development) EIA-708 (DTV) decoder. -goppts: Enable lots of time stamp output. -xdsdebug: Enable XDS debug data (lots of it). -vides: Print debug info about the analysed elementary video stream. -cbraw: Print debug trace with the raw 608/708 data with time stamps. -nosync: Disable the syncing code. Only useful for debugging purposes. -fullbin: Disable the removal of trailing padding blocks when exporting to bin format. Only useful for for debugging purposes. -parsedebug: Print debug info about the parsed container file. (Only for TS/ASF files at the moment.) -parsePAT: Print Program Association Table dump. -parsePMT: Print Program Map Table dump. -dumpdef: Hex-dump defective TS packets. -investigate_packets: If no CC packets are detected based on the PMT, try to find data in all packets by scanning. Teletext related options: -tpage page: Use this page for subtitles (if this parameter is not used, try to autodetect). In Spain the page is always 888, may vary in other countries. -tverbose: Enable verbose mode in the teletext decoder. -teletext: Force teletext mode even if teletext is not detected. If used, you should also pass -datapid to specify the stream ID you want to process. -noteletext: Disable teletext processing. This might be needed for video streams that have both teletext packets and CEA-608/708 packets (if teletext is processed then CEA-608/708 processing is disabled). Transcript customizing options: -customtxt format: Use the passed format to customize the (Timed) Transcript output. The format must be like this: 1100100 (7 digits). These indicate whether the next things should be displayed or not in the (timed) transcript. They represent (in order): - Display start time - Display end time - Display caption mode - Display caption channel - Use a relative timestamp ( relative to the sample) - Display XDS info - Use colors Examples: 0000101 is the default setting for transcripts 1110101 is the default for timed transcripts 1111001 is the default setting for -ucla Make sure you use this parameter after others that might affect these settings (-out, -ucla, -xds, -txt, -ttxt, ...) Communication with other programs and console output: --gui_mode_reports: Report progress and interesting events to stderr in a easy to parse format. This is intended to be used by other programs. See docs directory for. details. --no_progress_bar: Suppress the output of the progress bar -quiet: Don&#39;t write any message. Notes on the CEA-708 decoder: While it is starting to be useful, it&#39;s a work in progress. A number of things don&#39;t work yet in the decoder itself, and many of the auxiliary tools (case conversion to name one) won&#39;t do anything yet. Feel free to submit samples that cause problems and feature requests. Notes on spupng output format: One .xml file is created per output field. A set of .png files are created in a directory with the same base name as the corresponding .xml file(s), but with a .d extension. Each .png file will contain an image representing one caption and named subNNNN.png, starting with sub0000.png. For example, the command: ccextractor -out=spupng input.mpg will create the files: input.xml input.d/sub0000.png input.d/sub0001.png ... The command: ccextractor -out=spupng -o /tmp/output -12 input.mpg will create the files: /tmp/output_1.xml /tmp/output_1.d/sub0000.png /tmp/output_1.d/sub0001.png ... /tmp/output_2.xml /tmp/output_2.d/sub0000.png /tmp/output_2.d/sub0001.png ... Error: (This help screen was shown because there were no input files) .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-command_line_usage.html",
            "relUrl": "/2020/02/20/public-general-command_line_usage.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post91": {
            "title": "Public:general:about_the_org",
            "content": "~~META: title = About CCExtractor Development ~~ . CCExtractor Development is an informal (meaning we’re not incorporated anywhere) organization that exists to coordinate the development efforts of the volunteers that contribute to the software and to manage our participation in specific events such as Google Summer of Code and Code-In. . The following video is a contribution from Manveer Singh Basra, a Code-In 2016 student: .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-general-about_the_org.html",
            "relUrl": "/2020/02/20/public-general-about_the_org.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post92": {
            "title": "Mastermind #3: Write the backend (in any language you want) for a competition between student submissions",
            "content": "We already had two tasks about this superfun yet easy to understand game (links below). Many students have worked on creating mastermind players, so it’s time to make them compete against each other! Let’s see who’s algorithm is better. . In order to do this, we need a servers for the players to connect to and play. Your job is to implement such a server. . We have come up with a simple protocol between player and server. Your job here is to implement the server side. The protocol is like this: . When the player wants to start a game, it will request (via HTTP GET) . /himastermind/newgame/$name_of_player . The “name_of_player” can be anything (alphanumeric only) but it shouldn’t change - so if a player plays 100 times, it should use the same name in all of 100, so the server can keep track of results for each player. . A player here is the AI, not the name of the developer. In fact, don’t use your own name (that goes against GCI rules). . When that URL is called, the server will generate a random number (for the player to guess) and a “game ID” which it will return. The “game ID” (equivalent to “session ID”, if you are used to that term when taking about websites) is a 8 characters random string (alphanumeric). The game ID is returned to the player so he can pass it to play. . Then the game actually starts. The player will make requests like this: . /himastermind/play/$game_id/$guess . And the server will return: . $digits_in_the_right_position $digits_in_the_wrong_position $number_of_guesses_in_this_game $time_since_the_game_started . A possible interaction would be like this: . **CLIENT REQUESTS**: /himastermind/newgame/MazingerZ/1235678 **SERVER REPLIES**: AHVEDJ34 **CLIENT REQUESTS**: /himastermind/play/AHVEDJ34/123456 **SERVERS REPLIES**: 2 1 3 **CLIENT REQUESTS**: /himastermind/play/AHVEDJ34/126544 **SERVERS REPLIES**: 4 0 4 **CLIENT REQUESTS**: /himastermind/play/AHVEDJ34/126588 **SERVERS REPLIES**: 6 0 6 . Of course the game ends when the player guesses the number correctly, so the reply is 6 0. . Things the server needs to do: . If the game ID doesn’t exist, return an error | If the guess string is not correct (exactly 6 digits) return an error | Be able to handle the same player playing more than one game simultaneously, which is why we have the “game ID”. Each time the player calls “newgame” a new game is created, but it doesn’t destroy the previous one the server might have. | Keep track of everything in a database. That means for each player, the games its played, the guesses, elapsed time, and so on. | . You can deploy your work in any cloud service that as a free tier (most do). . In a separate task we’ll create a new dashboard to see who’s the best player. . There will be rewards for the students that create the best players and the best server. . Useful links: . Previous mastermind tasks: https://codein.withgoogle.com/dashboard/tasks/6684006435782656/ https://codein.withgoogle.com/dashboard/tasks/6022435409756160/ . Mastermind rules: https://www.wikihow.com/Play-Mastermind .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-codein-google_code-in_2019-mastermind.html",
            "relUrl": "/2020/02/20/public-codein-google_code-in_2019-mastermind.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post93": {
            "title": "Google Code-in 2019: Flutter",
            "content": "While the tasks themselves can’t be made public until the GCI starts officially, we think it’s OK to explain the kind of things we want to do for those of you that want to somehow get started - not with the tasks themselves, which is not possible, but getting prepared to start working immediately. . If you have already done some basic digging about Flutter, you already know what it is: A new platform that lets you write apps that will work both on Android, iOS and web. Most apps have menus, have logins, maybe access a database or some kind of internet resource, and depending on the specific app, maybe accesses the device capabilities such as the camera or location. . The programming language that Flutter uses is Dart, so that’s something that you want to look at. . Also, getting Flutter to work may take a bit of time: You can start by installing it and making sure “Flutter Doctor” says everything is great. . We’re going to be building a few apps. The goal is that build 3 applications that are actually going to be useful and we hope, popular. To get there each of them will consist on a large number of small tasks that anyone can do. Each task will have several instances (so several students can work on the same thing) and for each we’ll use the best one. Of course this doesn’t mean that the rest completed tasks will not be accepted. If a task it’s completed, it will be accepted, and the student is of course welcome to use his/her own version of that specific piece of program. . Remember: It’s open source, so everybody is allowed to have their own copy and customize it. . So what are the applications? . Bingo . Important: This is free bingo. We’re not building a betting game. That’s not interesting at all - but the pieces we’re going to learn, are. What are we going to learn here? . Menus | Drawing on the screen (for example, a grid) | Interactions with a server (we’re getting the tickets from a server, and getting the numbers from it) | Getting user feedback (where on the screen did the user press) | . The food locator . Suppose we are at a place, for example at a conference venue, or a large university campus, in which food is delivered at different places during different times of the day (this is a real use case, believe it or not). When you are hungry, you have to go around the place to find something to eat. Sometimes it’s something you like, and sometimes it’s not. Or maybe you won’t find anything. . We’re going to write an app that shows a map and let users report when they’ve seen food where they are. That information will appear to other users of the app that are in the same place, for example attending the same conference. Users can also report that food is not there, and also food can be removed from the map automatically after a certain amount of time. . Here we’re going to be learning: . Maps | Location services | Timeouts | Interaction with servers | . Smart photo app . Build an app that lets you take pictures with the camera and flag them in a useful way. Also, do special things with them. . We all know that camera pictures can be geolocated, which means that as part of the metadata they contain the physical location. We’re going to extend that by linking our pictures with things such as the calendar. For example, if your (Google) Calendar says that at 11:00-11:30 you were attending a book signing, would it be useful that the picture and the calendar event were automatically linked together? . Here we’re going to be learning: . Camera | Location services | Accessing the Google Calendar | Basic AI (details on this will be disclosed with the tasks) | .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-codein-google_code-in_2019-flutter.html",
            "relUrl": "/2020/02/20/public-codein-google_code-in_2019-flutter.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post94": {
            "title": "Welcome to Google Code-In 2018 and CCExtractor!",
            "content": "**Questions? You can email us at code-in@ccextractor.org or join our Slack group! But please make sure you read the whole page first. ** . . . &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt; This is going to be another absolutely amazing GCI year! We have a long and proud history of taking part in the Google Summer of Code with university students, and are excited to participate in GCI again for 3rd year with pre-university students! We have tasks that are: fun, useful, educational… and for all levels and interests - coding, design, documentation, UI, research and much more! &lt;/text&gt; . . . . &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt; While it is completely optional, it is highly recommended that you join our Slack group. All the mentors, org admins, contributors and fellow GCI participants hang out in that group. That’s the best place to get quick answers to any query or problem you might have. Go to the end of this page to invite yourself to the group. &lt;/text&gt; . &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt; Can’t join the Slack group? It’s no problem! We try to be super fast to respond to all comments and submissions in the GCI website. If you prefer email, you can email us at code-in@ccextractor.org. There’s also a mailing list/Google group for CCExtractor : https://groups.google.com/forum/#!forum/ccextractor-dev if that’s how you sail! &lt;/text&gt; . Things to know! ✅ . &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt;For tasks that require some resources in general we will provide them for you, including access to videos, system accounts, etc.&lt;/text&gt; . | &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt;This year we are going to have some system administration tasks. We will provide you with root access (Yes! We’re that cool) to a small server for interested students to play with. Check out our sysadmin tasks.&lt;/text&gt; . | &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt;We can’t stress this enough: Winners are those that do the hard tasks. Amount of tasks is not so important.&lt;/text&gt; . | &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt;Collaboration is much better than competition.&lt;/text&gt; . | &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt;Mentors love it when a student comes up with a better idea than their own, really. Do not just do as told. If something doesn’t feel right either argue against it (politely of course) or work on a different area.&lt;/text&gt; . | &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt;If you want to do something that is 90% or so implemented in any other open source project just take it, complete it, send the maintainers of that project whatever changes you did so they can use them if they want, and integrate with our code. Always remember to leave all license and credits intact (you can add your own name).&lt;/text&gt; . | &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt;Mentors are there to help but they’re people too, not bots. So they sleep from time to time, may also have other things going on, can get sick, etc. They will reciprocate when they think of students.&lt;/text&gt; . | &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt;Whatever you do, we want to integrate. This means that your work will be public and will be around for a long time. In a few years you will find your own code again (/ccextractor-wiki-test/2020/02/20/code tends to follow you). Try to leave it in a condition that the future you will be proud of.&lt;/text&gt; . | &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt;Be mindful of your own privacy. Yes, we’re a friendly bunch and you’ll get to know us and we’ll get to know you in our community. That’s different from posting your real name publicly everywhere. &lt;/text&gt; . | . . Perks . &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt; Remember that the absolute best way to get invited by an organization to participate in Google Summer of Code is by being part of the community before GSoC is even announced. If we, as an organization, are invited to GSoC 2019 the applications from successful Code-in students will go to the top of pile. &lt;/text&gt; . &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt; We also give back to our students in any way we can, including writing recommendation letters that can help to apply to universities, visas, jobs and so on. &lt;/text&gt; . &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt; In short - don’t think that the reward for participating this year may be limited to a t-shirt :-) &lt;/text&gt; . Code-in for Designers 👩‍🎨 . &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt; If you’re passionate about becoming a great designer and willing to do some serious work, look for the tasks labelled [Harddesign]. Hard means that they are going to take time and talent to produce the quality results we want and to bring up design tasks at par with coding. At least one of the students that does a great job on those will be a finalist, and maybe a winner. &lt;/text&gt; . &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt; We are doing this to prevent the design tasks being treated just as an easy way to complete beginner tasks. For example, you can create a T-Shirt design in 10 minutes, but that’s very unlikely to be good and usable to well, actually make T-Shirts with it. &lt;/text&gt; . &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt; We did this last year as well and got some amazing results. One of our winners from last year did some major design tasks including the organization logo. &lt;/text&gt; . &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt; Remember though that hard means hard. Don’t expect us to approve the first design you come up with. We will give you feedback and work with you until you produce something that you can be proud of for years and that we can use. &lt;/text&gt; . Get familiar with Tags 🏷 . &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt; We’ll do our best to keep consistent tasks that help you find out good things to do. If you think we could use better tags please get in touch, with examples, and we’ll improve. For some some tags you might want to look out for: &lt;/text&gt; . &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt;winnerstrack: The hardest and/or more valuable tasks go here. If you are really serious about winning, work on those. To be realistic we don’t think they will be solved, but it wouldn’t be the first time a GCI student productivity is better than the mentors :-) So we’re putting a few of these out there (not at the same time).&lt;/text&gt; . | &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt;hardtask: Difficult tasks but doable, with effort, patience, and mentor support. That’s what we’re here for!&lt;/text&gt; . | &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt;githubissue: The task has a related GitHub issue, so by doing this task you will be actually fixing a bug or adding a requested feature.&lt;/text&gt; . | &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt;anylanguage: Tasks that you can do in any programming language you want, usually because they are about writing a new (small) program so you would start from scratch.&lt;/text&gt; . | &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt;googleassistant: Tasks related to Google Assistant. We’ll have a few of them every week, and they don’t have to be related to our organization primary focus at all - they can be anything, because we want you (and us) to explore this new technology.&lt;/text&gt; . | &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt;bonus: Tasks that come with a special prize, such as a software license (that we will buy for the student) or a book. We will publish one of these tasks every week or so, so make sure to look for them often!&lt;/text&gt; . | . FAQ: Why is CCExtractor written in C? Are you from the past? ⏱ . &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt; Yes, we get this from time to time :-) We know there’s lots of cool languages out there, many really easy to start with, and well, C is not one of them. But the thing is, the most performance critical tools are written in C, such as the Linux kernel, or FFmpeg, or… you get the idea. A tool that needs to process lots of data (such as video) just needs to be as efficient as possible. &lt;/text&gt; . &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt; We do have auxiliary tools written in different languages, for example the Windows GUI is written in C#, and we have lots of Python as well. But the core CCExtractor tool is in C. Should you learn C then? Well, depends on how serious you are with IT in general. By learning it you will learn a lot of how things really work - without using all the magic that higher level languages provide. &lt;/text&gt; . Video from previous winners . &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt; We think that the best way to let you know how cool Code-In is is to show you a video of previous winners. This was at Google’s office in San Francisco in 2016, where Evgeny and Alexandru (which are of course now core developers at CCExtractor) presented what they did during GCI 2016! &lt;/text&gt; . . &lt;text size=&quot;18px&quot; align=&quot;justify&quot;&gt; And Aadi and Shiyuan (also core team members now as well as GCI mentors) in 2017: &lt;/text&gt; . . Matej and Ivan, 2018: . . Slack . Slack is a great communication tool. Most CCExtractor developers hang out in a slack team. You’re welcome to request an invitation here: . {slackinvite} .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-codein-google_code-in_2018.html",
            "relUrl": "/2020/02/20/public-codein-google_code-in_2018.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post95": {
            "title": "Public:codein:google_code In_2017_code In_for_designers",
            "content": "Code-In 2017 for designers . This year we are going to have some hard design tasks to bring design up to par with coding. Hard means that they are going to take time and talent to produce the quality results we want. . At least one of our finalists will be a designer even if he or she has not contributed code. We are doing this to prevent the design tasks being treated just as an easy way to complete beginner tasks. For example, you can create a T-Shirt design in 10 minutes, but that’s very unlikely to be good and usable to well, actually make T-Shirts with it. . If you are serious about becoming a great designer and are willing to do serious work, look for tasks with the “HardDesign” tasks. At least one of the students that does a great job on those will be a finalist, and maybe a winner. . Remember though that hard means hard. Don’t expect us to approve the first design you come up with. We will give you feedback and work with you until you produce something that you can be proud of for years and that we can use. . Also, as a bonus, if the design is for something physical (T-Shirt, sticker, etc) we will ship you one totally free to any part of the world. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-codein-google_code-in_2017_code-in_for_designers.html",
            "relUrl": "/2020/02/20/public-codein-google_code-in_2017_code-in_for_designers.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post96": {
            "title": "Public:codein:google_code In_2016_task_list",
            "content": "**Google Code-In 2016 ** . Code-In 2016 finished already. We’re really sad, but it’s been an amazing experience so we will be back! . **Questions? You can email us at code-in@ccextractor.org. But please make sure you read the whole page first. ** For tasks that require some resources in general we will provide them for you, including access to videos, system accounts, etc. . Remember that the absolute best way to get invited by an organization to participate in Summer of Code is by being part of the community before GSoC is even announced. If we, as an organization, are invited to GSoC 2017 the applications from successful Code-In students will go to the top of pile. . We also give back to our students in any way we can, including writing recommendation letters that can help to apply to universities, visas, jobs and so on. . In short - don’t think that the reward for participating this year may be limited to a T-Shirt :-) . General things to keep in mind while working: . 1) Collaboration is much better than competition. 2) Mentors love it when a student comes up with a better idea than their own, really. Do not just do as told. If something doesn’t feel right either argue against it or work on a different area. 3) If you want to do something that is 90% or so implemented in any other open source project just take it, complete it, send the maintainers of that project whatever changes you did so they can use them if they want, and integrate with our code. Always remember to leave all license and credits intact (you can add your own name). 4) Mentors are there to help but they’re people too, not bots. So they sleep from time to time, may also have other things going on, can get sick, etc. They will reciprocate when they think of students. 5) Whatever you do, we want to integrate. This means that your work will be public and will be around for a long time. In a few years you will find your own code again (/ccextractor-wiki-test/2020/02/20/code tends to follow you). Try to leave it in a condition that your future you will be proud of. . Slack . Slack is a great communication tool. Most CCExtractor developers hang out in a slack team. You’re welcome to request an invitation here: . {slackinvite} .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-codein-google_code-in_2016_task_list.html",
            "relUrl": "/2020/02/20/public-codein-google_code-in_2016_task_list.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post97": {
            "title": "User Documentation for Activity Extractor",
            "content": "Activity Extractor aims to extract and download viewing activity from popular video streaming services including: Netflix, Hulu and Amazon. This process is automated and needs very little user interaction. It can be called from the command line with the streaming service as a parameter, and it outputs the viewing activity into a simple .txt file. . The program requires the user to have a valid login and password for the streaming service they wish to retrieve viewing activity from. . Installation Instructions . Clone the repository from GitHub: . git clone https://github.com/ManveerBasra/ActivityExtractor . Install pip . If pip3 is not installed run this in a command window: . sudo apt-get install python3-setuptools sudo easy_install3 pip sudo mv /usr/local/bin/pip /usr/local/bin/pip-3 . Install Selenium . Run this in a command window: . sudo pip3 install -U selenium . Install PhantomJS . Make sure you have NodeJS installed (https://nodejs.org/) Using Node’s package manager run this in a command window: . npm -g install phantomjs-prebuilt . Disclaimer: Use it at your own risk. . Usage Instructions . If credentials are already in userconfig.ini . Open a command window in directory containing ActivityExtractor.py Run this command: . python activityextractor.py [service] . If credentials are NOT already in userconfig.ini . Open a command window in directory containing ActivityExtractor.py Run this command: . python activityextractor.py [service] --email=[email] --password=[password] . service : Put your streaming service here [email] : Put your email address for the streaming service here [password]: Put your password here . If you’re getting activity from Netflix, you must include an additional parameter: . ... --user=[user] . [user] : Put your Netflix username here . Please report any errors on GitHub along with the error message for support. .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-codein-activity_extractor_user_docs.html",
            "relUrl": "/2020/02/20/public-codein-activity_extractor_user_docs.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post98": {
            "title": "Activity Extractor Technical Documentation",
            "content": "This page contains how the service modules were coded and also how to add support for a new service. . Module Information . ActivityExtractor.py . This module is responsible for processing the parameters passed through the command line and calling the appropriate streaming service. . It passes the streaming service a dictionary containing credentials required to complete the process The dictionary is formatted like this: . parameters = { &#39;url&#39;: self.url, &#39;email&#39;: self.email, &#39;password&#39;: self.password, &#39;user&#39;: self.user } . url: The url the driver initially navigates to. email: The email required to log into the service. password: The password associated with the email. user: (Only required for Netflix) The profile name the user wishes to retrieve viewing activity from. . common.py . Contains modules common to all services. . &gt; output_activity(SERVICE, activity_list) . Module to output activity into a .txt file. Accepts 2 parameters ‘SERVICE’ and ‘activity_list’: SERVICE: Name of the service calling the function. activity_list: List of viewing activity extracted from the streaming service. . hulu.py . Gets viewing activity from Hulu. . &gt; get_activity() . Called from the Main Module. It’s main purpose is to initialize the process and call login_hulu() . &gt; login_hulu() . First this function creates an instance of Chrome and passes potential arguments to the driver. It then navigates to www.hulu.com and logs in with the user credentials. Then calls navigate_site() . &gt; navigate_site() . The main purpose of this function is to navigate to the ‘History’ page on Hulu. . &gt; navigate_pages() . Depending on the length of the user’s viewing history there may be multiple pages of viewing history. This function calls get_page_activity() for every page of viewing history. Then calls common.output_activity(). . &gt; get_page_activity() . Gets all the viewing activity on the current viewing history page. Also displays a progress bar to the user. . amazon.py . Gets viewing activity from Amazon. . &gt; get_activity() . Called from the Main Module. It’s main purpose is to initialize the process and call login_amazon() . &gt; login_amazon() . First this function creates an instance of Chrome and passes potential arguments to the driver. It then navigates to https://www.amazon.com/gp/sign-in.html and logs in with the user credentials. It then navigates to the viewing history page by passing a url to the driver. Calls navigate_pages() . &gt; navigate_pages() . Depending on the length of the user’s viewing history there may be multiple pages of viewing history. This function calls get_page_activity() for every page of viewing history. Then calls common.output_activity(). . &gt; get_page_activity() . Gets all the viewing activity on the current viewing history page. . netflix.py . Gets viewing activity from Netflix. . &gt; get_activity() . Called from the Main Module. It’s main purpose is to initialize the process and call login_netflix() . &gt; login_amazon() . First this function creates an instance of Chrome and passes potential arguments to the driver. It then navigates to https://www.netflix.com/Login and logs in with the user credentials. It then calls get_active_profile() . &gt; get_active_profile() . Selects user profile based on profile name present in parameters[‘user’]. Calls navigate_site() . &gt; navigate_site() . Calls hover_click() then clicks the ‘Viewing Activity’ link once hover_click() has navigated to the user’s account page. Then calls scroll_to_bottom() . &gt; hover_click() . Hovers on the profile icon in the top right corner of the Netflix homepage. Then clicks on ‘Your Account’ on the dropdown menu that appears. Returns True or False depending on whether the process was successful. . &gt; scroll_to_bottom() . Depending on the length of the user’s viewing activity Netflix displays only a portion of it. In order to have Netflix display the full list this function is called. Scrolls to the bottom of the page and waits for Netflix to load the next dynamic page of activity. This may be repeated multiple time until all of the activity is displayed. Calls get_page_activity() . &gt; get_page_activity() . Gets all viewing activity from the page. Displays a progress bar to the user. Calls common.output_activity() . New Service Instructions . In order to add a new service to the platform, follow these steps. . Instructions . 1. Add your service and it’s parameters to the file ‘userconfig.ini’ Follow this format when adding your service: . [SERVICE_NAME] url = service_login_page_url email = test@email.com password = test . 2. Create a .py file for your service. Take a look at hulu.py, amazon.py or netflix.py as a reference. Your file must have a class containing all of the functions required to login and get viewing activity. The class should be named like ‘SERVICE_NAMEActivityExtractor’. Example: NetflixActivityExtractor Your class’s init() function needs to accept an argument that will contain the parameters which ActivityExtractor.py will pass. Here is the general format: . def __init__(self, parameters): self.parameters = parameters self.driver = None ... . The main things your function should accomplish: . Log into streaming service | Navigate to viewing activity page | Retrieve viewing activity | Display progress bar (if possible) | Call common.output_activity() to output viewing activity into a .txt file common.output_activity() accepts 2 parameters. The first is the name of the viewing service, the second is a list containing all of the viewing activity. Make user to ‘import common’ to use the function. | . 3. Add you service into ActivityExtractor.py. In ‘ActivityExtractor.py’, create an import statement to import your service class from your service file. It should be something like this: . from SERVICE_NAME import SERVICE_NAMEActivityExtractor . Next you have to add your service into supported_services. In the ActivityExtractor, the init() function has a dictionary named ‘self.supported_services’. Add your service into the dictionary following the format of the other services. It should look something like this: . self.supported_services = { &#39;amazon&#39;: AmazonActivityExtractor, &#39;hulu&#39;: HuluActivityExtractor, &#39;netflix&#39;: NetflixActivityExtractor, &#39;SERVICE_NAME&#39;: SERVICENAMEActivityExtractor } . 4. Test the program with your service and report any errors. If your service worked successfully create a pull request to the repository and it’ll be added. If any errors are thrown that you can’t solve yourself, create an issue in the repository and we’ll try helping you out. . 5. Add your service to this documentation page. Contact Carlos to get login credentials for this page and add your service following the format of the other streaming services. . For bug fixes create an issue on the repository For any other inquiries contact me at m13basra@gmail.com .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-codein-activity_extractor_technical_docs.html",
            "relUrl": "/2020/02/20/public-codein-activity_extractor_technical_docs.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post99": {
            "title": "Blog Posts from our Students",
            "content": "Our Google Summer of Code Students are hard at work, but they are also creative writers who document their journey and adventure while developing their projects. Here you can find many blog posts linking to their blog posts where they describe the process on how it is to work for CCExtractor and Google Summer Of Code . Google Summer of Code 2019 . Artem Fedoskin(@thelastpolaris) with his project ‘‘Poor Mans Rekognition’’ GSoC 2019 Starts! | GSoC 2019 — Community Bonding Period | GSoC 2019 — Choosing the Right Structure | GSoC 2019 — Choosing the Right License and building the DL Rig | GSoC 2019 — Working on Face Detection | GSoC 2019 — Facial Recognition and First Evaluations | GSoC 2019 — Polishing Face Detection and working on Web App | GSoC 2019 — Web App and Second Evaluations | GSoC 2019 — Continuing Working on Web App *GSoC 2019 — Poor Man’s Rekognition | . | Amit Kumar(@pymit) working also on ‘‘Poor Mans Rekognition’’ GSoC’19 with CCExtractor Development | week 1 | week 2 | week 3 | week 4 | week 5 | week 6&amp;7 | Final Phase | Final Work Submission | . | Faiz Khan and ‘‘Poor Mans Rekognition’’ Google Summer of Code.! 2019 (my story and opinion) | Technical details of my project (Google summer of code) | Week-1, Poor man Rekognition | REPORT 1: 4th Week. | Report 2 | Upgrade Face and eye detection using OpenCV. | Report 3 | Report 4: FINAL | . | Sarfaraz Iraqui(@sziraqui) also with his project ‘‘Poor Mans Rekognition’’: Not The Normal GSoC Journey | . | Shivam Jha(@thealphadollar) is working on the ‘‘Sample Platform’’ [[https://thealphadollar.github.io/experience/2019/05/17/gsoc19-0.html| GSoC’19 [0]: Congratulations And Let’s Begin]] | . | Chris Wang has the goal of improving ‘‘Swag Lyrics’’ with ‘‘autosynch’’ GSoC 2019 Phase 1: Vocal Isolation | GSoC 2019 Phase 2: Hyphenation &amp; Alignment | GSoC 2019 Phase 3: Optimization | . | Suyash Bajpai is developing ‘‘co-oCCur’’ a High speed subtitle synchronization tool: | | | GSoC : Final Work Submission! | . | Chaitanya Bankanhal goal is to make a ‘‘Web UI for Rclone’’ Google summer of Code ‘19 RClone WebUI PHASE I | File Structure Overview for RClone WebUI React | Creating a new widget | . | Mohsin Mustafa(@buoyantbird) project is ‘‘Poor Man Rekognition’’: First Evaluation Report | Second Evaluation Report | Final Evaluation Report | . | . Google Summer of Code 2018 . Archit Matur(@achie27) did work on ‘‘FabBits’’ Building FabBits : GSoC with CCExtractor #1 | Building FabBits : GSoC with CCExtractor #2 | Building FabBits : GSoC with CCExtractor #3 | Building FabBits : GSoC with CCExtractor #4 | [[https://medium.com/@achie27/building-fabbits-gsoc-with-ccextractor-final-e4b5d3160bf6| Building FabBits : GSoC with CCExtractor — Final]] | . | Shivam Jha(@thealphadollar) and ‘‘Nephos’’ | | | | | | | . | Aaditya Nair and his work with ‘‘Nephos’’ GSoC The Beginning | GSOC Update Week 1 and Week 2 | GSOC Update Week 3 and Week 4 | GSOC Update Week 5 and Week 6 | GSOC Update Week 7 and Week 8 | GSOC Update Weeks 9, 10 and 11 | . | Saurbah Shah with the aim to ‘‘improve the OCR Subsystem’’ Selection in GSoC 2k18 | . | .",
            "url": "https://dumbmachine.github.io/ccextractor-wiki-test/2020/02/20/public-blog_posts_our_students.html",
            "relUrl": "/2020/02/20/public-blog_posts_our_students.html",
            "date": " • Feb 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This is where you put the contents of your About page. Like all your pages, it’s in Markdown format. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://dumbmachine.github.io/ccextractor-wiki-test/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  
  

  

  
  

  

  
      ,"page8": {
          "title": "Google Summer of Code 2020",
          "content": "Welcome to our ideas page. It’s great you want to start early. Please join us in our slack channel! (we’ll leave as an exercise to you to find it — it’s on our website). . This is going to be an amazing year — lots of new things to work on, including JokerTV, a totally open TV receiver, plus several experimental/for fun projects. Projects in C, Node.js, Python, Rust and more, you name it, we have it. Plus resources for students — we’ll give access to a high-speed server, all our samples (we’ll even ship a portable drive with them anywhere in the world, so don’t worry about slow connections) and various other perks. . You are welcome to check out the page (actual ideas at the bottom of the page, with each project having it’s own separate page as well) and start early in the community bonding process as well as learning a bit about our code ethics and practices. And of course, we’d love you to stay around even if we are not invited to GSoC or if we cannot invite you as a student. . The ideas we currently have . Important: If you have something else in mind that relates to subtitles and accessibility please get in touch. We prefer that you do something that you are passionate about even if it’s something we hadn’t considered. . After you check out our ideas please continue reading to the bottom of the page to get information about who we are, how we collaborate, what resources we will provide to you, etc. . Some tasks descriptions are still vague. We know that. Feel free to get in touch for questions, or just check their page from time to time. We will update the descriptions often. . Core subtitle tool (CCExtractor itself) . Name Description Tech you need to know Tech you will learn Difficulty . Complete 708 support | &lt;p&gt; This is one of the big ones. Why? Because it’s been on our wish list for some time and until now no one has decided to really go for it;after the initial work it’s always been incremental improvements, but no one has raised their hand and said “I’m going to complete this”. It’s possible the code base is not really friendly. Who knows. If this is the case we’re OK with a total rewrite if that’s what it takes to get this done. The details page has some more information if this picked your interest. This project is guaranteed to be selected if the proposal is good.&lt;/p&gt; | C | Video standards Subtitle standards CCExtractor internals Internationalization | Hard | . Add support for streaming Live TV | A number of streaming platforms now offer support for internet based live TV, which is great: It lets you watch TV on the go, it lets you get rid of cable, satellite and areal antennas… unfortunately, this live TV is not standardized at all. Your job is to do the work to add suport for Hulu and Youtube. We will pay for the subscription costs as well as any required infrastructure. | Any | Video standards Subtitle standards Live streaming platforms | Unknown | . Work on JokerTV integration | JokerTV is an excellent open hardware and software platform (think Arduino, but for TV). It’s still early days, and we really want to be among the first supporting this amazing new platform. JokerTV can receive signals from all TV standards around the world (finally!, no more European or American models, etc). We will buy one device for the student (or students, if their ideas are different) that works on this. Abylay Ospan, the genius behind JokerTV has agreed to mentor. | C | Hardware Video standards Joker (the platform) | Unknown | . Write Python bindings for CCExtractor | This was partially done during GSoC 2017, but the approach was totally wrong — a wrapper, instead of Cython. Let’s cut our losses and start over. | C Python | Obscure C+Python topics CCExtractor internals | Medium | . Add support for DTMB countries | DTMB is the standard for Chinese TV, also implemented by countries such as Cuba. What kind of student is ideal for this task? One with lots of analytic skills and patience. If you are one of those, don’t disregard this task just because you don’t speak (or maybe, even care) about Chinese. The experience on dealing with this will be extremely valuable in the future. We will use part of the organization funds to buy standard documents you might need, a capture device, and in general, anything required to make your life easier. | C | DTMB Video standards Hardware Research | Unknown | . Improve our OCR subsystem | We use tesseract to OCR bitmap based subtitles. In theory this is straight forward, but when you take into consideration all variants (color, languages, subtitles burned-in image, even moving text such as tickers) the complexity grows fast. Still, the work done by PhD students in the past is great, and we’re confident this year we can complete the work on this area if someone of the same caliber decides to join the effort. | C | Tesseract Imaging OCR | Suspected hard | . Add Japanese support | Captions are used by people all over the world on a regular basis. Most of us are familiar with regular horizontal captions at the bottom of the screen, but did you know that in Japan a common position for captions is vertically on the right or left side of the screen? Come learn more about what Japanese audiences need out of captions as well as how captioning standard likes IMSC and WebVTT support these features. | Japanese (or be good with foreign languages) | Depends | Suspected hard | . Artificial Intelligence and clever algorithms . Name Description Tech you need to know Tech you will learn Difficulty . Poor man’s Rekognition (II) | Amazon Rekognition is a (paid) service that is able to identify celebrity faces in a picture. Last year we did some work towards creating a free alternative. This year we want to improve on the past work. | Your choice | AI Computer vision | Unknown | . Poor man’s Textract | Amazon Textract a (paid) service that “automatically extracts text and data from scanned documents. Amazon Textract goes beyond simple optical character recognition (OCR) to also identify the contents of fields in forms and information stored in tables.”. We want to build a free alternative that provides an output of similar quality. | Your choice | AI Computer vision OCR | Unknown | . Support tools we and other orgs use as part of their development process . Name Description Tech you need to know Tech you will learn Difficulty . The sample platform (/ continuous integration) project | The sample platform is a good way to help new contributors to check if their code doesn’t introduce any regressions. It’s pretty stable, but is often hard to interpret for new contributors, and still pretty slow if the queue builds up. We want to take the concepts of this existing platform and re-write it from scratch making use of the horizontally scalable cloud options that are nowadays available. This project is guaranteed to be selected if the proposal is good. | Git Python | Cloud services API’s GitHub Actions GitHub API’s Continuous Integration (CI) Automated deployments GitHub integration | Medium/Hard | . New things we’re currently interested on . Name Description Tech you need to know Tech you will learn Difficulty . A reference channel for Roku | Roku is currently the most common media streamer. It’s cheap and neutral (it’s not in any “fight”). Unfortunately, there aren’t any good open source channels, so if you want to start your own you have to start from scratch. We want to fix that by creating the “reference” source code for a generic channel. We will send a free Roku to our student for development. | None | Brightscript Roku Video Streaming | Medium | . An “algorithm video creator” in Python | During Google Code-in we got some proof of concepts that are actually quite cool. We want to build a complete tool that helps study and understand algorithms | Python | Python internals Algorithms | Medium | . FFmpeg + Rust | This project is two fold: One, is create proper Rust bindings into FFmpeg’s libraries. The 2nd, and harder, is create a “graph to code” generator | C or C++ | FFmpeg’s internals Rust | Possibly hard | . Extend rclone’s web UI (mentored by Nick Craig-Wood, rclone’s developer) | rclone is a fantastic tool to synchronize cloud storage. It’s rsync for the cloud. Last year we started a web UI, and it was a successful GSoC project. We want to continue working on it. | Cloud (lots) Web (different tech) | — | Medium | . SwagLyrics | Last Summer of Code, we came up with a platform to align lyrics to their temporal location in the audio (https://github.com/SwagLyrics/autosynch). This year, we want to improve it, and integrate it to SwagLyrics proper. | Python (mainly) | Depends on your idea | Medium to Unknown | . Vote counter and reporter | More and more countries depend on electronic vote counting and/or reporting in their elections, and apparently no one can get this right. Either no one knows how to do it or they know exactly what they are doing. Both things are worrying, to say the least. We want to spend this summer working on an open-source solution everybody and use and audit, in any country. | Systems design | Flutter (frontend), your choice (backend) | Hard | . Mouseless for Linux | Mouseless is a nice tool to practice keyboard shortcuts for a few popular apps. Unfortunately it’s only available for Mac. We’d like to create an open-source Linux version that can be easily extended. | Your choice | ?? | Unknown | . rutorrent mobile interface | rutorrent is the most popular web interface for rtorrent, which is possibly the most used BitTorrent client in linux. The job is to write a Flutter based web interface that uses rutorrent’s backend service to provide a native interface. | Flutter | BitTorrent | Medium | . The next peer-to-peer protocol | BitTorrent is of course the world’s most used peer to peer protocol. It’s great, but it was designed before the cloud was ubiquitous and it doesn’t make use of the places where you have the most storage or the most bandwidth. Can we design something for the next decade? | Depends | Peer-to-peer, cloud | Medium | . Linux tuning for network throughput | Come up with a system that tunes the linux kernel to maximize network throughput for a number of workloads, such as web server or BitTorrent | Linux | Kernel internals, Networking | Hard | . About us . We are a small org, which means that your contribution will have a large impact. It’s not going to mean a 0.5% improvement on a big project — it’s going to be more than 10% on a medium size one. If you like challenges and want a chance to shine this is your place. . We have -we think- statistically amazing continuity in the team: Most GSoC students from all the past years are still involved, even if they are no longer eligible as students. They still contribute code, and they mentor both in GSoC and the sister program GCI. As mentors, they also come to the Summer of Code summit which traditionally takes place in October. . We have mentors all over the world (North America, Europe, Asia and Australia), so time zones are never a problem. Our main channel of communication is a Slack channel to which everyone is welcome. We expect all accepted students to be available on Slack very often, even if you don’t need to talk to your mentor. This will help you ask questions when necessary, and you might be able to help others out as well while working on your project. . Exception: If your country (such asRussia) has banned Slack please get in touch in we’ll work out a solution with you. We absolutely want you to participate. . A mailing list is also available for those that prefer email over slack. It’s a new mailing list (the old one hasn’t been used in a long time) but it’s read by everyone involved in GSoC. . All our top committers will be mentoring. Many of them are former GSoC students or winners of GCI. . Perks . All accepted students get a programming book immediately after being accepted, with the hope that they read them before the coding starts. We want to see if this increases the quality of the work. So far we have selected these three books (pick one), but we’re open to suggestions: Clean Code, Elements of Programming Interviews in Python, Cracking the code interview. . We will also provide to all accepted students: . 6 months of access (from the acceptance date) to all courses in educative.io | 12 months of access (from the acceptance date) to backtobackswe, which is a fantastic resource to learn algorithms, prepare for coding interviews, and in general learn fundamentals. | . The student working on CEA-708 will also receive a copy of the latest CEA-708 specification document. . About what we use . This is what we usetoday. It doesn’t mean this is what we want to continue using. Probably not — we’re really open to change. We’re just describing the status quo so you know what you are getting into :-) . The core tool that names the organization (CCExtractor) is a command-line program written inC(not C++). . The current Windows GUI is written inC#, and we have another GUI for Linux that’s written with Qt, and a small GUI that’s integrated into the main program (C). In we’re being honest, nothing is great. Good news for you is that you can start over if you want. . The testing tool we use to run regression tests is mainly written inPython, but it also used Javascript, CSS and some shell scripting. The Test suite is written in C#. One of the projects this year is about replacing it. . The prototype real time subtitle website is written inNodeJS. . We also have a number of support tools that do a number of different things, from downloading subtitles from streaming services to translating them with Google Translate or DeepL. Most of them are written inPython, but since they are small tools that do their job you don’t need to worry much about them. . For totally new things you can use whatever tool you feel is best for the job. . About sample media and other resources . We work with huge files. Not all of them are huge, but many are. We know that many students don’t have access to high speed internet. To those students we will ship (as soon as they are selected) a portable hard drive with all our samples. So if your internet connection is not good, don’t worry — as long as you can plug a USB drive to your development computer you can participate with us. . We also have a shared Linux development server with lots of storage and a Gigabit uplink. Students get an account on it and they are welcome to use it. There’s nothing there except our own work, so it’s a trusted environment (for a server that is connected to internet of course). . The sample platform also hosts a bunch of samples, both which are small or decently sized. . Some projects have specific requirements: For example to add support for JokerTV you will need a physical JokerTV device. We will send one to the student that takes this project well before GSoC starts. The LiveTV project requires a subscription to YouTube with LiveTV (whatever it’s called this week) and Hulu. We will pay for those. If your project requires some cloud resources (Google Compute Engine, for example), we will pay for that, too. . In general, you are not expected to pay for anything (other than your own development computer and internet, of course) related to any project. . If you need anything not mentioned (such as a book) let us know. Within reason, we’ll help you. . About the projects and getting accepted . Qualification: Our selection system is based on several factors. Of course no student ranks in all criteria, so don’t worry when you read the list below. . Work on our core tool: Even if you are going to be working on something totally different. This might seen counter intuitive, but the thing is if you prove you can dig into our (messy) code base, find yourself your way around it, and fix a few bugs, you are just the kind of person we can trust to “figure things out”. GSoC is among other things, a learning experience. No matter what project you decide to work on, there’s going to be roadblocks, things you don’t know how to do, etc. So we really like it when students embrace those situations. . Qualification tasks specific to the project: The detail page for some projects contains specific qualification tasks that apply to them. . Contributions to existing open source projects: This can be anything. From a good GitHub profile to pull-requests sent to any other existing project, participation in hackathons, Google Code-In, past GSoCs and so on. . A good proposal: This is the one criteria that is non-negotiable. Your proposal has to be good, period. . Project popularity: Some ideas just have more competition, so if participating in GSoC is a top priority for you (over working on a specific project), consider applying to one of the “niche” ideas. After all, that’s a great way to get your foot in the door :-) . Best core tool tasks . We’re added a difficulty level to all our open issues on GitHub. Best thing you can do is head there and see if you are able to fix some of the easy ones and work your way up. We don’t expect you to be able to do the hard ones but we’d be impressed if you did :-) . For some of the easy ones you don’t even need to know C. Just being able to compile CCExtractor and dig around a bit will be enough. . The sample platform’s issues are tagged with “gsoc-proposal-task”, so you can easily see what you can work on. . Take home qualification tasks . If instead of working on existing code you’d prefer to show us your skills working on something new, you can pick one of these projects. . Community etiquette . It goes without saying that everyone in the community has to be polite and respectful, and consider everyone else a member of a team and not a competitor. . All developers are part of the team, by the way. Our Slack channel has mentors, code-in participants, other students, or developers and users that are none of the above but they all play some kind of role in CCExtractor’s community. . Part of being respectful is giving consideration to everyone else’s time. Most of us have day jobs, and as such are limited in the time we can use to guide you. We’d like to spend it on quality discussions, and not on things that are for example written on this website, things that you can easily retrieve by reading documentation on used libraries or on the software’s help screen. Asking this kind of questions in the Slack channel shows little respect for our time. This doesn’t mean you can’t ask questions, but remember that being a clueless user and a lazy developer are two very different things. If you ask those questions you will probably get an answer as if you were a clueless user (polite no matter what), but if you apply to GSoC you will be considered a lazy developer. Google is your friend ;) . Tell things as you see them. Politely -you’re not Linus-, but don’t sugar-coat it. We know some parts of our code is poorly written, poorly documented, etc. It stands out, so you will know when you dig in. No one is going to be offended by having that code rewritten or refactored. Peer review applies to everybody’s work and is done by everybody. . Cross project proposals . Because we use a number of libraries and in fact “are a library” ourselves (meaning other programs can link CCExtractor as a library, or invoke the binary) we interact with other communities and their software. From time to time there’s a chance to do something interesting that affects CCExtractor and something else (FFmpeg comes to mind, but also Kodi, VLC, libGPAC, Red Hen, to mention just a few of our friends that typically participate in Summer of Code). So how does this work? As long as the work benefits CCExtractor and it’s part of your summer project, we’re OK with you spending some time on the other project. For example if you are improving our MP4 support, for which we use libGPAC, and need to fix or improve something on libGPAC you are welcome to do so. If you do, make sure you submit your changes to their maintainers and follow through with their merge process. . Your proposal . You can propose to do any of the following ideas, or you can bring your own. In any case, make sure you run them by us before you actually submit your proposal. . At the very least your proposal needs to . Explain what you do want to do, why it is important to you (don’t make up a story here — the reason can be that you need it, that you just think it’s cool, that you have an itch to work on it, etc), and why it could be important or useful to us. | Explain how you intend to accomplish the goal, in enough detail that makes it clear that you have done your homework. For example, “I will modify the CCExtractor binary so that it’s able to convert audio to text with perfect accuracy” is the same thing as sending your proposal to the trash. You need to have a plan. | Detail the timeline explaining what the expected progress is for each week or every two weeks (pay special attention to the milestones within the GSoC timeline itself, of course) and how we should validate the results. | Detail what kind of support you will need from us. For example, if you are going to need test streams, hardware, access to a server, etc, let us know, so we can prepare everything for you as soon as possible. | Detail your expected working hours in UTC. We’re used to weird working schedules, so don’t worry about working in the middle of the night, or weekends instead of other days, etc. Knowing your hours may help us to match you better with a mentor. | Mention your planned absences. We don’t need you to detail what you will be doing when you are not working of course, but if you are going away for any reason we need to know so we don’t think you’ve abandoned. | Link to your GitHub (or any other repository) profile, if you have one, so we can take a look at your previous work. | GSoC is a coding program: This means that ideas that are about testing (unless it involves coding something to test our programs ;) ), website design, etc, are out. | However, we want to have good documentation: Make sure you have time to write a good technical article explaining your work. | Be realistic and honest with the timeline. Consider each week you should work around 30 hours. If your timeline reserves a lot of time for minor things we’ll think that you are not going to be working full-time in GSoC. On the other hand if you promise to do things in a lot less than that it seems realistic to us it will seem that you don’t really know how much work things take. | If you are going to be using 3rd party libraries (that’s OK), make sure to validate that their license is compatible with GPLv2 (which is ours). List the libraries in your proposal. Check that they are cross-platform. If you will need to extend those libraries in any way please explain. In this case, your proposal should include time to get that extension submitted to the maintainers (we love to contribute to other projects). | . Something else: Mentors often have their fingers in several pies. If you send the same proposal to several orgs everyone will know. So do yourself a favor and don’t do that. You can apply to several organizations and that’s totally fine, but each organization will want to see that you have put the time to write a great proposal that is focused on them. . Useful resources . A great resource for GSoC. .",
          "url": "https://dumbmachine.github.io/ccextractor-wiki-test/_pages/Gsoc%20start%20here.html",
          "relUrl": "/_pages/Gsoc%20start%20here.html",
          "date": ""
      }
      
  

  
      ,"page9": {
          "title": "",
          "content": "Here for Google Summer of Code 2020? . User documentation and files . How to chat with the team (for support, to join us, for GSoC or GCI, or anything else) . What’s CCExtractor? (the software, not the organization) . About CCExtractor Development (the organization, not the software) . Downloads . Changelog . Using the command line tool . Using the Windows GUI . Real time demo - Currently down, our primary source of data is moving to a new office and their infrastructure is not yet available. . Extracting burned-in subtitles . Extracting CEA-708 subtitles . Translating subtitles in real time . Using the cross-platform GUI . Extracting closed captions from a DVD step by step tutorial . public:general:Working with HDHomeRun . public:general:Using SPUPNG . TV samples . Donate . Cool external projects that use subtitles . Technical documentation . Most of these pages are the result of Summer of Code work. . Getting started with our code . public:general:Rotating capture system with HDHomeRun . public:general:Subtitle standards around the world . Regression system . Online real time repository . Subtitle Downloader (user) . Subtitle Downloader (technical) . public:gsoc:DVD Subtitles Technical Documentation GSoC’16 . public:gsoc:Python Extension Module Technical Documentation GSoC’17 . public:gsoc:Python Extension Module Compilation Documentation GSoC’17 . Building CCExtractor inside a Vagrant box . Activity Extractor (user) . Activity Extractor (technical) . Google Code-in public pages . public:codein:Google Code-in 2016 task list . public:codein:Google Code-in 2017 code-in for designers . public:codein:google_code-in_2018 . Google Code-in 2019: Welcome and introduction (start here) . Google Code-in 2019: Rust . Google Code-in 2019: Flutter . Google Code-in 2019: FFmpeg . Google Code-in 2019: Mastermind . Summer of Code public pages . public:gsoc:Ideas page for Summer of Code 2020 . public:gsoc:Ideas page for Summer of Code 2019 . public:gsoc:Ideas page for Summer of Code 2018 . public:gsoc:Welcome to Summer of Code 2016 . public:gsoc:Welcome to Summer of Code 2015 . public:gsoc:ccextractor_Bug Hunt . public:gsoc:ccextractor Tasks . CCExtractor unassigned tasks (pick what you like) . Blog Posts from our Students . Season of docs public pages . Ideas page for Season of Docs 2019 . GSoC Students Project Report . 2019 . Amit - Poor Man’s Rekognition . Bowen - PiPot . Faiz - Poor Man’s Rekognition . Sarfaraz - Poor Man’s Rekognition . Shivam Kumar Jha - Sample Platform . 2018 {{public:gsoc:gsoc_cc_2018.png?0x25 | GSoC with CCExtractor}} | . Archit - FabBits . Aaditya - Project Nephos . Shivam Kumar Jha - Project Nephos . Saurabh Shrivastava - CCExtractor Web - A web application for subtitle extraction through CCExtractor. . Satyam Mittal - The sample platform / Continuous integration . 2017 {{public:gsoc:gsoc_cc_up.png?0x25 | GSoC with CCExtractor}} | . Diptanshu - Python Extension Module (bindings) for CCExtractor . Saurabh - CCAligner - Word by Word Audio Subtitle Synchronisation . Satyam - Sample platform improvements (Windows testing) . 2016 . Willem - Sample platform iteration 2 . Abishek - Subtitle Extractor and CCExtractor improvements . Abhinav - Extract hard-coded subtitles from video streams . Shruti - News shot classification . Rishabh - DVD Subtitle Extraction . Ruslan - Real-time Repository and website . Vasanth - Commercial detection . 2015 . Willem - Sample submission platform / CCExtractor improvements . Nurendra - Sentiment Analysis / Realtime Translation with Google Translate/Apertium . Summer of Code private pages . private:gsoc:People . private:gsoc:technical_resources . private:gsoc:Planned absences . Contract work . How to hire CCExtractor developers . Miscellaneous resources about things that interest us . Rust . Flutter . Preparing for interviews (Silicon Valley style) . Useful linux tools . Articles about vim (the editor) .",
          "url": "https://dumbmachine.github.io/ccextractor-wiki-test/_pages/original-start-page.html",
          "relUrl": "/_pages/original-start-page.html",
          "date": ""
      }
      
  

  
      ,"page10": {
          "title": "",
          "content": "Here for Google Summer of Code 2020? . User documentation and files . How to chat with the team (/ccextractor-wiki-test/2020/02/20/for support, to join us, for GSoC or GCI, or anything else) . What’s CCExtractor? (/ccextractor-wiki-test/2020/02/20/the software, not the organization) . About CCExtractor Development (/ccextractor-wiki-test/2020/02/20/the organization, not the software) . Downloads . Changelog . Using the command line tool . Using the Windows GUI . Real time demo - Currently down, our primary source of data is moving to a new office and their infrastructure is not yet available. . Extracting burned-in subtitles . Extracting CEA-708 subtitles . Translating subtitles in real time . Using the cross-platform GUI . Extracting closed captions from a DVD step by step tutorial . public:general:Working with HDHomeRun . public:general:Using SPUPNG . TV samples . Donate . Cool external projects that use subtitles . Technical documentation . Most of these pages are the result of Summer of Code work. . Getting started with our code . public:general:Rotating capture system with HDHomeRun . public:general:Subtitle standards around the world . Regression system . Online real time repository . Subtitle Downloader (/ccextractor-wiki-test/2020/02/20/user) . Subtitle Downloader (/ccextractor-wiki-test/2020/02/20/technical) . public:gsoc:DVD Subtitles Technical Documentation GSoC’16 . public:gsoc:Python Extension Module Technical Documentation GSoC’17 . public:gsoc:Python Extension Module Compilation Documentation GSoC’17 . Building CCExtractor inside a Vagrant box . Activity Extractor (/ccextractor-wiki-test/2020/02/20/user) . Activity Extractor (/ccextractor-wiki-test/2020/02/20/technical) . Google Code-in public pages . public:codein:Google Code-in 2016 task list . public:codein:Google Code-in 2017 code-in for designers . public:codein:google_code-in_2018 . Google Code-in 2019: Welcome and introduction (start here) . Google Code-in 2019: Rust . Google Code-in 2019: Flutter . Google Code-in 2019: FFmpeg . Google Code-in 2019: Mastermind . Summer of Code public pages . public:gsoc:Ideas page for Summer of Code 2020 . public:gsoc:Ideas page for Summer of Code 2019 . public:gsoc:Ideas page for Summer of Code 2018 . public:gsoc:Welcome to Summer of Code 2016 . public:gsoc:Welcome to Summer of Code 2015 . public:gsoc:ccextractor_Bug Hunt . public:gsoc:ccextractor Tasks . CCExtractor unassigned tasks (/ccextractor-wiki-test/2020/02/20/pick what you like) . Blog Posts from our Students . Season of docs public pages . Ideas page for Season of Docs 2019 . GSoC Students Project Report . 2019 . Amit - Poor Man’s Rekognition . Bowen - PiPot . Faiz - Poor Man’s Rekognition . Sarfaraz - Poor Man’s Rekognition . Shivam Kumar Jha - Sample Platform . 2018 {{public:gsoc:gsoc_cc_2018.png?0x25 | GSoC with CCExtractor}} | . Archit - FabBits . Aaditya - Project Nephos . Shivam Kumar Jha - Project Nephos . Saurabh Shrivastava - CCExtractor Web - A web application for subtitle extraction through CCExtractor. . Satyam Mittal - The sample platform / Continuous integration . 2017 {{public:gsoc:gsoc_cc_up.png?0x25 | GSoC with CCExtractor}} | . Diptanshu - Python Extension Module (/ccextractor-wiki-test/2020/02/20/bindings) for CCExtractor . Saurabh - CCAligner - Word by Word Audio Subtitle Synchronisation . Satyam - Sample platform improvements (/ccextractor-wiki-test/2020/02/20/Windows testing) . 2016 . Willem - Sample platform iteration 2 . Abishek - Subtitle Extractor and CCExtractor improvements . Abhinav - Extract hard-coded subtitles from video streams . Shruti - News shot classification . Rishabh - DVD Subtitle Extraction . Ruslan - Real-time Repository and website . Vasanth - Commercial detection . 2015 . Willem - Sample submission platform / CCExtractor improvements . Nurendra - Sentiment Analysis / Realtime Translation with Google Translate/Apertium . Summer of Code private pages . private:gsoc:People . private:gsoc:technical_resources . private:gsoc:Planned absences . Contract work . How to hire CCExtractor developers . Miscellaneous resources about things that interest us . Rust . Flutter . Preparing for interviews (/ccextractor-wiki-test/2020/02/20/Silicon Valley style) . Useful linux tools . Articles about vim (/ccextractor-wiki-test/2020/02/20/the editor) .",
          "url": "https://dumbmachine.github.io/ccextractor-wiki-test/_pages/wip-start-page.html",
          "relUrl": "/_pages/wip-start-page.html",
          "date": ""
      }
      
  

  
      ,"page11": {
          "title": "",
          "content": "Warning . Do not manually save images into this folder. This is used by GitHub Actions to automatically copy images. Any images you save into this folder could be deleted at build time. .",
          "url": "https://dumbmachine.github.io/ccextractor-wiki-test/images/copied_from_nb/",
          "relUrl": "/images/copied_from_nb/",
          "date": ""
      }
      
  

  
  

}